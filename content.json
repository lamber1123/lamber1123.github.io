{"pages":[{"title":"凡是过往，皆为序章","text":"关于我本硕计算机科学与技术专业。主要使用C++、Python两门语言。 关于本站载入天数…载入时分秒… var now = new Date(); function createtime() { var grt = new Date(\"12/30/2021 10:16:51\"); now.setTime(now.getTime() + 250); days = (now - grt) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if (String(hnum).length == 1) { hnum = \"0\" + hnum; } minutes = (now - grt) / 1000 / 60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if (String(mnum).length == 1) { mnum = \"0\" + mnum; } seconds = (now - grt) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if (String(snum).length == 1) { snum = \"0\" + snum; } document.getElementById(\"timeDate\").innerHTML = \" | 本站已安全运行 \" + dnum + \" 天 \"; document.getElementById(\"times\").innerHTML = hnum + \" 小时 \" + mnum + \" 分 \" + snum + \" 秒 | \"; } setInterval(\"createtime()\", 250); 本站采用 hexo 框架搭建，使用 Icarus 主题，目前博客部署并发布在 Gitlab上。 本站为我的个人博客网站。建立本站的初衷有两点，一是为了整理我所学过的知识，二是相对我在学习过程中的收获和经验教训加以记录。 我目前主要在研究前端和数据库开发两个方向，对于机器学习等方面的涉猎。如果对相关方面也抱有兴趣，欢迎通过1143894636@qq.com或微信与我交流。","link":"/about/index.html"},{"title":"回望灯如旧，浅握双手","text":"The story of Lamber and Nancy 载入天数… var now = new Date(); function createtime() { var grt = new Date(\"4/17/2019 00:00:00\"); now.setTime(now.getTime() + 250); days = (now - grt) / 1000 / 60 / 60 / 24 + 1; dnum = Math.floor(days); document.getElementById(\"timeDate\").innerHTML = dnum + \" days have passed since April 17, 2019\"; } setInterval(\"createtime()\", 250); 遥遥万里，心声有否偏差，正是让这爱试出真与假 遥远的她，仿佛借风声跟我话 热情若冇变，哪管它沧桑变化","link":"/photos/index.html"}],"posts":[{"title":"CSS笔记（四）","text":"CSS 伪类 CSS 伪元素 CSS 导航栏 CSS 网页布局 CSS 总结 CSS 伪类CSS伪类是用来添加一些选择器的特殊效果。 1. 语法伪类的语法： selector:pseudo-class {property:value;} CSS类也可以使用伪类： selector.class:pseudo-class {property:value;} 2. anchor 伪类在支持 CSS 的浏览器中，链接的不同状态都可以以不同的方式显示 a:link {color:#FF0000;} /* 未访问的链接 */a:visited {color:#00FF00;} /* 已访问的链接 */a:hover {color:#FF00FF;} /* 鼠标划过链接 */a:active {color:#0000FF;} /* 已选中的链接 */ 注意：在CSS定义中，a:hover 必须被置于 a:link 和 a:visited 之后，才是有效的。注意：在 CSS 定义中，a:active 必须被置于 a:hover 之后，才是有效的。注意：伪类的名称不区分大小写。 伪类和CSS类伪类可以与 CSS 类配合使用： 3. 伪类和 CSS 类 a.red:visited {color:#FF0000;}&lt;a class=”red” href=”css-syntax.html”&gt;CSS 语法&lt;/a&gt; 如果在上面的例子的链接已被访问，它会显示为红色。 4. first-child 伪类您可以使用 :first-child 伪类来选择父元素的第一个子元素。注意：在IE8的之前版本必须声明&lt;!DOCTYPE&gt; ，这样 :first-child 才能生效。 匹配第一个 &lt;p&gt; 元素在下面的例子中，选择器匹配作为任何元素的第一个子元素的 &lt;p&gt; 元素： p:first-child{&nbsp;&nbsp;&nbsp;&nbsp;color:blue;} 在下面的例子中，选择相匹配的所有&lt;p&gt;元素的第一个 &lt;i&gt; 元素： p &gt; i:first-child{&nbsp;&nbsp;&nbsp;&nbsp;color:blue;} 在下面的例子中，选择器匹配所有作为元素的第一个子元素的 &lt;p&gt; 元素中的所有 &lt;i&gt; 元素： p:first-child i{&nbsp;&nbsp;&nbsp;&nbsp;color:blue;} CSS 伪元素CSS伪元素是用来添加一些选择器的特殊效果。 1. 伪元素的语法： selector:pseudo-element {property:value;} CSS类也可以使用伪元素： selector.class:pseudo-element {property:value;} 2. first-line 伪元素first-line 伪元素用于向文本的首行设置特殊样式。 在下面的例子中，浏览器会根据 first-line 伪元素中的样式对 p 元素的第一行文本进行格式化： p:first-line{&nbsp;&nbsp;&nbsp;&nbsp;color:#ff0000;&nbsp;&nbsp;&nbsp;&nbsp;font-variant:small-caps;} 3. first-letter 伪元素first-letter 伪元素用于向文本的首字母设置特殊样式： p:first-letter{&nbsp;&nbsp;&nbsp;&nbsp;color:#ff0000;&nbsp;&nbsp;&nbsp;&nbsp;font-size:xx-large;} CSS 导航栏熟练使用导航栏，对于任何网站都非常重要。使用CSS你可以转换成好看的导航栏而不是枯燥的HTML菜单。 具体流程看菜鸟教程：https://www.runoob.com/css/css-navbar.html CSS 网页布局网页布局有很多种方式，一般分为以下几个部分：头部区域、菜单导航区域、内容区域、底部区域。 1. 头部区域头部区域位于整个网页的顶部，一般用于设置网页的标题或者网页的 logo： .header {&nbsp;&nbsp;&nbsp;&nbsp;background-color: #F1F1F1;&nbsp;&nbsp;&nbsp;&nbsp;text-align: center;&nbsp;&nbsp;&nbsp;&nbsp;padding: 20px;} 2. 菜单导航区域菜单导航条包含了一些链接，可以引导用户浏览其他页面： /* 导航条 */.topnav {&nbsp;&nbsp;&nbsp;&nbsp;overflow: hidden;&nbsp;&nbsp;&nbsp;&nbsp;background-color: #333;}/* 导航链接 */.topnav a {&nbsp;&nbsp;&nbsp;&nbsp;float: left;&nbsp;&nbsp;&nbsp;&nbsp;display: block;&nbsp;&nbsp;&nbsp;&nbsp;color: #f2f2f2;&nbsp;&nbsp;&nbsp;&nbsp;text-align: center;&nbsp;&nbsp;&nbsp;&nbsp;padding: 14px 16px;&nbsp;&nbsp;&nbsp;&nbsp;text-decoration: none;}/* 链接 - 修改颜色 */.topnav a:hover {&nbsp;&nbsp;&nbsp;&nbsp;background-color: #ddd;&nbsp;&nbsp;&nbsp;&nbsp;color: black;} 3. 内容区域内容区域一般有三种形式: 1 列：一般用于移动端 2 列：一般用于平板设备 3 列：一般用于 PC 桌面设备 我们将创建一个 3 列布局，在小的屏幕上将会变成 1 列布局（响应式）： /* 创建三个相等的列 */.column {&nbsp;&nbsp;&nbsp;&nbsp;float: left;&nbsp;&nbsp;&nbsp;&nbsp;width: 33.33%;}/* 列后清除浮动 */.row:after {&nbsp;&nbsp;&nbsp;&nbsp;content: “”;&nbsp;&nbsp;&nbsp;&nbsp;display: table;&nbsp;&nbsp;&nbsp;&nbsp;clear: both;}/* 响应式布局 - 小于 600 px 时改为上下布局 */@media screen and (max-width: 600px) {&nbsp;&nbsp;&nbsp;&nbsp;.column {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;width: 100%;&nbsp;&nbsp;&nbsp;&nbsp;}} 4. 底部区域底部区域在网页的最下方，一般包含版权信息和联系方式等。 .footer {&nbsp;&nbsp;&nbsp;&nbsp;background-color: #F1F1F1;&nbsp;&nbsp;&nbsp;&nbsp;text-align: center;&nbsp;&nbsp;&nbsp;&nbsp;padding: 10px;} CSS 总结本教程已讲解了如何创建样式表来同时控制多重页面的样式和布局。你已经学会如何使用 CSS 来添加背景、格式化文本、以及格式化边框，并定义元素的填充和边距。同时，你也学会了如何定位元素、控制元素的可见性和尺寸、设置元素的形状、将一个元素置于另一个之后，以及向某些选择器添加特殊的效果，比如链接。 你已经学习了CSS，下一步学习什么呢？ 下一步应该学习 JavaScript 。 JavaScript 是最流行的语言之一。JavaScript 是属于 web 的语言，它适用于 PC、笔记本电脑、平板电脑和移动电话。JavaScript可以使您的网站更具活力。许多 HTML 开发者都不是程序员，但是 JavaScript 却拥有非常简单的语法。几乎每个人都有能力将小的 JavaScript 片段添加到网页中。","link":"/2022/01/01/CSS%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"CSS笔记（三）","text":"CSS 分组和嵌套 CSS 尺寸 (Dimension) CSS Display(显示) CSS Position(定位) CSS Overflow CSS Float（浮动） CSS 对齐 CSS 组合选择符 CSS 分组和嵌套 1. 分组选择器在样式表中有很多具有相同样式的元素。 h1 {&nbsp;&nbsp;&nbsp;&nbsp;color:green;}h2 {&nbsp;&nbsp;&nbsp;&nbsp;color:green;}p {&nbsp;&nbsp;&nbsp;&nbsp;color:green;} 为了尽量减少代码，你可以使用分组选择器。每个选择器用逗号分隔。在下面的例子中，我们对以上代码使用分组选择器： h1,h2,p{&nbsp;&nbsp;&nbsp;&nbsp;color:green;} 2. 嵌套选择器它可能适用于选择器内部的选择器的样式。在下面的例子设置了四个样式： p{ }: 为所有 p 元素指定一个样式。 .marked{ }: 为所有 class=”marked” 的元素指定一个样式。 .marked p{ }: 为所有 class=”marked” 元素内的 p 元素指定一个样式。 p.marked{ }: 为所有 class=”marked” 的 p 元素指定一个样式。 p{&nbsp;&nbsp;&nbsp;&nbsp;color:blue;&nbsp;&nbsp;&nbsp;&nbsp;text-align:center;}.marked{&nbsp;&nbsp;&nbsp;&nbsp;background-color:red;}.marked p{&nbsp;&nbsp;&nbsp;&nbsp;color:white;}p.marked{&nbsp;&nbsp;&nbsp;&nbsp;text-decoration:underline;} CSS 尺寸 (Dimension)CSS 尺寸 (Dimension) 属性允许你控制元素的高度和宽度。同样，它允许你增加行间距。所有CSS 尺寸 (Dimension)属性如下： 属性 描述 height 设置元素的高度 line-height 设置行高 max-height 设置元素的最大高度 max-width 设置元素的最大宽度 min-height 设置元素的最小高度 min-width 设置元素的最小宽度 width 设置元素的宽度 CSS Display(显示)display属性设置一个元素应如何显示，visibility属性指定一个元素应可见还是隐藏。 1. 隐藏元素 - display:none 或 visibility:hidden隐藏一个元素可以通过把display属性设置为”none”，或把visibility属性设置为”hidden”。但是请注意，这两种方法会产生不同的结果。visibility:hidden可以隐藏某个元素，但隐藏的元素仍需占用与未隐藏之前一样的空间。也就是说，该元素虽然被隐藏了，但仍然会影响布局。 h1.hidden {visibility:hidden;} display:none可以隐藏某个元素，且隐藏的元素不会占用任何空间。也就是说，该元素不但被隐藏了，而且该元素原本占用的空间也会从页面布局中消失。 h1.hidden {display:none;} 2. CSS Display - 块和内联元素块元素是一个元素，占用了全部宽度，在前后都是换行符。 块元素的例子： &lt;h1&gt; &lt;p&gt; &lt;div&gt; 内联元素只需要必要的宽度，不强制换行。 内联元素的例子： &lt;span&gt; &lt;a&gt; &lt;img&gt; Display 可以更改内联元素为块元素，反之亦然。 把列表项显示为内联元素： li {display:inline;} 下面的示例把span元素作为块元素： span {display:block;} 常用取值如下： 值 描述 none 此元素不会被显示 block 此元素将显示为块级元素，此元素前后会带有换行符 inline 默认。此元素会被显示为内联元素，元素前后没有换行符 list-item 此元素会作为列表显示 run-in 此元素会根据上下文作为块级元素或内联元素显示 compact 此元素会根据上下文作为块级元素或内联元素显示 CSS Position(定位)position 属性指定了元素的定位类型。position 属性的五个值： static relative fixed absolute sticky 元素可以使用的顶部，底部，左侧和右侧属性定位。然而，这些属性无法工作，除非是先设定position属性。他们也有不同的工作方式，这取决于定位方法。 1. static 定位HTML 元素的默认值，即没有定位，遵循正常的文档流对象。静态定位的元素不会受到 top, bottom, left, right 影响。 div.static {&nbsp;&nbsp;&nbsp;&nbsp;position: static;&nbsp;&nbsp;&nbsp;&nbsp;border: 3px solid #73AD21;} 2. fixed 定位元素的位置相对于浏览器窗口是固定位置。即使窗口是滚动的它也不会移动： p.pos_fixed{&nbsp;&nbsp;&nbsp;&nbsp;position:fixed;&nbsp;&nbsp;&nbsp;&nbsp;top:30px;&nbsp;&nbsp;&nbsp;&nbsp;right:5px;} 3. relative 定位相对定位元素的定位是相对其正常位置。 h2.pos_left{&nbsp;&nbsp;&nbsp;&nbsp;position:relative;&nbsp;&nbsp;&nbsp;&nbsp;left:-20px;}h2.pos_right{&nbsp;&nbsp;&nbsp;&nbsp;position:relative;&nbsp;&nbsp;&nbsp;&nbsp;left:20px;} 4. absolute 定位绝对定位的元素的位置相对于最近的已定位父元素，如果元素没有已定位的父元素，那么它的位置相对于: h2{&nbsp;&nbsp;&nbsp;&nbsp;position:absolute;&nbsp;&nbsp;&nbsp;&nbsp;left:100px;&nbsp;&nbsp;&nbsp;&nbsp;top:150px;} 5. sticky 定位position: sticky; 基于用户的滚动位置来定位。粘性定位的元素是依赖于用户的滚动，在 position:relative 与 position:fixed 定位之间切换。它的行为就像 position:relative; 而当页面滚动超出目标区域时，它的表现就像 position:fixed;，它会固定在目标位置。元素定位表现为在跨越特定阈值前为相对定位，之后为固定定位。这个特定阈值指的是 top, right, bottom 或 left 之一，换言之，指定 top, right, bottom 或 left 四个阈值其中之一，才可使粘性定位生效。否则其行为与相对定位相同。 div.sticky {&nbsp;&nbsp;&nbsp;&nbsp;position: -webkit-sticky; /* Safari */&nbsp;&nbsp;&nbsp;&nbsp;position: sticky;&nbsp;&nbsp;&nbsp;&nbsp;top: 0;&nbsp;&nbsp;&nbsp;&nbsp;background-color: green;&nbsp;&nbsp;&nbsp;&nbsp;border: 2px solid #4CAF50;} 6. 重叠的元素元素的定位与文档流无关，所以它们可以覆盖页面上的其它元素z-index属性指定了一个元素的堆叠顺序（哪个元素应该放在前面，或后面）一个元素可以有正数或负数的堆叠顺序： img{&nbsp;&nbsp;&nbsp;&nbsp;position:absolute;&nbsp;&nbsp;&nbsp;&nbsp;left:0px;&nbsp;&nbsp;&nbsp;&nbsp;top:0px;&nbsp;&nbsp;&nbsp;&nbsp;z-index:-1;} 具有更高堆叠顺序的元素总是在较低的堆叠顺序元素的前面。 CSS 布局 - Overflowoverflow 属性用于控制内容溢出元素框时显示的方式。 CSS overflow 属性可以控制内容溢出元素框时在对应的元素区间内添加滚动条。overflow属性有以下值： 值 描述 visible 默认值。内容不会被修剪，会呈现在元素框之外 hidden 内容会被修剪，并且其余内容是不可见的 scroll 内容会被修剪，但是浏览器会显示滚动条以便查看其余的内容 auto 如果内容被修剪，则浏览器会显示滚动条以便查看其余的内容 inherit 规定应该从父元素继承 overflow 属性的值 注意:overflow 属性只工作于指定高度的块元素上。 CSS Float(浮动)CSS 的 Float（浮动），会使元素向左或向右移动，其周围的元素也会重新排列。Float（浮动），往往是用于图像，但它在布局时一样非常有用。 1. 元素怎样浮动元素的水平方向浮动，意味着元素只能左右移动而不能上下移动。一个浮动元素会尽量向左或向右移动，直到它的外边缘碰到包含框或另一个浮动框的边框为止。浮动元素之后的元素将围绕它。浮动元素之前的元素将不会受到影响。如果图像是右浮动，下面的文本流将环绕在它左边： img{&nbsp;&nbsp;&nbsp;&nbsp;float:right;} 2. 清除浮动 - 使用 clear元素浮动之后，周围的元素会重新排列，为了避免这种情况，使用 clear 属性。clear 属性指定元素两侧不能出现浮动元素。使用 clear 属性往文本中添加图片廊： .text_line{&nbsp;&nbsp;&nbsp;&nbsp;clear:both;} 属性 描述 值 clear 指定不允许元素周围有浮动元素 leftrightbothnoneinherit float 指定一个盒子（元素）是否可以浮动 leftrightnoneinherit CSS 对齐 1. 元素居中对齐要水平居中对齐一个元素(如 &lt;div&gt;), 可以使用 **margin: auto;**。设置到元素的宽度将防止它溢出到容器的边缘。元素通过指定宽度，并将两边的空外边距平均分配： .center {&nbsp;&nbsp;&nbsp;&nbsp;margin: auto;&nbsp;&nbsp;&nbsp;&nbsp;width: 50%;&nbsp;&nbsp;&nbsp;&nbsp;border: 3px solid green;&nbsp;&nbsp;&nbsp;&nbsp;padding: 10px;} 注: 如果没有设置 width 属性(或者设置 100%)，居中对齐将不起作用。 2. 文本居中对齐如果仅仅是为了文本在元素内居中对齐，可以使用 text-align: center; .center {&nbsp;&nbsp;&nbsp;&nbsp;text-align: center;&nbsp;&nbsp;&nbsp;&nbsp;border: 3px solid green;} 3. 图片居中对齐要让图片居中对齐, 可以使用 margin: auto; 并将它放到 块 元素中: img {&nbsp;&nbsp;&nbsp;&nbsp;display: block;&nbsp;&nbsp;&nbsp;&nbsp;margin: auto;&nbsp;&nbsp;&nbsp;&nbsp;width: 40%;} 4. 左右对齐 - 使用定位方式我们可以使用 position: absolute; 属性来对齐元素: .right {&nbsp;&nbsp;&nbsp;&nbsp;position: absolute;&nbsp;&nbsp;&nbsp;&nbsp;right: 0px;&nbsp;&nbsp;&nbsp;&nbsp;width: 300px;&nbsp;&nbsp;&nbsp;&nbsp;border: 3px solid #73AD21;&nbsp;&nbsp;&nbsp;&nbsp;padding: 10px;} 注释：绝对定位元素会被从正常流中删除，并且能够交叠元素。提示: 当使用 position 来对齐元素时, 通常 &lt;body&gt; 元素会设置 margin 和 padding 。 这样可以避免在不同的浏览器中出现可见的差异。 5. 左右对齐 - 使用 float 方式我们也可以使用 float 属性来对齐元素: .right {&nbsp;&nbsp;&nbsp;&nbsp;float: right;&nbsp;&nbsp;&nbsp;&nbsp;width: 300px;&nbsp;&nbsp;&nbsp;&nbsp;border: 3px solid #73AD21;&nbsp;&nbsp;&nbsp;&nbsp;padding: 10px;} 我们可以在父元素上添加 overflow: auto; 来解决子元素溢出的问题: .clearfix {&nbsp;&nbsp;&nbsp;&nbsp;overflow: auto;} 6. 垂直居中对齐 - 使用 paddingCSS 中有很多方式可以实现垂直居中对齐。 一个简单的方式就是头部顶部使用 padding: .center {&nbsp;&nbsp;&nbsp;&nbsp;padding: 70px 0;&nbsp;&nbsp;&nbsp;&nbsp;border: 3px solid green;} 如果要水平和垂直都居中，可以同时使用 padding 和 text-align: center: .center {&nbsp;&nbsp;&nbsp;&nbsp;padding: 70px 0;&nbsp;&nbsp;&nbsp;&nbsp;border: 3px solid green;&nbsp;&nbsp;&nbsp;&nbsp;text-align: center;} 7. 垂直居中 - 使用 line-height .center {&nbsp;&nbsp;&nbsp;&nbsp;line-height: 200px;&nbsp;&nbsp;&nbsp;&nbsp;height: 200px;&nbsp;&nbsp;&nbsp;&nbsp;border: 3px solid green;&nbsp;&nbsp;&nbsp;&nbsp;text-align: center;}/* 如果文本有多行，添加以下代码: */.center p {&nbsp;&nbsp;&nbsp;&nbsp;line-height: 1.5;&nbsp;&nbsp;&nbsp;&nbsp;display: inline-block;&nbsp;&nbsp;&nbsp;&nbsp;vertical-align: middle;} 8. 垂直居中 - 使用 position 和 transform除了使用 padding 和 line-height 属性外,我们还可以使用 transform 属性来设置垂直居中: .center {&nbsp;&nbsp;&nbsp;&nbsp;height: 200px;&nbsp;&nbsp;&nbsp;&nbsp;position: relative;&nbsp;&nbsp;&nbsp;&nbsp;border: 3px solid green;}.center p {&nbsp;&nbsp;&nbsp;&nbsp;margin: 0;&nbsp;&nbsp;&nbsp;&nbsp;position: absolute;&nbsp;&nbsp;&nbsp;&nbsp;top: 50%;&nbsp;&nbsp;&nbsp;&nbsp;left: 50%;&nbsp;&nbsp;&nbsp;&nbsp;transform: translate(-50%, -50%);} CSS 组合选择符CSS组合选择符包括各种简单选择符的组合方式。在 CSS3 中包含了四种组合方式: 后代选择器(以空格 &nbsp; 分隔) 子元素选择器(以大于 &gt; 号分隔） 相邻兄弟选择器（以加号 + 分隔） 普通兄弟选择器（以波浪号 ～ 分隔） 1. 后代选择器后代选择器用于选取某元素的后代元素。以下实例选取所有 &lt;p&gt; 元素插入到 &lt;div&gt; 元素中: div p{&nbsp;&nbsp;&nbsp;&nbsp;background-color:yellow;} 2. 子元素选择器与后代选择器相比，子元素选择器（Child selectors）只能选择作为某元素直接/一级子元素的元素。以下实例选择了&lt;div&gt;元素中所有直接子元素 &lt;p&gt; ： div&gt;p{&nbsp;&nbsp;&nbsp;&nbsp;background-color:yellow;} 3. 相邻兄弟选择器相邻兄弟选择器（Adjacent sibling selector）可选择紧接在另一元素后的元素，且二者有相同父元素。如果需要选择紧接在另一个元素后的元素，而且二者有相同的父元素，可以使用相邻兄弟选择器（Adjacent sibling selector）。以下实例选取了所有位于 &lt;div&gt; 元素后的第一个 &lt;p&gt; 元素: div+p{&nbsp;&nbsp;&nbsp;&nbsp;background-color:yellow;} 4. 后续兄弟选择器后续兄弟选择器选取所有指定元素之后的相邻兄弟元素。以下实例选取了所有 &lt;div&gt; 元素之后的所有相邻兄弟元素 &lt;p&gt; : div~p{&nbsp;&nbsp;&nbsp;&nbsp;background-color:yellow;}","link":"/2022/01/01/CSS%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"CSS笔记（一）","text":"CSS简介 CSS 语法 CSS Id 和 Class 选择器 CSS 创建 CSS Backgrounds(背景) CSS Text(文本) CSS Fonts(字体) CSS 链接(link) CSS 简介在学习 CSS 之前，你需要对 HTML / XHTML 的知识有基本的了解。 1. 什么是 CSS ? CSS 指层叠样式表 (Cascading Style Sheets) 样式定义如何显示 HTML 元素 样式通常存储在样式表中 把样式添加到 HTML 4.0 中，是为了解决内容与表现分离的问题 外部样式表可以极大提高工作效率 外部样式表通常存储在 CSS 文件中 多个样式定义可层叠为一个 点击查看菜鸟教程的CSS的示例 2. CSS 解决了什么问题?HTML 标签原本被设计为用于定义文档内容。 样式表定义如何显示 HTML 元素，就像 HTML 中的字体标签和颜色属性所起的作用那样。样式通常保存在外部的 .css 文件中。我们只需要编辑一个简单的 CSS 文档就可以改变所有页面的布局和外观。 CSS 语法CSS 规则由两个主要的部分构成：选择器，以及一条或多条声明: 选择器通常是您需要改变样式的 HTML 元素。每条声明由一个属性和一个值组成。属性（property）是您希望设置的样式属性（style attribute）。每个属性有一个值。属性和值被冒号分开。 1. CSS 实例CSS声明总是以分号(;)结束，声明总以大括号({})括起来: p {&nbsp;&nbsp;&nbsp;&nbsp;color:red;&nbsp;&nbsp;&nbsp;&nbsp;text-align:center;} 2. CSS 注释注释是用来解释你的代码，并且可以随意编辑它，浏览器会忽略它。CSS注释以 /* 开始, 以 */ 结束, 实例如下: /*这是个注释*/p{&nbsp;&nbsp;&nbsp;&nbsp;text-align:center;&nbsp;&nbsp;&nbsp;&nbsp;/*这是另一个注释*/&nbsp;&nbsp;&nbsp;&nbsp;color:black;&nbsp;&nbsp;&nbsp;&nbsp;font-family:arial;} CSS Id 和 Class 选择器如果你要在HTML元素中设置CSS样式，你需要在元素中设置”id” 和 “class”选择器。 1. id 选择器id 选择器可以为标有特定 id 的 HTML 元素指定特定的样式。HTML元素以id属性来设置id选择器,CSS 中 id 选择器以 “#” 来定义。以下的样式规则应用于元素属性 id=”para1”: #para1{&nbsp;&nbsp;&nbsp;&nbsp;text-align:center;&nbsp;&nbsp;&nbsp;&nbsp;color:red;} 2. class 选择器class 选择器用于描述一组元素的样式，class 选择器有别于id选择器，class可以在多个元素中使用。class 选择器在HTML中以class属性表示, 在 CSS 中，类选择器以一个点”.”号显示： 在以下的例子中，所有拥有 center 类的 HTML 元素均为居中。 .center {&nbsp;&nbsp;&nbsp;&nbsp;text-align:center;} 也可以指定特定的HTML元素使用class。 在以下实例中, 所有的 p 元素使用 class=”center” 让该元素的文本居中: p.center {&nbsp;&nbsp;&nbsp;&nbsp;text-align:center;} CSS 创建当读到一个样式表时，浏览器会根据它来格式化 HTML 文档。 1. 如何插入样式表？插入样式表的方法有三种: 外部样式表(External style sheet) 内部样式表(Internal style sheet) 内联样式(Inline style) 2. 外部样式表当样式需要应用于很多页面时，外部样式表将是理想的选择。在使用外部样式表的情况下，你可以通过改变一个文件来改变整个站点的外观。每个页面使用 &lt;link&gt; 标签链接到样式表。 &lt;link&gt; 标签在（文档的）头部： &lt;head&gt;&nbsp;&nbsp;&nbsp;&nbsp;&lt;link rel=”stylesheet” type=”text/css” href=”mystyle.css”&gt;&lt;/head&gt; 浏览器会从文件 mystyle.css 中读到样式声明，并根据它来格式文档。外部样式表可以在任何文本编辑器中进行编辑。文件不能包含任何的 html 标签。样式表应该以 .css 扩展名进行保存。 3. 内部样式表当单个文档需要特殊的样式时，就应该使用内部样式表。你可以使用 &lt;style&gt; 标签在文档头部定义内部样式表，就像这样: &lt;head&gt;&nbsp;&nbsp;&nbsp;&nbsp;&lt;style&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hr {color:sienna;}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p {margin-left:20px;}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;body {background-image:url(“images/back40.gif”);}&nbsp;&nbsp;&nbsp;&nbsp;&lt;/style&gt;&lt;/head&gt; 4. 内联样式由于要将表现和内容混杂在一起，内联样式会损失掉样式表的许多优势。请慎用这种方法，例如当样式仅需要在一个元素上应用一次时。要使用内联样式，你需要在相关的标签内使用样式（style）属性。Style 属性可以包含任何 CSS 属性。本例展示如何改变段落的颜色和左外边距： &lt;p style=”color:sienna;margin-left:20px”&gt;这是一个段落。&lt;/p&gt; 5. 多重样式如果某些属性在不同的样式表中被同样的选择器定义，那么属性值将从更具体的样式表中被继承过来。这涉及到：多重样式优先级问题 一般情况下，优先级如下：内联样式 &gt; 内部样式 &gt; 外部样式 &gt; 浏览器默认样式 CSS 背景CSS 背景属性用于定义HTML元素的背景。CSS 属性定义背景效果: background-color background-image background-repeat background-attachment background-position 1. background-colorbackground-color 属性定义了元素的背景颜色。页面的背景颜色使用在body的选择器中: body {background-color:#b0c4de;} 2. background-imagebackground-image 属性描述了元素的背景图像。默认情况下，背景图像进行平铺重复显示，以覆盖整个元素实体。 页面背景图片设置实例: body {background-image:url(‘paper.gif’);} 3. background-repeat一些图像如果在水平方向与垂直方向平铺，这样看起来很不协调。background-repeat 属性定义了图像的平铺模式。 值 描述 repeat 默认。背景图像将在垂直方向和水平方向重复 repeat-x 背景图像将在水平方向重复 repeat-y 背景图像将在垂直方向重复 no-repeat 背景图像将仅显示一次 inherit 规定应该从父元素继承 background-repeat 属性的设置 4. background-positionbackground-position 属性设置背景图像的起始位置。这个属性设置背景原图像（由 background-image 定义）的位置，背景图像如果要重复，将从这一点开始。注：需要把 background-attachment 属性设置为 “fixed”，才能保证该属性正常工作。 5. background-attachmentbackground-attachment 属性设置背景图像是否固定或者随着页面的其余部分滚动。 值 描述 scroll 默认值。背景图像会随着页面其余部分的滚动而移动 fixed 当页面的其余部分滚动时，背景图像不会移动 inherit 规定应该从父元素继承 background-attachment 属性的设置 6. background-originbackground-origin 属性规定 background-position 属性相对于什么位置来定位。如果背景图像的 background-attachment 属性为 “fixed”，则该属性没有效果。 background-origin: padding-box|border-box|content-box; 值 描述 padding-box 背景图像相对于内边距框来定位 border-box 背景图像相对于边框盒来定位 content-box 背景图像相对于内容框来定位 CSS Text(文本) 1. 文本颜色颜色属性被用来设置文字的颜色。颜色是通过CSS最经常的指定： 十六进制值 - 如: ＃FF0000 一个RGB值 - 如: RGB(255,0,0) 颜色的名称 - 如: red 一个网页的背景颜色是指在主体内的选择： body {color:red;}h1 {color:#00ff00;}h2 {color:rgb(255,0,0);} 2. 文本的对齐方式文本排列属性是用来设置文本的水平对齐方式。文本可居中或对齐到左或右,两端对齐.当text-align设置为”justify”，每一行被展开为宽度相等，左，右外边距是对齐（如杂志和报纸）。 h1 {text-align:center;}p.date {text-align:right;}p.main {text-align:justify;} 3. 文本修饰text-decoration 属性用来设置或删除文本的装饰。从设计的角度看 text-decoration属性主要是用来删除链接的下划线： a {text-decoration:none;} 也可以为非链接文本加划线: h1 {text-decoration:overline;}h2 {text-decoration:line-through;}h3 {text-decoration:underline;} 浏览器显示效果如下: 4. 文本转换文本转换属性是用来指定在一个文本中的大写和小写字母。可用于所有字句变成大写或小写字母，或每个单词的首字母大写。 p.uppercase {text-transform:uppercase;}p.lowercase {text-transform:lowercase;}p.capitalize {text-transform:capitalize;} 浏览器显示效果如下: 5. 文本缩进文本缩进属性是用来指定文本的第一行的缩进。 p {text-indent:50px;} 6. 所有文本属性 属性 描述 color 设置文本颜色 direction 设置文本方向 letter-spacing 设置字符间距 line-height 设置行高 text-align 对齐元素中的文本 text-decoration 向文本添加修饰 text-indent 缩进元素中文本的首行 text-shadow 设置文本阴影 text-transform 控制元素中的字母 unicode-bidi 设置或返回文本是否被重写 vertical-align 设置元素的垂直对齐 white-space 设置元素中空白的处理方式 word-spacing 设置字间距 CSS Fonts(字体)CSS字体属性定义字体，加粗，大小，文字样式。在计算机屏幕上，sans-serif字体被认为是比serif字体容易阅读。 1. CSS字型font-family 规定元素的字体系列。font-family 可以把多个字体名称作为一个“回退”系统来保存。如果浏览器不支持第一个字体，则会尝试下一个。也就是说，font-family 属性的值是用于某个元素的字体族名称或/及类族名称的一个优先表。浏览器会使用它可识别的第一个值。使用逗号分割每个值，并始终提供一个类族名称作为最后的选择。推荐使用一个通用字体系列名作为后路。 有两种类型的字体系列名称： 指定的系列名称：具体字体的名称，比如：”times”、”courier”、”arial”。 通常字体系列名称：比如：”serif”、”sans-serif”、”cursive”、”fantasy”、”monospace”。 p{font-family:Arial, Times, serif;} 2. 字体样式主要是用于指定斜体文字的字体样式属性。 这个属性有三个值： 正常 - 正常显示文本 斜体 - 以斜体字显示的文字 倾斜的文字 - 文字向一边倾斜（和斜体非常类似，但不太支持） p.normal {font-style:normal;}p.italic {font-style:italic;}p.oblique {font-style:oblique;} 3. 字体大小font-size 属性设置文本的大小。能否管理文字的大小，在网页设计中是非常重要的。但是，你不能通过调整字体大小使段落看上去像标题，或者使标题看上去像段落。请务必使用正确的HTML标签，就&lt;h1&gt; - &lt;h6&gt;表示标题和&lt;p&gt;表示段落：字体大小的值可以是绝对或相对的大小。 绝对大小： 设置一个指定大小的文本 不允许用户在所有浏览器中改变文本大小 确定了输出的物理尺寸时绝对大小很有用 相对大小： 相对于周围的元素来设置大小 允许用户在浏览器中改变文字大小 Remark 如果你不指定一个字体的大小，默认大小和普通文本段落一样，是16像素（16px=1em）。 4. 设置字体大小像素设置文字的大小与像素，让您完全控制文字大小： h1 {font-size:40px;}h2 {font-size:30px;}p {font-size:14px;} 5. 用em来设置字体大小为了避免Internet Explorer 中无法调整文本的问题，许多开发者使用 em 单位代替像素。em的尺寸单位由W3C建议。1em和当前字体大小相等。在浏览器中默认的文字大小是16px。因此，1em的默认大小是16px。可以通过下面这个公式将像素转换为em：px/16=em h1 {font-size:2.5em;} /* 40px/16=2.5em /h2 {font-size:1.875em;} / 30px/16=1.875em /p {font-size:0.875em;} / 14px/16=0.875em */ 6. 使用百分比和EM组合在所有浏览器的解决方案中，设置 元素的默认字体大小的是百分比： body {font-size:100%;}h1 {font-size:2.5em;}h2 {font-size:1.875em;}p {font-size:0.875em;} 7. 所有CSS字体属性 Property 描述 font 在一个声明中设置所有的字体属性 font-family 指定文本的字体系列 font-size 指定文本的字体大小 font-style 指定文本的字体样式 font-variant 以小型大写字体或者正常字体显示文本 font-weight 指定字体的粗细 CSS 链接不同的链接可以有不同的样式。 1. 链接样式链接的样式，可以用任何CSS属性（如颜色，字体，背景等）。特别的链接，可以有不同的样式，这取决于他们是什么状态。这四个链接状态是： a:link - 正常，未访问过的链接 a:visited - 用户已访问过的链接 a:hover - 当用户鼠标放在链接上时 a:active - 链接被点击的那一刻 使用方式如下: a:link {color:#000000;} /* 未访问链接*/a:visited {color:#00FF00;} /* 已访问链接 /a:hover {color:#FF00FF;} / 鼠标移动到链接上 /a:active {color:#0000FF;} / 鼠标点击时 */ 当设置为若干链路状态的样式，也有一些顺序规则：a:hover 必须跟在 a:link 和 a:visited后面a:active 必须跟在 a:hover后面 2. 文本修饰text-decoration 属性主要用于删除链接中的下划线： a:link {text-decoration:none;}a:visited {text-decoration:none;}a:hover {text-decoration:underline;}a:active {text-decoration:underline;} 3. 背景颜色背景颜色属性指定链接背景色： a:link {background-color:#B2FF99;}a:visited {background-color:#FFFF85;}a:hover {background-color:#FF704D;}a:active {background-color:#FF704D;}","link":"/2021/12/31/CSS%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"CSS笔记（二）","text":"CSS 列表 CSS Table(表格) CSS 盒子模型 CSS Border(边框) CSS 轮廓（outline）属性 CSS margin(外边距) CSS padding（填充） CSS 列表CSS 列表属性作用如下： 设置不同的列表项标记为有序列表 设置不同的列表项标记为无序列表 设置列表项标记为图像 1. 列表在 HTML中，有两种类型的列表： 无序列表 ul - 列表项标记用特殊图形（如小黑点、小方框等） 有序列表 ol - 列表项的标记有数字或字母使用 CSS，可以列出进一步的样式，并可用图像作列表项标记。 2. 不同的列表项标记list-style-type属性是指定列表项标记的类型。 ul.a {list-style-type: circle;}ul.b {list-style-type: square;}ol.c {list-style-type: upper-roman;}ol.d {list-style-type: lower-alpha;} 3. 作为列表项标记的图像要指定列表项标记的图像，使用列表样式图像属性，如： ul{&nbsp;&nbsp;&nbsp;&nbsp;list-style-image: url(‘sqpurple.gif’);} 4. 列表 - 简写属性在单个属性中可以指定所有的列表属性。这就是所谓的简写属性。为列表使用简写属性，列表样式属性设置如下： ul{&nbsp;&nbsp;&nbsp;&nbsp;list-style: square url(“sqpurple.gif”);} 要按顺序设置如下属性： list-style-type list-style-position list-style-image 如果上述值丢失一个，其余仍在指定的顺序，就没关系。 5. 移除默认设置list-style-type:none 属性可以用于移除小标记。默认情况下列表 &lt;ul&gt; 或 &lt;ol&gt; 还设置了内边距和外边距，可使用 margin:0 和 padding:0 来移除: ul {&nbsp;&nbsp;&nbsp;&nbsp;list-style-type: none;&nbsp;&nbsp;&nbsp;&nbsp;margin: 0;&nbsp;&nbsp;&nbsp;&nbsp;padding: 0;} 6. 所有的CSS列表属性 属性 描述 list-style 简写属性。用于把所有用于列表的属性设置于一个声明中 list-style-image 将图像设置为列表项标志 list-style-position 设置列表中列表项标志的位置 list-style-type 设置列表项标志的类型 CSS 表格使用 CSS 可以使 HTML 表格更美观。 1. 表格边框指定CSS表格边框，使用border属性。下面的例子指定了一个表格的Th和TD元素的黑色边框： table, th, td{&nbsp;&nbsp;&nbsp;&nbsp;border: 1px solid black;} 请注意，在上面的例子中的表格有双边框。这是因为表、 th 和 td元素都有独立的边界。为了显示一个表的单个边框，使用 border-collapse属性。 2. 折叠边框border-collapse 属性设置表格的边框是否被折叠成一个单一的边框或隔开： table{&nbsp;&nbsp;&nbsp;&nbsp;border-collapse: collapse;}table, th, td{&nbsp;&nbsp;&nbsp;&nbsp;border: 1px solid black;} 3. 表格宽度和高度Width和height属性定义表格的宽度和高度。下面的例子是设置100％的宽度，50像素的th元素的高度的表格： table{&nbsp;&nbsp;&nbsp;&nbsp;width:100%;}th{&nbsp;&nbsp;&nbsp;&nbsp;height:50px;} 4. 表格文字对齐包括表格中的文本对齐和垂直对齐属性。 text-align 属性设置水平对齐方式，向左，右，或中心： td{&nbsp;&nbsp;&nbsp;&nbsp;text-align:right;} vertical-align 属性设置垂直对齐方式，比如顶部，底部或中间： td{&nbsp;&nbsp;&nbsp;&nbsp;height:50px;&nbsp;&nbsp;&nbsp;&nbsp;vertical-align:bottom;} 5. 表格填充修改td和th元素 padding 属性，控制边框和表格内容之间的间距： td{&nbsp;&nbsp;&nbsp;&nbsp;padding:15px;} 6. 表格颜色指定边框的颜色、th元素的文本和背景颜色： table, td, th{&nbsp;&nbsp;&nbsp;&nbsp;border:1px solid green;}th{&nbsp;&nbsp;&nbsp;&nbsp;background-color:green;&nbsp;&nbsp;&nbsp;&nbsp;color:white;} CSS 盒子模型所有HTML元素可以看作盒子，在CSS中，”box model”这一术语是用来设计和布局时使用。CSS盒模型封装周围的HTML元素，它包括：边距，边框，填充，和实际内容。盒模型允许我们在其它元素和周围元素边框之间的空间放置元素。下面的图片说明了盒子模型(Box Model)： Margin(外边距) - 清除边框外的区域，外边距是透明的。 Border(边框) - 围绕在内边距和内容外的边框。 Padding(内边距) - 清除内容周围的区域，内边距是透明的。 Content(内容) - 盒子的内容，显示文本和图像。 当指定一个 CSS 元素的宽度和高度属性时，你只是设置内容区域的宽度和高度。要知道，完整大小的元素，你还必须添加内边距，边框和外边距。试想一下，你只有 250 像素的空间。让总宽度为 250 像素的元素可以如下设置: div {&nbsp;&nbsp;&nbsp;&nbsp;width: 220px;&nbsp;&nbsp;&nbsp;&nbsp;padding: 10px;&nbsp;&nbsp;&nbsp;&nbsp;border: 5px solid gray;&nbsp;&nbsp;&nbsp;&nbsp;margin: 0;} 最终元素的总宽度计算公式是这样的：总元素的宽度 = 宽度 + 左填充 + 右填充 + 左边框 + 右边框 + 左边距 + 右边距 元素的总高度最终计算公式是这样的：总元素的高度 = 高度 + 顶部填充 + 底部填充 + 上边框 + 下边框 + 上边距 + 下边距 CSS Border(边框)CSS边框属性允许你指定一个元素边框的样式和颜色。 在四边都有边框 红色底部边框 圆角边框 左侧边框带宽度，颜色为蓝色 1. 边框样式边框样式属性指定要显示什么样的边界。border-style 属性用来定义边框的样式 none: 默认无边框 dotted: 定义一个点线边框 dashed: 定义一个虚线边框 solid: 定义实线边框 double: 定义两个边框。 两个边框的宽度和 border-width 的值相同 groove: 定义3D沟槽边框。效果取决于边框的颜色值 ridge: 定义3D脊边框。效果取决于边框的颜色值 inset:定义一个3D的嵌入边框。效果取决于边框的颜色值 outset: 定义一个3D突出边框。 效果取决于边框的颜色值 2. 边框宽度您可以通过 border-width 属性为边框指定宽度。为边框指定宽度有两种方法：可以指定长度值，比如 2px 或 0.1em(单位为 px, pt, cm, em 等)，或者使用 3 个关键字之一，它们分别是 thick 、medium（默认） 和 thin。注：CSS 没有定义 3 个关键字的具体宽度，所以一个用户可能把 thick 、medium 和 thin 分别设置为等于 5px、3px 和 2px，而另一个用户则分别设置为 3px、2px 和 1px。 p.one{&nbsp;&nbsp;&nbsp;&nbsp;border-style:solid;&nbsp;&nbsp;&nbsp;&nbsp;border-width:5px;}p.two{&nbsp;&nbsp;&nbsp;&nbsp;border-style:solid;&nbsp;&nbsp;&nbsp;&nbsp;border-width:medium;} 3. 边框-单独设置各边在CSS中，可以指定不同的侧面不同的边框： p{&nbsp;&nbsp;&nbsp;&nbsp;border-top-style:dotted;&nbsp;&nbsp;&nbsp;&nbsp;border-right-style:solid;&nbsp;&nbsp;&nbsp;&nbsp;border-bottom-style:dotted;&nbsp;&nbsp;&nbsp;&nbsp;border-left-style:solid;} 4. border-style 属性可以设置一个单一属性设置四个边框。border-style属性可以有1-4个值： border-style:dotted solid double dashed; 上边框是 dotted 右边框是 solid 底边框是 double 左边框是 dashed border-style:dotted solid double; 上边框是 dotted 左、右边框是 solid 底边框是 double border-style:dotted solid; 上、底边框是 dotted 右、左边框是 solid border-style:dotted; 四面边框是 dotted 上面的例子用了border-style。然而，它也可以和border-width 、 border-color一起使用。 5. 边框-简写属性上面的例子用了很多属性来设置边框，也可以在一个属性中设置边框。你可以在 border 属性中设置： border-width border-style border-color 对他们的先后顺序没有要求,如： border:5px solid red; 6. CSS 边框属性 属性 描述 border 简写属性，用于把针对四个边的属性设置在一个声明 border-style 用于设置元素所有边框的样式，或者单独地为各边设置边框样式 border-width 简写属性，用于为元素的所有边框设置宽度，或者单独地为各边边框设置宽度 border-color 简写属性，设置元素的所有边框中可见部分的颜色，或为 4 个边分别设置颜色 border-bottom 简写属性，用于把下边框的所有属性设置到一个声明中 border-bottom-color 设置元素的下边框的颜色 border-bottom-style 设置元素的下边框的样式 border-bottom-width 设置元素的下边框的宽度 border-left 简写属性，用于把左边框的所有属性设置到一个声明中 border-left-color 设置元素的左边框的颜色 border-left-style 设置元素的左边框的样式 border-left-width 设置元素的左边框的宽度 border-right 简写属性，用于把右边框的所有属性设置到一个声明中 border-right-color 设置元素的右边框的颜色 border-right-style 设置元素的右边框的样式 border-right-width 设置元素的右边框的宽度 border-top 简写属性，用于把上边框的所有属性设置到一个声明中 border-top-color 设置元素的上边框的颜色 border-top-style 设置元素的上边框的样式 border-top-width 设置元素的上边框的宽度 CSS 轮廓（outline） 轮廓（outline）是绘制于元素周围的一条线，位于边框边缘的外围，可起到突出元素的作用。 轮廓（outline）属性指定元素轮廓的样式、颜色和宽度。 轮廓（outline）是绘制于元素周围的一条线，位于边框边缘的外围，可起到突出元素的作用。outline 属性规定元素轮廓的样式、颜色和宽度。 所有CSS 轮廓属性如下： 属性 说明 值 outline 在一个声明中设置所有的轮廓属性 outline-coloroutline-styleoutline-widthinherit outline-color 设置轮廓的颜色 color-namehex-numberrgb-numberinvertinherit outline-style 设置轮廓的样式 nonedotteddashedsoliddoublegrooveridgeinsetoutsetinherit outline-width 设置轮廓的宽度 thinmediumthicklengthinherit CSS margin(外边距)CSS margin(外边距)属性定义元素周围的空间。 margin 清除周围的（外边框）元素区域。margin 没有背景颜色，是完全透明的。margin 可以单独改变元素的上，下，左，右边距，也可以一次改变所有的属性。 1. 可能的值Margin可以使用负值，起到重叠的效果。 值 说明 auto 设置浏览器边距 length 定义一个固定的margin（使用px，pt，em等） % 定义一个使用百分比的边距 2. Margin - 单边外边距属性在CSS中，它可以指定不同的侧面不同的边距： margin-top:100px;margin-bottom:100px;margin-right:50px;margin-left:50px; 3. Margin - 简写属性为了缩短代码，有可能使用一个属性中margin指定的所有边距属性。这就是所谓的简写属性。所有边距属性的简写属性是 margin : margin属性可以有一到四个值。 margin:25px 50px 75px 100px; 上边距为25px 右边距为50px 下边距为75px 左边距为100px margin:25px 50px 75px; 上边距为25px 左右边距为50px 下边距为75px margin:25px 50px; 上下边距为25px 左右边距为50px margin:25px; 所有的4个边距都是25px 4. 所有的CSS边距属性 属性 描述 margin 简写属性。在一个声明中设置所有外边距属性 margin-bottom 设置元素的下外边距 margin-left 设置元素的左外边距 margin-right 设置元素的右外边距 margin-top 设置元素的上外边距 CSS padding（填充）CSS padding（填充）是一个简写属性，定义元素边框与元素内容之间的空间，即上下左右的内边距。 当元素的 padding（填充）内边距被清除时，所释放的区域将会受到元素背景颜色的填充。单独使用 padding 属性可以改变上下左右的填充。 值 说明 length 定义一个固定的填充(像素, pt, em,等) % 使用百分比值定义一个填充 1. 填充- 单边内边距属性在CSS中，它可以指定不同的侧面不同的填充。如： padding-top:25px;padding-bottom:25px;padding-right:50px;padding-left:50px; 2. 填充 - 简写属性为了缩短代码，它可以在一个属性中指定的所有填充属性。这就是所谓的简写属性。所有的填充属性的简写属性是 padding : Padding属性，可以有一到四个值。 padding:25px 50px 75px 100px; 上填充为25px 右填充为50px 下填充为75px 左填充为100px padding:25px 50px 75px; 上填充为25px 左右填充为50px 下填充为75px padding:25px 50px; 上下填充为25px 左右填充为50px padding:25px; 所有的填充都是25px 3. 所有的CSS填充属性 属性 说明 padding 使用简写属性设置在一个声明中的所有填充属性 padding-bottom 设置元素的底部填充 padding-left 设置元素的左部填充 padding-right 设置元素的右部填充 padding-top 设置元素的顶部填充","link":"/2022/01/01/CSS%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"HTML笔记（一）","text":"HTML 简介 HTML 基础 HTML 元素 HTML 属性 HTML 标题 HTML 段落 文本格式化 HTML 超链接 HTML 头部 HTML 简介 1. 什么是 HTML?HTML 是用来描述网页的一种语言。 HTML 指的是超文本标记语言: HyperText Markup Language HTML 不是一种编程语言，而是一种标记语言 标记语言是一套标记标签 (markup tag) HTML 使用标记标签来描述网页 HTML 文档包含了HTML 标签及文本内容 HTML文档也叫做 web 页面 2. HTML 标签 HTML 标记标签通常被称为 HTML 标签 (HTML tag)。 HTML 标签是由尖括号包围的关键词，比如 HTML 标签通常是成对出现。 标签对中的第一个标签是开始标签，第二个标签是结束标签 开始和结束标签也被称为开放标签和闭合标签 形式为：&lt;标签&gt;内容&lt;/标签&gt; 3. HTML 元素“HTML 标签” 和 “HTML 元素” 通常都是描述同样的意思。但是严格来讲, 一个 HTML 元素包含了开始标签与结束标签，如下是一个HTML 元素: &lt;p&gt;这是一个段落。&lt;/p&gt; 4. Web 浏览器Web浏览器是用于读取HTML文件，并将其作为网页显示。浏览器并不是直接显示的HTML标签，但可以使用标签来决定如何展现HTML页面的内容给用户。 5. 声明与编码HTML5 &lt;!DOCTYPE html&gt; 中文编码 目前在大部分浏览器中，直接\b输出中文会出现中文乱码的情况，这时候我们就需要在头部将字符声明为 UTF-8 或 GBK。 &lt;meta charset=”UTF-8”&gt; 6. HTML 编辑器推荐 VS Code：https://code.visualstudio.com/ HTML基础 1. HTML 标题HTML 标题通过&lt;h1&gt;到&lt;h6&gt;标签来定义。 &lt;h1&gt;这是一个标题&lt;/h1&gt;&lt;h2&gt;这是一个标题&lt;/h2&gt;&lt;h3&gt;这是一个标题&lt;/h3&gt; 2. HTML 段落HTML 段落是通过标签 &lt;p&gt; 来定义的。 &lt;p&gt;这是一个段落。&lt;/p&gt;&lt;p&gt;这是另外一个段落。&lt;/p&gt; 3. HTML 链接HTML 链接是通过标签 &lt;a&gt; 来定义的。 &lt;a href=”https://www.runoob.com&quot; &gt;这是一个链接&lt;/a&gt; 4. HTML 图像HTML 图像是通过标签 &lt;img&gt; 来定义的。 &lt;img loading=”lazy” src=”/images/logo.png” width=”224” height=”224” /&gt; HTML 元素HTML 文档由 HTML 元素定义。 HTML 元素以开始标签起始 HTML 元素以结束标签终止 元素的内容是开始标签与结束标签之间的内容 某些 HTML 元素具有空内容（&lt;br&gt;） 空元素在开始标签中进行关闭（以开始标签的结束而结束） 大多数 HTML 元素可拥有属性 HTML 属性 HTML 元素可以设置属性 属性可以在元素中添加附加信息 属性一般描述于开始标签 属性总是以名称/值对的形式出现，如：name=”value”。 属性值应该始终被包括在引号内。双引号是最常用的，不过使用单引号也没有问题。 HTML 标题标题（Heading）是通过 &lt;h1&gt; - &lt;h6&gt; 标签进行定义的。&lt;h1&gt; 定义最大的标题。 &lt;h6&gt; 定义最小的标题。浏览器会自动地在标题的前后添加空行。 1. 标题重要性确保将 HTML 标题 标签只用于标题。不要仅仅是为了生成粗体或大号的文本而使用标题。搜索引擎使用标题为您的网页的结构和内容编制索引。 因为用户可以通过标题来快速浏览您的网页，所以用标题来呈现文档结构是很重要的。应该将 h1 用作主标题（最重要的），其后是 h2（次重要的），再其次是 h3，以此类推。 2. HTML 水平线&lt;hr&gt; 标签在 HTML 页面中创建水平线。hr 元素可用于分隔内容。 3. HTML 注释可以将注释插入 HTML 代码中，这样可以提高其可读性，使代码更易被人理解。浏览器会忽略注释，也不会显示它们。注释写法如下: &lt;!– 这是一个注释 –&gt; 4. 如何查看源代码?单击右键，然后选择”查看源文件”（IE）或”查看页面源代码”（Firefox），其他浏览器的做法也是类似的。这么做会打开一个包含页面 HTML 代码的窗口。 HTML 段落段落是通过 &lt;p&gt; 标签定义的。 1. 不要忘记结束标签省略/&lt;p&gt;都没问题，但不要依赖这种做法。忘记使用结束标签会产生意想不到的结果和错误。 2. HTML 折行如果您希望在不产生一个新段落的情况下进行换行（新行），请使用 &lt;br&gt; 标签： &lt;p&gt;这个&lt;br&gt;段落&lt;br&gt;演示了分行的效果&lt;/p&gt; 3. 空行问题无法通过在 HTML 代码中添加额外的空格或换行来改变输出的效果。 当显示页面时，浏览器会移除源代码中多余的空格和空行。所有连续的空格或空行都会被算作一个空格。需要注意的是，HTML 代码中的所有连续的空行或换行也被显示为一个空格。 文本格式化对文本进行加粗、斜体、下沉和上浮等效果。 1. HTML 文本格式化标签 定义粗体文本：&lt;b&gt; 定义着重文字：&lt;em&gt; 定义斜体字：&lt;i&gt; 定义小号字：&lt;small&gt; 定义加重语气：&lt;strong&gt; 定义下标字：&lt;sub&gt; 定义上标字：&lt;sup&gt; 定义插入字：&lt;ins&gt; 定义删除字：&lt;del&gt; 2. HTML “计算机输出” 标签 定义计算机代码：&lt;code&gt; 定义键盘码：&lt;kbd&gt; 定义计算机代码样本：&lt;samp&gt; 定义变量：&lt;var&gt; 定义预格式文本：&lt;pre&gt; 3. HTML 引文, 引用, 及标签定义 定义缩写：&lt;abbr&gt; 定义地址：&lt;address&gt; 定义文字方向：&lt;bdo&gt; 定义长的引用：&lt;blockquote&gt; 定义短的引用语：&lt;q&gt; 定义引用、引证：&lt;cite&gt; 定义一个定义项目：&lt;dfn&gt; HTML 超链接HTML使用标签 &lt;a&gt;来设置超文本链接。超链接可以是一个字，一个词，或者一组词，也可以是一幅图。您可以点击这些内容来跳转到新的文档或者当前文档中的某个部分。当您把鼠标指针移动到网页中的某个链接上时，箭头会变为一只小手。 在标签&lt;a&gt; 中使用了href属性来描述链接的地址。 默认情况下，链接将以以下形式出现在浏览器中，写下形式均可以设置CSS语句来改变。 一个未访问过的链接显示为蓝色字体并带有下划线。 访问过的链接显示为紫色并带有下划线。 点击链接时，链接显示为红色并带有下划线。 1. HTML 链接语法 &lt;a href=”url”&gt;链接文本&lt;/a&gt; 点击这个超链接会把用户带到菜鸟教程的首页。 2. HTML 链接- target 属性使用 target 属性，你可以定义被链接的文档在何处显示。 _blank: 在新窗口中打开被链接文档。 _self: 默认。在相同的框架中打开被链接文档。 _parent: 在父框架集中打开被链接文档。 _top: 在整个窗口中打开被链接文档。 framename: 在指定的框架中打开被链接文档。 3. HTML 链接- id 属性id 属性可用于创建一个 HTML 文档书签。注意：书签不会以任何特殊方式显示，即在 HTML 页面中是不显示的，所以对于读者来说是隐藏的。 &lt;a id=”tips”&gt;有用的提示部分&lt;/a&gt;&lt;a href=”#tips”&gt;访问有用的提示部分&lt;/a&gt; 4. 各类型链接图片链接 &lt;p&gt;无边框的图片链接:&lt;a href=”//www.runoob.com/html/html-tutorial.html&quot; &gt;&lt;img src=”smiley.gif” alt=”HTML 教程” width=”32” height=”32”&gt;&lt;/a&gt;&lt;/p&gt; 书签连接 &lt;p&gt;&lt;a href=”#C3”&gt;查看章节3&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;章节1&lt;/h2&gt;&lt;p&gt;这边显示该章节的内容……&lt;/p&gt;&lt;h2&gt;章节2&lt;/h2&gt;&lt;p&gt;这边显示该章节的内容……&lt;/p&gt;&lt;h2&gt;&lt;a id=”C3”&gt;章节3&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;这边显示该章节的内容……&lt;/p&gt; 跳出框架 &lt;p&gt;跳出框架?&lt;/p&gt;&lt;a href=”//www.runoob.com/&quot; target=”_top” &gt;点击这里!&lt;/a&gt; 邮件链接 &lt;p&gt;这是一个电子邮件链接：&lt;a href=”mailto:someone@example.com?Subject=Hello%20again” target=”_top” &gt;发送邮件&lt;/a&gt;&lt;/p&gt; HTML 头部 &lt;title&gt; - 定义了HTML文档的标题，使用 &lt;title&gt; 标签定义HTML文档的标题 &lt;base&gt; - 定义了所有链接的URL，使用 &lt;base&gt; 定义页面中所有链接默认的链接目标地址。 &lt;meta&gt; - 提供了HTML文档的meta标记，使用 &lt;meta&gt; 元素来描述HTML文档的描述、关键词、作者、字符集等。 1. HTML &lt;head&gt; 元素&lt;head&gt; 元素包含了所有的头部标签元素。在 &lt;head&gt;元素中你可以插入脚本（scripts）, 样式文件（CSS），及各种meta信息。 可以添加在头部区域的元素标签为: &lt;title&gt;, &lt;style&gt;, &lt;meta&gt;, &lt;link&gt;, &lt;script&gt;, &lt;noscript&gt; 和 &lt;base&gt;。 2. HTML &lt;title&gt; 元素&lt;title&gt; 标签定义了不同文档的标题。&lt;title&gt; 在 HTML/XHTML 文档中是必须的。&lt;title&gt; 元素: 定义了浏览器工具栏的标题 当网页添加到收藏夹时，显示在收藏夹中的标题 显示在搜索引擎结果页面的标题 &lt;!DOCTYPE html&gt;&lt;html/&gt;&lt;head/&gt;&lt;meta charset=”utf-8”&gt;&lt;title&gt;文档标题/&lt;/title&gt;&lt;/head&gt;&lt;body&gt;文档内容……&lt;/body&gt;&lt;/html&gt; 3. HTML &lt;base&gt; 元素&lt;base&gt; 标签描述了基本的链接地址/链接目标，该标签作为HTML文档中所有的链接标签的默认链接: &lt;head&gt;&lt;base href=”http://www.runoob.com/images/&quot; target=”_blank” &gt;&lt;/head&gt; 4. HTML &lt;link&gt; 元素&lt;link&gt; 标签定义了文档与外部资源之间的关系。&lt;link&gt; 标签通常用于链接到样式表: &lt;head&gt;&lt;link rel=”stylesheet” type=”text/css” href=”mystyle.css” &gt;&lt;/head&gt; 5. HTML &lt;style&gt; 元素&lt;style&gt; 标签定义了HTML文档的样式文件引用地址。在&lt;style&gt; 元素中你也可以直接添加样式来渲染 HTML 文档: &lt;head&gt;&lt;style type=”text/css” &gt;body {background-color:yellow}p {color:blue}&lt;/style&gt;&lt;/head&gt; 6. HTML &lt;meta&gt; 元素meta标签描述了一些基本的元数据。 标签提供了元数据。元数据也不显示在页面上，但会被浏览器解析。 META 元素通常用于指定网页的描述，关键词，文件的最后修改时间，作者，和其他元数据。 元数据可以使用于浏览器（如何显示内容或重新加载页面），搜索引擎（关键词），或其他Web服务。 \\ 一般放置于 \\ 区域。 7. 使用情景为搜索引擎定义关键词:&lt;meta name=”keywords” content=”HTML, CSS, XML, XHTML, JavaScript” &gt; 为网页定义描述内容:&lt;meta name=”description” content=”免费 Web &amp; 编程 教程” &gt; 定义网页作者:&lt;meta name=”author” content=”Lamber” &gt; 每30秒钟刷新当前页面:&lt;meta http-equiv=”refresh” content=”30” &gt; 8. HTML &lt;script&gt; 元素&lt;script&gt;标签用于加载脚本文件，如：JavaScript。&lt;script&gt; 元素在以后的章节中会详细描述。 9. 总结 &lt;head&gt;: 定义了文档的信息 &lt;title&gt;: 定义了文档的标题 &lt;base&gt;: 定义了页面链接标签的默认链接地址 &lt;link&gt;: 定义了一个文档和外部资源之间的关系 &lt;meta&gt;: 定义了HTML文档中的元数据 &lt;script&gt;: 定义了客户端的脚本文件 &lt;style&gt;: 定义了HTML文档的样式文件","link":"/2021/12/30/HTML%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"DCFTest：DCF框架的测试工具","text":"前期配置工作 DCFTest的设计 DCFTest的测试 目录 1 配置工作 2 DCFTest的设计 3 DCFTest的测试 3.1 集群选举 3.2 日志复制 3.3 节点宕机 1 配置工作1.1 关于DCFDCF(Distributed Consensus Framework) 是华为Gauss数据库推出的基于Paxos协议的高可用一致性组件，该组件使得GaussDB(for openGauss)在保证数据一致性的同时，在高可用方面可进一步得到增强，包括： (1)通过自仲裁、多数派选主能力摆脱第三方仲裁组件，极大缩短RTO时间，且可预防任何故障下的脑裂双主； (2)支持节点同步、同异步混合部署的多集群部署模式； (3)提升主备间节点日志复制效率，提升系统的最大吞吐能力。借助GaussDB(for openGauss)的DCF高可用组件，用户不仅可以免去系统脑裂的风险，还提升了可用性。 项目地址：https://gitee.com/opengauss/DCF DCFTest基于GitHub上的项目DCF-Demo，希望通过设计测试程序来验证DCF的可用性与性能，在验证DCF框架的可用性后，也便于后期和其他的项目对接。DCFTest希望能够通过DCF-Demo中的代码来进行测试，具体做法是从DCF-Demo中将部分代码段提取出来，将dcf_test_main.c中的部分代码封装到dcf_demo.h当中，供DCFTest调用。 DCF-Demo项目地址：https://github.com/NPUWDBLab/DCF-Demo 关于DCFTest具体的安装与配置过程，在DCFTest主页有详细介绍。 DCFTest项目地址：https://github.com/lamber1123/DCFTest 2 DCFTest的设计暂时跳过，后期补上。 3 DCFTest的测试本次参与集群测试的三台服务器初始配置如下： {“stream_id” : 1, “node_id” : 1, “ip” : “172.19.0.202”, “port” : 29222,”role” : “LEADER”},{“stream_id” : 1, “node_id” : 2, “ip” : “172.19.0.203”, “port” : 29222, “role” : “FOLLOWER”},{“stream_id” : 1, “node_id” : 3, “ip” : “172.19.0.204”, “port” : 29222, “role” : “FOLLOWER”} 3.1 集群选举DCF采用类paxos协议，集群在启动时首先会由集群所有成员选举出一个leader，该leader会接管后续所有的client的请求，且集群日志状态以leader为准。除了在集群初始化启动时需要执行leader选举的过程，当leader失效的时也需要集群的成员选举出新的leader，所谓leader失效包括leader意外宕机，或同多数的follower发生网络隔离，甚至是leader因负载过重导致其不能及时同其他多数follower保持心跳。当然，另外还有一种情况是leader主动降到follower，此时它会让权给集群指定的follower。本节的测试暂不考虑异常情况，只测试集群启动时进行的选举与集群主动发起的选举。 首先打开三台服务器服务器，运行DCFTest cd DCFTestsh build.sh 分别看到启动成功的信息后，输入query指令查看集群状态 query 可见DCFTest节点均启动成功，node2当选为leader节点 在leader节点上主动推选node1成为leader promote leader 1query node1当选为leader节点 本节测试结束 3.2 日志复制在openGauss中，负责落盘的线程通过调DCF的write接口，把数据写到buffer队列里面，写完后无阻塞立即返回。当本次写入得到大多认可后，会异步的write callback。而buffer里的数据会经过一系列的复制流水线，经过组包发送给备机。备机收到数据包后会回调Replay callback通知数据库内核，然后将数据拷贝到xlog日志里面。 这一节主要通过DCF的读写来测试日志复制情况。 在leader节点中写入数据 dcftestisgood write dcftestisgood 在所有节点中通过index来读取这一数据 read 14 所有节点均可以读到这一数据 然后，在follower节点写入数据 hellodcftest write hellodcftest 在所有节点中通过index来读取这一数据 read 19 所有节点均可以读到这一数据 本节测试结束 3.2 节点宕机节点的宕机一种常见的异常事件，但是，若没有妥善处理则会影响到集群的安全性。宕机节点重启后能否正确的同步日志就是一个重要的问题。举个例子，在一个包含3个节点的集群中，S1为leader节点。若S1接收到了客户端的写请求，并将数据包发送给S2与S3。此时，若S3在接收到数据包之前发生宕机，但是S2正确接收并反馈了，此时S1依然会提交这一写请求。一段时间后S3重启，如果没有进行日志同步的话，S3的日志将落后于集群，针对S3的读请求将出现异常。本节中将通过读写数据对日志同步情况进行测试。 将一个follower节点手动宕机 stop 在另一节点中写入一条数据 outagetest write outagetest 在所有节点中通过index来读取这一数据 read 4 除宕机节点外，所有节点均可以正确读取数据 然后，将宕机节点手动恢复并读取数据 startread 4 宕机节点已经正确同步了前面的日志 本节测试结束","link":"/2022/12/07/DCFTest%EF%BC%9ADCF%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6%E7%9A%84%E8%AE%BE%E8%AE%A1/"},{"title":"HTML笔记（三）","text":"HTML 框架 HTML 颜色 HTML 脚本 HTML 字符实体 HTML URL HTML 总结 HTML 框架通过使用框架，你可以在同一个浏览器窗口中显示不止一个页面，如： &lt;iframe src=”https://space.bilibili.com/167431968&quot; width=”600” height=”400” &gt;&lt;/iframe&gt; 1. iframe - 设置高度与宽度height 和 width 属性用来定义iframe标签的高度与宽度。属性默认以像素为单位, 但是你可以指定其按比例显示 (如：”80%”)。 &lt;iframe loading=”lazy” src=”https://lamber1123.github.io/&quot; width=”200” height=”200” &gt;&lt;/iframe&gt; 其中 loading=”lazy” 代表允许延迟加载，避免不必要的流量浪费。 2. iframe - 移除边框frameborder 属性用于定义iframe表示是否显示边框。设置属性值为 “0” 移除iframe的边框: &lt;iframe src=”https://lamber1123.github.io/&quot; frameborder=”0”&gt;&lt;/iframe&gt; 3. 使用 iframe 来显示目标链接页面iframe 可以显示一个目标链接的页面目标链接的属性必须使用 iframe 的属性，如下实例: &lt;iframe src=”” name=”iframe_a”&gt;&lt;/iframe&gt;&lt;p&gt;&lt;a href=”https://lamber1123.github.io/&quot; target=”iframe_a” rel=”noopener”&gt;LAMBER的博客&lt;/a&gt;&lt;/p&gt; LAMBER的博客 颜色 HTML 颜色名目前所有浏览器都支持以下颜色名。141个颜色名称是在HTML和CSS颜色规范定义的（17标准颜色，再加124非标准颜色）。 17标准颜色指的是：黑色，蓝色，水，紫红色，灰色，绿色，石灰，栗色，海军，橄榄，橙，紫，红，白，银，蓝绿色，黄色。 查看所有颜色名：https://www.w3school.com.cn/tags/html_ref_colornames.asp HTML 颜色值HTML 颜色由一个十六进制符号来定义，这个符号由红色、绿色和蓝色的值组成（RGB）。 每种颜色的最小值是0（十六进制：#00），最大值是255（十六进制：#FF）。 查看更多颜色信息：https://encycolorpedia.cn/00cdff HTML HTML 脚本JavaScript 使 HTML 页面具有更强的动态和交互性。 1. HTML &lt;script&gt; 标签&lt;script&gt; 标签用于定义客户端脚本，比如 JavaScript。&lt;script&gt; 元素既可包含脚本语句，也可通过 src 属性指向外部脚本文件。JavaScript 最常用于图片操作、表单验证以及内容动态更新。 &lt;script&gt;document.write(“Hello World!”);&lt;/script&gt; 2. HTML &lt;noscript&gt; 标签&lt;noscript&gt; 标签提供无法使用脚本时的替代内容，比方在浏览器禁用脚本时，或浏览器不支持客户端脚本时。&lt;noscript&gt;元素可包含普通 HTML 页面的 body 元素中能够找到的所有元素。只有在浏览器不支持脚本或者禁用脚本时，才会显示 &lt;noscript&gt; 元素中的内容： &lt;script&gt;document.write(“Hello World!”)&lt;/script&gt;&lt;noscript&gt;抱歉，你的浏览器不支持 JavaScript!&lt;/noscript&gt; HTML 字符实体HTML 中的预留字符必须被替换为字符实体。一些在键盘上找不到的字符也可以使用字符实体来替换。 1. HTML 实体在 HTML 中，某些字符是预留的。在 HTML 中不能使用小于号（&lt;）和大于号（&gt;），这是因为浏览器会误认为它们是标签。如果希望正确地显示预留字符，我们必须在 HTML 源代码中使用字符实体。 如需显示小于号，我们必须这样写：&amp;lt; 或 &amp;#60; 或 &amp;#060; 2. 不间断空格HTML 中的常用字符实体是不间断空格(&nbsp;)。浏览器总是会截短 HTML 页面中的空格。如果您在文本中写 10 个空格，在显示该页面之前，浏览器会删除它们中的 9 个。如需在页面中增加空格的数量，需要使用 &nbsp; 字符实体。 3. HTML字符实体实体名称对大小写敏感。 显示结果 描述 实体名称 实体编号 空格 &amp;nbsp; &amp;#160; &lt; 小于号 &amp;lt; &amp;#60; &gt; 大于号 &amp;gt; &amp;#62; &amp; 和号 &amp;amp; &amp;#38; &quot; 引号 &amp;quot; &amp;#34; ' 撇号 &amp;apos; (IE不支持) \\￠ 分 &amp;cent; &amp;#162; \\£ 镑 &amp;pound; &amp;#163; \\¥ 人民币/日元 &amp;yen; &amp;#165; \\€ 欧元 &amp;euro; &amp;#8364; \\§ 小节 &amp;sect; &amp;#167; \\© 版权 &amp;copy; &amp;#169; \\® 注册商标 &amp;reg; &amp;#174; \\™ 商标 &amp;trade; &amp;#8482; \\× 乘号 &amp;times; &amp;#215; \\÷ 除号 &amp;divide; &amp;#247; HTML URLURL 是一个网页地址。 URL可以由字母组成，如”runoob.com”，或互联网协议（IP）地址： 192.68.20.50。大多数人进入网站使用网站域名来访问，因为 名字比数字更容易记住。 1. URL - 统一资源定位器Web浏览器通过URL从Web服务器请求页面。当您点击 HTML 页面中的某个链接时，对应的 &lt;a&gt; 标签指向万维网上的一个地址。一个统一资源定位器(URL) 用于定位万维网上的文档。URL 只能使用 ASCII 字符集。 一个网页地址语法规则: scheme://host.domain:port/path/filename scheme - 定义因特网服务的类型。最常见的类型是 http host - 定义域主机（http 的默认主机是 www） domain - 定义因特网域名，比如 runoob.com :port - 定义主机上的端口号（http 的默认端口号是 80） path - 定义服务器上的路径（如果省略，则文档必须位于网站的根目录中）。 filename - 定义文档/资源的名称 2. 常见的 URL Scheme以下是一些URL scheme： Scheme 访问 用途 http 超文本传输协议 以 http:// 开头的普通网页。不加密。 https 安全超文本传输协议 安全网页，加密所有信息交换。 ftp 文件传输协议 用于将文件下载或上传至网站。 file 您计算机上的文件。 总结以上教程已教你如何使用 HTML 制作页面。HTML 是一种在 Web 上使用的通用标记语言。HTML 允许你格式化文本，添加图片，创建链接、输入表单、框架和表格等等，并可将之存为文本文件，浏览器即可读取和显示。HTML 的关键是标签，其作用是指示将出现的内容。 那么学完HTML，接下来该学习什么呢？ 1. 学习 CSSCSS被用来同时控制多重网页的样式和布局。通过使用 CSS，所有的格式化均可从 HTML 中剥离出来，并存储于一个独立的文件中。如需学习如何创建样式表，请访问我们的 CSS 教程 。 2. 站点服务器在自己的服务器上托管网站始终是一个选项。有几点需要考虑： 硬件支出如果要运行”真正”的网站，您不得不购买强大的服务器硬件。不要指望低价的 PC 能够应付这些工作。您还需要稳定的（一天 24 小时）高速连接。 软件支出请记住，服务器授权通常比客户端授权更昂贵。同时请注意，服务器授权也许有用户数量限制。 人工费不要指望低廉的人工费用。您必须安装自己的硬件和软件。您同时要处理漏洞和病毒，以确保您的服务器时刻正常地运行于一个”任何事都可能发生”的环境中。 3. 使用因特网服务提供商（ISP）从 ISP 租用服务器也很常见。大多数小公司会把网站存放到由 ISP 提供的服务器上。其优势有以下几点： 连接速度大多数 ISP 都拥有连接因特网的高速连接。 强大的硬件ISP 的 web 服务器通常强大到能够由若干网站分享资源。您还要看一下 ISP 是否提供高效的负载平衡，以及必要的备份服务器。 安全性和可靠性ISP 是网站托管方面的专家。他们应该提供 99% 以上的在线时间，最新的软件补丁，以及最好的病毒防护。 4. 选择 ISP 时的注意事项24 小时支持确保 ISP 提供 24 小时支持。不要使自己置于无法解决严重问题的尴尬境地，同时还必须等待第二个工作日。如果您不希望支付长途电话费，那么免费电话服务也是必要的。 每日备份确保 ISP 会执行每日备份的例行工作，否则您有可能损失有价值的数据。 流量研究一下 ISP 的流量限制。如果出现由于网站受欢迎而激增的不可预期的访问量，那么您要确保不会因此支付额外费用。 带宽或内容限制研究一下 ISP 的带宽和内容限制。如果您计划发布图片或播出视频或音频，请确保您有此权限。 E-mail 功能请确保 ISP 支持您需要的 e-mail 功能。 数据库访问如果您计划使用网站数据库中的数据，那么请确保您的 ISP 支持您需要的数据库访问。在您选取一家 ISP 之前，请务必阅读菜鸟教程的 Web 主机教程。","link":"/2021/12/31/HTML%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"HTML笔记（二）","text":"HTML CSS HTML 图像 HTML 表格 HTML 列表 HTML 区块 HTML 布局 HTML 表单 HTML CSSCSS (Cascading Style Sheets) 用于渲染HTML元素标签的样式。 1. 如何使用CSSCSS 是在 HTML 4 开始使用的,目的是为更好的渲染HTML元素。CSS 可以通过以下方式添加到HTML中: 内联样式- 在HTML元素中使用”style” 属性 内部样式表 -在HTML文档头部 &lt;head&gt; 区域使用&lt;style&gt; 元素 来包含CSS 外部引用 - 使用外部 CSS 文件 最好的方式是通过外部引用CSS文件。 2. 内联样式当特殊的样式需要应用到个别元素时，就可以使用内联样式。 使用内联样式的方法是在相关的标签中使用样式属性。样式属性可以包含任何 CSS 属性。如显示出如何改变段落的颜色和左外边距： &lt;p style=”color:blue;margin-left:20px;” &gt;这是一个段落。&lt;/p&gt; 3. 内部样式表当单个文件需要特别样式时，就可以使用内部样式表。你可以在&lt;head&gt; 部分通过 &lt;style&gt;标签定义内部样式表: &lt;head&gt;&lt;style type=”text/css” &gt;body {background-color:yellow;}p {color:blue;}&lt;/style&gt;&lt;/head&gt; 4. 外部样式表当样式需要被应用到很多页面的时候，外部样式表将是理想的选择。使用外部样式表，你就可以通过更改一个文件来改变整个站点的外观。 &lt;head&gt;&lt;link rel=”stylesheet” type=”text/css” href=”mystyle.css” &gt;&lt;/head&gt; HTML 图像 1. HTML 图像-图像标签&lt;img&gt;和源属性Src在 HTML 中，图像由&lt;img&gt; 标签定义。&lt;img&gt; 是空标签，它只包含属性，且没有闭合标签。 要在页面上显示图像，你需要使用源属性src。源属性的值是图像的 URL 地址。 定义图像的语法如： &lt;img src=”url” alt=”some_text” &gt;URL 指存储图像的位置。如果名为 “pulpit.jpg” 的图像位于 www.runoob.com 的 images 目录中，那么其 URL 为 http://www.runoob.com/images/pulpit.jpg。浏览器将图像显示在文档中图像标签出现的地方。如果你将图像标签置于两个段落之间，那么浏览器会首先显示第一个段落，然后显示图片，最后显示第二段。 2. HTML 图像-Alt属性alt 属性用来为图像定义一串预备的可替换的文本。替换文本属性的值是用户定义的。如： &lt;img src=”boat.gif” alt=”Big Boat” &gt; 在浏览器无法载入图像时，替换文本属性告诉读者她们失去的信息。此时，浏览器将显示这个替代性的文本而不是图像。为页面上的图像都加上替换文本属性是个好习惯，这样有助于更好的显示信息，并且对于那些使用纯文本浏览器的人来说是非常有用的。 3. HTML 图像-高度与宽度height 与 width 属性用于设置图像的高度与宽度。属性值默认单位为像素，如: &lt;img src=”pulpit.jpg” alt=”Pulpit rock” width=”304” height=”228” &gt; 指定图像的高度和宽度是一个很好的习惯。如果图像指定了高度宽度，页面加载时就会保留指定的尺寸。如果没有指定图片的大小，加载页面时有可能会破坏HTML页面的整体布局。另外，加载图片是需要时间的，所以要慎用图片。 HTML 表格表格由 &lt;table&gt; 标签来定义。每个表格均有若干行（由 &lt;tr&gt; 标签定义），每行被分割为若干单元格（由 &lt;td&gt; 标签定义）。字母 td 指表格数据（table data），即数据单元格的内容。数据单元格可以包含文本、图片、列表、段落、表单、水平线、表格等等。 1. HTML 表格和边框属性如果不定义边框属性，表格将不显示边框。有时这很有用，但是大多数时候，我们希望显示边框。使用边框属性来显示一个带有边框的表格： &lt;table border=”1” &gt; &lt;tr&gt; &lt;td&gt;Row 1, cell 1&lt;/td&gt; &lt;td&gt;Row 1, cell 2&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; 2. HTML 表格表头表格的表头使用 &lt;th&gt; 标签进行定义。大多数浏览器会把表头显示为粗体居中的文本： &lt;table border=”1” &gt; &lt;tr&gt; &lt;th&gt;Header 1&lt;/th&gt; &lt;th&gt;Header 2&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;row 1, cell 1&lt;/td&gt; &lt;td&gt;row 1, cell 2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;row 2, cell 1&lt;/td&gt; &lt;td&gt;row 2, cell 2&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; 3. HTML 表格标签 &lt;table&gt; 定义表格 &lt;th&gt; 定义表格的表头 &lt;tr&gt; 定义表格的行 &lt;td&gt; 定义表格单元 &lt;caption&gt; 定义表格标题 &lt;colgroup&gt; 定义表格列的组 &lt;col&gt; 定义用于表格列的属性 &lt;thead&gt; 定义表格的页眉 &lt;tbody&gt; 定义表格的主体 &lt;tfoot&gt; 定义表格的页脚 HTML 列表HTML 支持有序、无序和定义列表: 有序列表如: 第一个列表项 第二个列表项 第三个列表项 无序列表如： 列表项 列表项 列表项 1. HTML 无序列表无序列表是一个项目的列表，此列项目使用粗体圆点进行标记。无序列表使用 &lt;ul&gt; 标签，如： &lt;ul&gt;&lt;li&gt;Coffee&lt;/li&gt;&lt;li&gt;Milk&lt;/li&gt;&lt;/ul&gt; 2. HTML 有序列表同样，有序列表也是一列项目，列表项目使用数字进行标记。 有序列表始于 &lt;ol&gt; 标签。每个列表项始于 &lt;li&gt; 标签。列表项使用数字来标记。 &lt;ol&gt;&lt;li&gt;Coffee&lt;/li&gt;&lt;li&gt;Milk&lt;/li&gt;&lt;/ol&gt; 3. HTML 自定义列表自定义列表不仅仅是一列项目，而是项目及其注释的组合。自定义列表以 &lt;dl&gt; 标签开始。每个自定义列表项以 &lt;dt&gt; 开始。每个自定义列表项的定义以 &lt;dd&gt; 开始。 &lt;dl&gt;&lt;dt&gt;Coffee&lt;/dt&gt;&lt;dd&gt;- black hot drink&lt;/dd&gt;&lt;dt&gt;Milk&lt;/dt&gt;&lt;dd&gt;- white cold drink&lt;/dd&gt;&lt;/dl&gt; 4. HTML 列表标签&lt;ol&gt; 定义有序列表&lt;ul&gt; 定义无序列表&lt;li&gt; 定义列表项&lt;dl&gt; 定义列表&lt;dt&gt; 自定义列表项目&lt;dd&gt; 定义自定列表项的描述 HTML 区块HTML 可以通过 &lt;div&gt; 和 &lt;span&gt;将元素组合起来。 1. HTML 区块元素大多数 HTML 元素被定义为块级元素或内联元素。块级元素在浏览器显示时，通常会以新行来开始（和结束）。实例: &lt;h1&gt;, &lt;p&gt;, &lt;ul&gt;, &lt;table&gt; 2. HTML 内联元素内联元素在显示时通常不会以新行开始。实例: &lt;b&gt;, &lt;td&gt;, &lt;a&gt;, &lt;img&gt; 3. HTML &lt;div&gt; 元素HTML &lt;div&gt; 元素是块级元素，它可用于组合其他 HTML 元素的容器。&lt;div&gt; 元素没有特定的含义。除此之外，由于它属于块级元素，浏览器会在其前后显示折行。如果与 CSS 一同使用， 元素可用于对大的内容块设置样式属性。 元素的另一个常见的用途是文档布局。它取代了使用表格定义布局的老式方法。使用 \\ 元素进行文档布局不是表格的正确用法。\\ 元素的作用是显示表格化的数据。 4. HTML &lt;span&gt; 元素HTML &lt;span&gt; 元素是内联元素，可用作文本的容器。&lt;span&gt; 元素也没有特定的含义。当与 CSS 一同使用时，&lt;span&gt; 元素可用于为部分文本设置样式属性。 HTML 布局网页布局对改善网站的外观非常重要，要慎重设计您的网页布局。 1. 网站布局大多数网站会把内容安排到多个列中（就像杂志或报纸那样）。大多数网站可以使用 &lt;div&gt; 或者 &lt;table&gt; 元素来创建多列。CSS 用于对元素进行定位，或者为页面创建背景以及色彩丰富的外观。注意，虽然我们可以使用HTML的table标签来设计出漂亮的布局，但是table标签是不建议作为布局工具使用的，表格不是布局工具。 2. 使用&lt;div&gt; 元素div 元素是用于分组 HTML 元素的块级元素。 下面的例子使用五个 div 元素来创建多列布局： &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=”utf-8”&gt;&lt;title&gt;Lamber的博客(lamber1123.github.io)&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=”container” style=”width:500px”&gt;&lt;div id=”header” style=”background-color:#FFA500;”&gt;&lt;h1 style=”margin-bottom:0;”&gt;主要的网页标题&lt;/h1&gt;&lt;/div&gt;&lt;div id=”menu” style=”background-color:#FFD700;height:200px;width:100px;float:left;”&gt;&lt;b&gt;菜单&lt;/b&gt;&lt;br&gt;HTML&lt;br&gt;CSS&lt;br&gt;JavaScript&lt;/div&gt;&lt;div id=”content” style=”background-color:#EEEEEE;height:200px;width:400px;float:left;”&gt;内容在这里&lt;/div&gt;&lt;div id=”footer” style=”background-color:#FFA500;clear:both;text-align:center;”&gt;版权 Lamber&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 效果图如下： 3. 使用&lt;table&gt; 元素使用 HTML &lt;table&gt; 标签是创建布局的一种简单的方式。大多数站点可以使用 &lt;div&gt; 或者 &lt;table&gt; 元素来创建多列。CSS 用于对元素进行定位，或者为页面创建背景以及色彩丰富的外观。 &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=”utf-8”&gt;&lt;title&gt;Lamber的博客(lamber1123.github.io)&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;table width=”500” border=”0”&gt;&lt;tr&gt;&lt;td colspan=”2” style=”background-color:#81c7db;”&gt;&lt;h1&gt;主要的网页标题&lt;/h1&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=”background-color:#00cdff;width:100px;”&gt;&lt;b&gt;菜单&lt;/b&gt;&lt;br&gt;HTML&lt;br&gt;CSS&lt;br&gt;JavaScript&lt;/td&gt;&lt;td style=”background-color:#eeeeee;height:200px;width:400px;”&gt;内容在这里&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=”2” style=”background-color:#81c7db;text-align:center;”&gt;版权 Lamber&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 效果图如下： 4. 更好的布局选择使用 CSS 最大的好处是，如果把 CSS 代码存放到外部样式表中，那么站点会更易于维护。通过编辑单一的文件，就可以改变所有页面的布局。 由于创建高级的布局非常耗时，使用模板是一个快速的选项。通过搜索引擎可以找到很多免费的网站模板。 HTML 表单HTML 表单用于收集不同类型的用户输入。 &lt;form action=””&gt;Username: &lt;input type=”text” name=”user”&gt;&lt;br&gt;Password: &lt;input type=”password” name=”password”&gt;&lt;/form&gt; 其中密码会隐藏成黑圆点，效果如下： 1. 表单的使用表单是一个包含表单元素的区域。表单元素是允许用户在表单中输入内容,比如：文本域(textarea)、下拉列表、单选框(radio-buttons)、复选框(checkboxes)等等。表单使用表单标签 &lt;form&gt; 来设置: &lt;form&gt;…input 元素…&lt;/form&gt; 2. 文本 type-text多数情况下被用到的表单标签是输入标签（&lt;input&gt;）。输入类型是由类型属性（type）定义的，如文本域（text）。 文本域通过&lt;input type=”text”&gt; 标签来设定，当用户要在表单中键入字母、数字等内容时，就会用到文本域。但是表单本身并不可见。同时，在大多数浏览器中，文本域的默认宽度是 20 个字符。 &lt;form&gt;First name: &lt;input type=”text” name=”firstname”&gt;&lt;br&gt;Last name: &lt;input type=”text” name=”lastname”&gt;&lt;/form&gt; 浏览器显示效果如下: First name: Last name: 3. 密码 type-password密码字段通过标签 来定义。密码字段字符不会明文显示，而是以星号或圆点替代。 &lt;form&gt;Password: &lt;input type=”password” name=”pwd”&gt;&lt;/form&gt; 浏览器显示效果如下: Password: 4. 单选按钮 type-radio&lt;input type=”radio”&gt; 标签定义了表单单选框选项 &lt;form&gt;&lt;input type=”radio” name=”sex” value=”male”&gt;Male&lt;br&gt;&lt;input type=”radio” name=”sex” value=”female”&gt;Female&lt;/form&gt; 浏览器显示效果如下: Male Female 5. 复选框 type-radio &lt;input type=”checkbox”&gt; 定义了复选框. 用户需要从若干给定的选择中选取一个或若干选项。 &lt;form&gt;&lt;input type=”checkbox” name=”vehicle” value=”Bike”&gt;I have a bike&lt;br&gt;&lt;input type=”checkbox” name=”vehicle” value=”Car”&gt;I have a car&lt;/form&gt; 浏览器显示效果如下: I have a bike I have a car 6. 提交按钮 type-submit&lt;input type=”submit”&gt; 定义了提交按钮. 当用户单击确认按钮时，表单的内容会被传送到另一个文件。表单的动作属性定义了目的文件的文件名。由动作属性定义的这个文件通常会对接收到的输入数据进行相关的处理： &lt;form name=”input” action=”html_form_action.php” method=”get”&gt;Username: &lt;input type=”text” name=”user”&gt;&lt;input type=”submit” value=”Submit”&gt;&lt;/form&gt; 浏览器显示效果如下: Username: 7. HTML 表单标签 &lt;form&gt; 定义供用户输入的表单 &lt;input&gt; 定义输入域 &lt;textarea&gt; 定义文本域 (一个多行的输入控件) &lt;label&gt; 定义了 &lt;input&gt; 元素的标签，一般为输入标题 &lt;fieldset&gt; 定义了一组相关的表单元素，并使用外框包含起来 &lt;legend&gt; 定义了 &lt;fieldset&gt; 元素的标题 &lt;select&gt; 定义了下拉选项列表 &lt;optgroup&gt; 定义选项组 &lt;option&gt; 定义下拉列表中的选项 &lt;button&gt; 定义一个点击按钮 &lt;datalist&gt; 指定一个预先定义的输入控件选项列表 &lt;keygen&gt; 定义了表单的密钥对生成器字段 &lt;output&gt; 定义一个计算结果","link":"/2021/12/30/HTML%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"JS笔记（一）","text":"什么是 JavaScript? HTML 中的 JavaScript 语言基础 第 1 章 什么是 JavaScript ？JavaScript 是互联网上最流行的脚本语言，这门语言可用于 HTML 和 web，更可广泛用于服务器、PC、笔记本电脑、平板电脑和智能手机等设备。所有现代的 HTML 页面都使用 JavaScript。 为什么学习 JavaScript? JavaScript 是 web 开发人员必须学习的 3 门语言中的一门： HTML 定义了网页的内容 CSS 描述了网页的布局 JavaScript 控制了网页的行为 JavaScript 是一种轻量级的编程语言，是可插入 HTML 页面的编程代码。插入 HTML 页面后，可由所有的现代浏览器执行。JavaScript 可以做到： 直接写入 HTML 输出流 对事件的反应 改变 HTML 内容 改变 HTML 图像 能够改变任意 HTML 元素的大多数属性，而不仅仅是图片。 改变 HTML 样式 验证输入 完整的 JavaScript 由三部分组成： 核心（ECMAScript） 文档对象模型（DOM） 浏览器对象模型（BOM） 1.1 ECMAScriptECMAScript即ECMA-262定义的语言，他描述了这门语言的： 语法 类型： 语句： 关键字： 保留字： 操作符： 全局对象 1.2 DOM文档对象模型 DOM 是一个应用编程接口，用于在 HTML 中使用扩展的 XML。 DOM 将整个页面抽象为一组分层节点。使用 DOM 可以轻松的控制网页的内容结构，以及创建、删除、修改节点。 1.3 BOM浏览器对象模型 BOM 的 API，用于支持访问和操作浏览器的窗口。使用 DOM，开发者可以操控浏览器显示页面以外的部分。 第 2 章 HTML 中的 JavaScript将 JavaScript 引入网页，首先要解决它与网页的主导语言 HTML 的关系问题。 2.1 &lt;script&gt; 元素将 JavaScript 插入 HTML 的主要办法是使用 &lt;script&gt; 元素。HTML 中的脚本必须位于 &lt;script&gt; 与 &lt;/script&gt; 标签之间。脚本可被放置在 HTML 页面的 &lt;body&gt; 和 &lt;head&gt; 部分中。 &lt;script&gt;&nbsp;&nbsp;&nbsp;&nbsp;function sayHi() {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.log(“Hello,world!”);&nbsp;&nbsp;&nbsp;&nbsp;}&lt;/script&gt; 2.1.1 src 属性要包含外部文件的 JavaScript，就必须使用 src 属性。属性值是一个 URL，指向包含 JavaScript 的代码文件，如： &lt;script src=”example.js”&gt;&lt;/script&gt; 如果使用了 src 属性，那么 script 标签内不要再加别的内容，加上的内容会被忽略。其中 script 标签可以包含外域的 URL，如： &lt;script src=”http://www.somewhere.com/example.js&quot; &gt;&lt;/script&gt; 2.1.2 推迟执行脚本设置 &lt;script&gt; 的 defer 属性，表示脚本在执行的时候不会改变页面结构。也就是说，脚本会被延迟到整个页面都被解析完毕后再运行。如： &lt;script defer src=”example1.js”&gt;&lt;/script&gt;&lt;script defer src=”example2.js”&gt;&lt;/script&gt; 2.1.3 异步执行脚本&lt;script&gt;元素定义了 async 属性。从改变脚本处理方式上看，async 属性与 defer 类似。当然，它们两者也都只适用于外部脚本，都会告诉浏览器立即开始下载。不过，与 defer 不同的是，标记为 async 的脚本并不保证能按照它们出现的次序执行。如下面这个例子，第二个脚本可能先于第一个脚本执行。因此它们之间没有依赖关系。 &lt;script async src=”example1.js”&gt;&lt;/script&gt;&lt;script async src=”example2.js”&gt;&lt;/script&gt; 2.1.4 动态加载脚本除了&lt;script&gt;标签，还有其他方式可以加载脚本。因为 JavaScript 可以使用 DOM API，所以通过向 DOM 中动态添加 script 元素同样可以加载指定的脚本。只要创建一个 script 元素并将其添加到DOM 即可。 let script = document.createElement(‘script’);script.src = ‘gibberish.js’;script.async = false;document.head.appendChild(script); 2.2 行内代码与外部文件推荐使用外部文件，理由如下： 可维护性。JavaScript 代码如果分散到很多 HTML 页面，会导致维护困难。而用一个目录保存所有 JavaScript 文件，则更容易维护，这样开发者就可以独立于使用它们的 HTML 页面来编辑代码。 缓存。浏览器会根据特定的设置缓存所有外部链接的 JavaScript 文件，这意味着如果两个页面都用到同一个文件，则该文件只需下载一次。这最终意味着页面加载更快。 适应未来。通过把 JavaScript 放到外部文件中，就不必考虑用 XHTML 或前面提到的注释黑科技。包含外部 JavaScript 文件的语法在 HTML 和 XHTML 中是一样的 2.3 文档模式指混杂模式与标准模式。 2.4 &lt;noscript&gt; 元素针对早期浏览器不支持 JavaScript 的问题，需要一个页面优雅降级的处理方案。最终，&lt;noscript&gt;元素出现，被用于给不支持 JavaScript 的浏览器提供替代内容。虽然如今的浏览器已经 100%支持JavaScript，但对于禁用 JavaScript 的浏览器来说，这个元素仍然有它的用处。&lt;noscript&gt; 元素可以包含任何可以出现在&lt;body&gt;中的 HTML 元素，&lt;script&gt;除外。在下列两种情况下，浏览器将显示包含在&lt;noscript&gt;中的内容： 浏览器不支持脚本； 浏览器对脚本的支持被关闭。 如下面这段代码，如果浏览器支持脚本，则用户永远不会看到它： &lt;noscript&gt; &lt;p&gt;This page requires a JavaScript-enabled browser.&lt;/p&gt;&lt;/noscript&gt; 第 3 章 语言基础 语法 数据类型 流控制语句 理解函数 3.1 语法ECMAScript 的语法很大程度上借鉴了 C 语言和其他类 C 语言，如 Java 和 Perl。 3.1.1 区分大小写 3.1.2 标识符 第一个字符必须是一个字母、下划线或美元符号。 剩下的其他字符可以是字母、下划线、美元符号或数字。 3.1.4 严格模式ECMAScript 5 增加了严格模式（strict mode）的概念。严格模式是一种不同的 JavaScript 解析和执行模型，ECMAScript 3 的一些不规范写法在这种模式下会被处理，对于不安全的活动将抛出错误。 启用严格模式，在脚本开头加上这一行： “use strict”; 也可以单独指定一个函数在严格模式下执行，只要把这个预处理指令放到函数体开头即可： function doSomething() {&nbsp;&nbsp;&nbsp;&nbsp;”use strict”;&nbsp;&nbsp;&nbsp;&nbsp;// 函数体} 3.1.5 语句ECMAScript 中的语句以分号结尾。包含多条语句的代码块用花括号括起来。 3.2 关键字与保留字关键字如下：break do in typeofcase else instanceof varcatch export new voidclass extends return whileconst finally super withcontinue for switch yielddebugger function thisdefault if throwdelete import try 始终保留：enum 严格模式下保留：implements package publicinterface protected staticlet private 模块代码中保留：await 这些词汇不能用作标识符，不要使用关键字和保留字作为标识符和属性名。 3.3 变量ECMAScript 变量是松散类型的，意思是变量可以用于保存任何类型的数据。有 3 个关键字可以声明变量：var、const 和 let。其中，var 在ECMAScript 的所有版本中都可以使用，而 const 和 let 只能在 ECMAScript 6 及更晚的版本中使用。 3.3.1 var 关键字要定义变量，可以使用 var 操作符： var message; 这行代码定义了一个名为 message 的变量，可以用它保存任何类型的值。不初始化的情况下，变量会保存一个特殊值 undefined。 var message = “hi”; var 声明作用域，意味着该变量将在函数退出时被销毁。但是在函数内定义变量时省略 var 操作符，可以创建一个全局变量。 function test() {&nbsp;&nbsp;&nbsp;&nbsp;message = “hi”; // 全局变量} 3.3.2 let 声明let 跟 var 的作用差不多，但有着非常重要的区别。最明显的区别是，let 声明的范围是块作用域，而 var 声明的范围是函数作用域。 对声明冗余报错不会因混用 let 和 var 而受影响。这两个关键字声明的并不是不同类型的变量，它们只是指出变量在相关作用域如何存在。 3.3.3 const 声明const 的行为与 let 基本相同，唯一一个重要的区别是用它声明变量时必须同时初始化变量，且尝试修改 const 声明的变量会导致运行时错误。 const age = 26;age = 36; // TypeError: 给常量赋值 3.3.4 声明风格及最佳实践1.不使用 var 有了 let 和 const，大多数开发者会发现自己不再需要 var 了。限制自己只使用 let 和 const 有助于提升代码质量，因为变量有了明确的作用域、声明位置，以及不变的值。 2.const 优先，let 次之 使用 const 声明可以让浏览器运行时强制保持变量不变，也可以让静态代码分析工具提前发现不合法的赋值操作。因此，很多开发者认为应该优先使用 const 来声明变量，只在提前知道未来会有修改时，再使用 let。这样可以让开发者更有信心地推断某些变量的值永远不会变，同时也能迅速发现因意外赋值导致的非预期行为。 3.4 数据类型ECMAScript 有 6 种简单数据类型（也称为原始类型），还有一种复杂数据类型叫 Object。 3.4.1 typeof 操作符需要一种手段来确定任意变量的数据类型。 “undefined”表示值未定义； “boolean”表示值为布尔值； “string”表示值为字符串； “number”表示值为数值； “object”表示值为对象（而不是函数）或 null； “function”表示值为函数； “symbol”表示值为符号。 下面是使用 typeof 操作符的例子： let message = “some string”;console.log(typeof message); // “string”console.log(typeof(message)); // “string”console.log(typeof 95); // “number” 3.4.2 Undefined 类型Undefined 类型只有一个值，就是特殊值 undefined。当使用 var 或 let 声明了变量但没有初始化时，就相当于给变量赋予了 undefined 值。 3.4.3 Null 类型Null 类型同样只有一个值，即特殊值 null。逻辑上讲，null 值表示一个空对象指针，这也是给typeof 传一个 null 会返回”object”的原因。 在定义将来要保存对象值的变量时，建议使用 null 来初始化，不要使用其他值。这样，只要检查这个变量的值是不是 null 就可以知道这个变量是否在后来被重新赋予了一个对象的引用。 3.4.4 Boolean 类型Boolean（布尔值）类型是 ECMAScript 中使用最频繁的类型之一，有两个字面值：true 和 false。 let found = true;let lost = false; 所有其他 ECMAScript 类型的值都有相应布尔值的等价形式。要将一个其他类型的值转换为布尔值，可以调用特定的 **Boolean()**转型函数： let message = “Hello world!”;let messageAsBoolean = Boolean(message); 下表总结了不同类型与布尔值之间的转换规则。 数据类型 转换为 true 的值 转换为 false 的值 Boolean true false String 非空字符串 “”（空字符串） Number 非零数值（包括无穷值） 0、NaN（参见后面的相关内容） Object 任意对象 null Undefined N/A（不存在） undefined 3.4.5 Number 类型最基本的数值字面量格式是十进制整数，直接写出来即可： let intNum = 55; // 整数 要定义浮点值，数值中必须包含小数点，而且小数点后面必须至少有一个数字。在小数点后面没有数字的情况下，数值就会变成整数。 let floatNum1 = 1.1;let floatNum2 = 0.1;let floatNum3 = .1; // 有效，但不推荐 ECMAScript 可以表示的最小数值保存在 Number.MIN_VALUE 中，可以表示的最大数值保存在 Number.MAX_VALUE 中。 如果某个计算得到的数值结果超出了 JavaScript 可以表示的范围，那么这个数值会被自动转换为一个特殊的 Infinity（无穷）值。 要确定一个值是不是有限大（即介于 JavaScript 能表示的最小值和最大值之间），可以使用 **isFinite()**函数，如下所示： let result = Number.MAX_VALUE + Number.MAX_VALUE;console.log(isFinite(result)); // false 有一个特殊的数值叫 NaN，意思是“不是数值”（Not a Number），用于表示本来要返回数值的操作失败了，为此，ECMAScript 提供了 **isNaN()**函数。 console.log(isNaN(NaN)); // trueconsole.log(isNaN(10)); // false，10 是数值console.log(isNaN(“10”)); // false，可以转换为数值 10console.log(isNaN(“blue”)); // true，不可以转换为数值console.log(isNaN(true)); // false，可以转换为数值 1 有 3 个函数可以将非数值转换为数值：Number()、parseInt()和 parseFloat()。Number()是转型函数，可用于任何数据类型。后两个函数主要用于将字符串转换为数值。 3.4.6 String 类型String（字符串）数据类型表示零或多个 16 位 Unicode 字符序列。字符串可以使用双引号（”）、单引号（’）或反引号（`）标示。 字符串的长度可以通过其 length 属性获取：console.log(text.length); // 28 ECMAScript 中的字符串是不可变的，要想修改必须先销毁原始的字符串。 let lang = “Java”;lang = lang + “Script”; 有两种方式把一个值转换为字符串。首先是使用几乎所有值都有的 **toString()**方法。通过传入参数，可以得到数值的二进制、八进制、十六进制。 let num = 10;console.log(num.toString()); // “10”console.log(num.toString(2)); // “1010”console.log(num.toString(8)); // “12”console.log(num.toString(10)); // “10”console.log(num.toString(16)); // “a” 3.4.7 Symbol 类Symbol（符号）是 ECMAScript 6 新增的数据类型。符号是原始值，且符号实例是唯一、不可变的。 let sym = Symbol();console.log(typeof sym); // symbol 3.4.8 Object 类型ECMAScript 中的对象其实就是一组数据和功能的集合。 let o = new Object(); 每个 Object 实例都有如下属性和方法： constructor：用于创建当前对象的函数。在前面的例子中，这个属性的值就是 Object() 函数。 hasOwnProperty(propertyName)：用于判断当前对象实例（不是原型）上是否存在给定的属性。要检查的属性名必须是字符串（如 o.hasOwnProperty(“name”)）或符号。 isPrototypeOf(object)：用于判断当前对象是否为另一个对象的原型。 propertyIsEnumerable(propertyName)：用于判断给定的属性是否可以使用（本章稍后讨论的）for-in 语句枚举。与 hasOwnProperty()一样，属性名必须是字符串。 toLocaleString()：返回对象的字符串表示，该字符串反映对象所在的本地化执行环境。 toString()：返回对象的字符串表示。 valueOf()：返回对象对应的字符串、数值或布尔值表示。通常与 toString()的返回值相同。 3.5 操作符包括数学操作符（如加、减）、位操作符、关系操作符和相等操作符等。 3.5.1 一元操作符 递增/递减操作符 一元加和减 3.5.2 位操作符 按位非 let num2 = ~num1; 按位 let result = 25 &amp; 3; 按位或 let result = 25 | 3; 按位异或 let result = 25 ^ 3; 左移 let newValue = oldValue &lt;&lt; 5; 有符号右移 let newValue = oldValue &gt;&gt; 5; 无符号右移 let newValue = oldValue &gt;&gt;&gt; 5; 3.5.3 布尔操作符 逻辑非 console.log(!false); // true 逻辑与 let result = true &amp;&amp; false; 逻辑或 let result = true || false; 3.5.4 乘性操作符 乘法操作符 除法操作符 取模操作符 3.5.5 指数操作符console.log(3 ** 2); // 9 3.5.6 加性操作符要注意如果两个操作数都是字符串，则将第二个字符串拼接到第一个字符串后面。 let result2 = 5 + “5”; // “55” 3.5.7 关系操作符包括小于（&lt;）、大于（&gt;）、小于等于（&lt;=）和大于等于（&gt;=）。 let result1 = 5 &gt; 3; // truelet result2 = 5 &lt; 3; // false 3.5.8 相等操作符 等于和不等于 全等和不全等 let result1 = (“55” == 55); // true，转换后相等let result2 = (“55” === 55); // false，不相等，因为数据类型不同 3.5.9 条件操作符条件操作符是 ECMAScript 中用途最为广泛的操作符之一，语法如下：**variable = boolean_expression ? true_value : false_value;**、 比如： let max = (num1 &gt; num2) ? num1 : num2; 3.5.10 赋值操作符如：let num = 10;num += 10; 3.5.11 逗号操作符let num1 = 1, num2 = 2, num3 = 3;let num = (5, 1, 4, 8, 0); // num 的值为 0 3.6 语句 if 语句 do-while 语句 while 语句 for 语句 for-in 语句 for (property in expression) statement for-of 语句 for (property of expression) statement 标签语句 label: statement，可以在后面通过 break 或 continue 语句引用 break 和 continue 语句 后面可加标签 with 语句 with (expression) statement; switch 语句 其中对于with语句，如: with(location) {&nbsp;&nbsp;&nbsp;&nbsp;let qs = search.substring(1);&nbsp;&nbsp;&nbsp;&nbsp;let hostName = hostname;&nbsp;&nbsp;&nbsp;&nbsp;let url = href;} 3.7 函数函数形式如下: function functionName(arg0, arg1,…,argN) { statements}","link":"/2022/01/02/JS%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"JS笔记（二）","text":"变量、作用域与内存 第 4 章 变量、作用域与内存 通过变量使用原始值与引用值 理解执行上下文 理解垃圾回收 4.1 原始值与引用值原始值就是最简单的数据，引用值则是由多个值构成的对象。保存原始值的变量是按值（by value）访问的，因为我们操作的就是存储在变量中的实际值。引用值是保存在内存中的对象。 4.1.1 动态属性对于引用值而言，可以随时添加、修改和删除其属性和方法。 12345678let name1 = &quot;Nicholas&quot;; let name2 = new String(&quot;Matt&quot;); name1.age = 27; name2.age = 26; console.log(name1.age); // undefined console.log(name2.age); // 26 console.log(typeof name1); // string console.log(typeof name2); // object 4.1.2 复制值通过变量把一个原始值赋值到另一个变量时，原始值会被复制到新变量的位置。 12let num1 = 5; let num2 = num1; 在把引用值从一个变量赋给另一个变量时，这里复制的值实际上是一个指针，指向存储在堆内存中的对象。 1234let obj1 = new Object(); let obj2 = obj1; obj1.name = &quot;Nicholas&quot;; console.log(obj2.name); // &quot;Nicholas&quot; 4.1.3 传递参数变量有按值和按引用访问，而传参则只有按值传递。 123456789function addTen(num) { num += 10; return num; } let count = 20; let result = addTen(count); console.log(count); // 20，没有变化console.log(result); // 30 4.1.4 确定类型前一章提到的 typeof 操作符最适合用来判断一个变量是否为原始类型。 123456789101112let s = &quot;Nicholas&quot;; let b = true; let i = 22; let u; let n = null; let o = new Object(); console.log(typeof s); // string console.log(typeof i); // number console.log(typeof b); // boolean console.log(typeof u); // undefined console.log(typeof n); // object console.log(typeof o); // object typeof 虽然对原始值很有用，但它对引用值的用处不大。想知道它是什么类型的对象，使用instanceof 操作符 123console.log(person instanceof Object); // 变量 person 是 Object 吗？console.log(colors instanceof Array); // 变量 colors 是 Array 吗？console.log(pattern instanceof RegExp); // 变量 pattern 是 RegExp 吗？ 4.2 执行上下文与作用域执行上下文（以下简称“上下文”）的概念在 JavaScript 中是颇为重要的。变量或函数的上下文决定了它们可以访问哪些数据，以及它们的行为。 4.2.1 作用域链增强4.2.2 变量声明 4.3 垃圾回收4.3.1 标记清理4.3.2 引用计数4.3.3 性能4.3.3 性能 第 5 章 基本引用类型","link":"/2022/01/03/JS%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"TiKV 与 Raft","text":"TiKV 简介 Raft 协议 1. TiKV 简介TiKV 是一个分布式事务型的键值数据库，提供了满足 ACID 约束的分布式事务接口，并且通过 Raft 协议保证了多副本数据一致性以及高可用。TiKV 作为 TiDB 的存储层，为用户写入 TiDB 的数据提供了持久化以及读写服务，同时还存储了 TiDB 的统计信息数据。 1.1 ACID是数据库事务正确执行的四个基本要素。它们分别指： 原子性（atomicity） 一致性（consistency） 隔离性（isolation） 持久性（durability） 1.2 什么是 Raft 协议？Raft 协议是一种分布式一致性协议，相对 Paxos 协议，他更好理解。Paxos 也是一种一致性协议，它可以说是一致性协议研究的起点，也以难以理解闻名。后文将会对其进行细致的学习。 1.3 什么是 TiDB ？TiDB 是 PingCAP 公司自主设计、研发的开源分布式关系型数据库，是一款同时支持在线事务处理与在线分析处理的融合型分布式数据库产品。具备水平扩容或者缩容、金融级高可用、实时 HTAP、云原生的分布式数据库、兼容 MySQL 5.7 协议和 MySQL 生态等重要特性。 1.4 什么是分布式分布式数据库？分布式数据库（DDB）的定义是：数据分布在计算机网络的不同计算机上，网络中的每个结点具有独立处理的能力，同时，每个结点也能通过网络通信子系统执行全局应用。负责分布式数据库管理的软件，称为分布式数据库管理系统（DDBMS）其中，每个节点都有自己的操作系统。 2. Raft 协议一致性协议包括：两阶段协议协议、三阶段提交协议、Paxos协议、Raft协议等，先学习 RITF 协议。 2.1 分布一致性在单节点数据库系统中，从客户端写入一个值到服务器，只需要写入一个节点就可以了，很简单的实现了一致性。但是，企业常常采用多节点系统，如何在多系统间通信存在延迟的情况下保持一致性呢？就需要采用分布一致性协议。 2.2 Leader 选举过程Raft是分布式一致性的实现协议，那它是如何工作的呢？ Raft 定义了一个节点的3种状态： Follower state Candidate state Leader state 一开始，所有的节点都是Follower状态，我们称这些节点为Follower（跟随者）。当所有的Follower都无法感知到Leader的存在时，他们会变成candidate（参选者），candidate向其他节点发起投票，其他节点反馈投票的结果，即是否同意。如果投票获得大部分同意，则该candidate会成为leader。 如果选举可能出现多个Leader，则本次选举失效，进行下一轮选举。选举失效的检测很简单，因为它们不可能同时满足大多数原则（vote count&gt; == n/2+1）。 2.3 随即选举超时如何确保在有限的时间内确定出Leader呢？Raft提出了随即选举超时方法。这使得每个sever的timeout不同（150ms到300ms之间），这使得每一个sever不是同时开始的新一轮选举，使得新一轮选举会很快选出Leader。 2.4 日志复制Leader选出来之后，任何改变都需要通过Leader来传达。日志复制过程是： 每一次变更都会作为一个entry加入到Leader节点日志中，这时entry的状态是未提交状态（uncommitted），所以这并不会改变节点的当前值。为了能够提交entry： Leader将entry复制到所有Follower节点 leader开始等待直到大多数节点都写入成功了entry为止 leader提交entry，节点值发生变更。 leader通知所有Follower entry is committed 最后所有节点都达到了一致的状态 2.5 心跳检测当一个节点成为leader后，会间隔指定时间发送 Append Entries 消息给他的Follower，间隔时间是由心跳超时控制的（heartbeat timeout，即第二种超时类型），follower收到消息后会重置等待时间，目的是阻止Follower成为candidate。 这个过程会一直持续下去，直到一个Follower停止接收heatbeats，并且成为candidate为止。 2.6 网络分区下的一致性Raft 协议的优秀之处在于网络分区（比如节点部署在不同机房，不同网段）下仍然可以确保节点数据一致。这是如何实现的呢？ 假设有5个节点（abcde）组成的网络，a、b位于一个机房，c、d、e位于一个机房，此时的Leader是a节点。由于网络故障造成2个机房节点通信失败，位于一个机房的c、d、e发现Leader心跳不再了，则发起选举过程，设节点c获得了多数选票成为了新的Leader，此时5个节点会同时存在2 Leader（a、c）。 此时，一个客户端尝试修改a的值。由于节点a无法与c、d、e通信，在做日志复制时无法得到大多数的应答，那么这条entry将一直是uncommited状态。但是，一个客户端尝试修改节点c的值却可以获得大多数的应答，所以这次操作entry可以正常提交。 当网络故障被修复，节点a、b都会广播心跳并携带，此时节点a发现了更高的election term，则将自己降级为follower，且a、b同时需要回滚他们未提交的entry，并且匹配new Leader日志。","link":"/2022/01/06/TiKV%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"Raft算法原理","text":"简介 Raft 算法流程 集群成员变更 日志压缩 高效处理只读请求 目录 1. 简介 2. Raft 算法流程 2.1 算法概述 2.2 Raft 算法基础 2.3 leader 选举 2.4 日志复制 2.5 新 leader 与 follower 同步数据 2.6 安全性-选举限制 2.7 安全性-提交前面任期的日志条目 3. 集群成员变更 3.1 安全性 3.2 可用性-添加新节点到集群中 3.3 可用性-删除当前集群的leader节点 3.4 可用性-处理移除集群的节点 4. 日志压缩 5. 高效处理只读请求 1. 简介我写这篇笔记的目的是系统的来解析 etcd raft 库，这篇笔记是在codedump的网络日志基础之上记录的。之所以如此详细的学习Raft算法，是因为我的本科毕业设计的题目是参照Raft算法实现数据库的分布式存储。后面我还会对Raft源码解析和我对Raft的应用再做记录。 关于Raft算法，最初有两篇论文做理论支撑。一篇是《In search of an Understandable Consensus Algorithm》，这篇论文只有16页，仅对Raft做了简单的介绍，有很多的细节没有涉及到。第二篇论文是《Consensus: Bridging Theory and Practice》，在第一篇的基础上加了大量的细节描述，足足有258页之多。据codedump所说，etcd raft库的代码基本就是参照第二篇论文的所编写的。 2. Raft 算法流程2.1 算法概述Raft 算法由leader节点来处理一致性问题。leader节点接收来自客户端的请求日志数据，然后同步到集群中其它节点进行复制，当日志已经同步到超过半数以上节点的时候，leader节点再通知集群中其它节点哪些日志已经被复制成功，可以提交到Raft状态机中执行。 通过以上方式，Raft算法将要解决的一致性问题分为了以下几个子问题： leader选举：集群中必须存在一个leader节点。 日志复制：leader节点接收来自客户端的请求然后将这些请求序列化成日志数据再同步到集群中其它节点。 安全性：如果某个节点已经将一条提交过的数据输入Raft状态机执行了，那么其它节点不可能再将相同索引的另一条日志数据输入到Raft状态机中执行。 而 Raft 算法需要一直保持的几个属性： 选举安全性（Election Safety）：在一个任期内只能存在最多一个leader节点。 Leader节点上的日志为只添加（Leader Append-Only）：leader节点永远不会删除或者覆盖本节点上面的日志数据，leader节点上写日志的操作只可能是添加操作。 日志匹配性（Log Matching）：如果两个节点上的日志，在日志的某个索引上的日志数据其对应的任期号相同，那么在两个节点在这条日志之前的日志数据完全匹配。 leader完备性（Leader Completeness）：如果一条日志在某个任期被提交，那么这条日志数据在leader节点上更高任期号的日志数据中都存在。 状态机安全性（State Machine Safety）：如果某个节点已经将一条提交过的数据输入raft状态机执行了，那么其它节点不可能再将相同索引的另一条日志数据输入到raft状态机中执行。 2.2 Raft 算法基础在Raft算法中，一个集群里面的所有节点有以下三种状态： Leader：领导者，一个集群里只能存在一个Leader。 Follower：跟随者，follower是被动的，一个客户端的修改数据请求如果发送到Follower上面时，会首先由Follower重定向到Leader上， Candidate：参与者，一个节点切换到这个状态时，将开始进行一次新的选举。 每开始一次新的选举时，称为一个任期。每个任期都有一个对应的任期号Term，这是一个严格递增的整数值。 节点的状态切换状态机如下图所示： 上图中的六种状态，下文会详细展开讨论: start up：起始状态，节点刚启动的时候自动进入的是follower状态。 times out, starts election：follower在启动之后，将开启一个选举超时的定时器，当这个定时器到期时，将切换到candidate状态发起选举。 times out, new election：进入candidate 状态之后就开始进行选举，但是如果在下一次选举超时到来之前，都还没有选出一个新的leade，那么还会保持在candidate状态重新开始一次新的选举。 receives votes from majority of servers：当candidate状态的节点，收到了超过半数的节点选票，那么将切换状态成为新的leader。 discovers current leader or new term：candidate状态的节点，如果收到了来自leader的消息，或者更高任期号的消息，都表示已经有leader了，将切换回到follower状态。 discovers server with higher term：leader状态下如果收到来自更高任期号的消息，将切换到follower状态。这种情况大多数发生在有网络分区的状态下。 如果一个candidate在一次选举中赢得大多数选票，那么这个节点将在该任期中成为leader。但并不是每个任期号都有leader，比如在情况3中，可能在选举超时到来之前都没有产生一个新的leader，那么此时任期号自增并开始一次新的选举。 可见，任期号Term在Raft中更像一个逻辑时钟。根据任期号，集群可以发现哪些节点状态已过期。每个节点都会保存任期号，并在通信时带上记录的任期号。如果一个节点的任期号小于其他节点的任期号，则说明当前状态已过期，需要同步到最新任期号。如果当处于candidate或leader状态的节点发现自己的任期号小于其他节点，则主动切换至follower状态。相反，如果一个节点收到状态过期节点的消息，则拒绝这一消息。 raft节点之间通过RPC请求来互相通信，主要有以下两类RPC请求： RequestVote RPC：用于candidate状态的节点进行选举。 AppendEntries RPC：用于leader节点向其他节点复制日志数据和同步心跳。 2.3 leader 选举raft算法是使用心跳机制来触发leader选举的。 leader节点通过周期性的发送带有空数据的 AppendEntries RPC 来发送心跳请求，目的是来维持着leader节点状态。而每个follower都有一个选举超时（election timeout）定时器，如果在定时器超时前都没有收到来自leader的心跳请求，则判定集群中已经没有leader了，它将发起新一轮选举。 发起选举时，follower将递增它的任期号然后切换到candidate状态。然后通过向集群中其它节点发送 RequestVote RPC 请求来发起一次新的选举。一个节点将保持在该任期内的candidate状态下，直到以下一种情况发生： 该candidate节点收到超过半数以上集群中其它节点的选票，赢得选举并成为leader。 另一个节点成为了leader。 选举超时到来时没有任何一个节点成为leader。 对于第一种情况，如果节点收到了集群中半数以上节点的投票，那么此时candidate节点将成为新的leader。每个节点在一个任期中只有一票且优先投给自己，并遵守先到先得的原则。这就保证了，每个任期内最多只有一个节点会成为leader。当一个candidate节点赢得选举成为leader后，它将立即发送心跳消息通知其他节点以阻止发起新的选举。 对于第二种情况，当candidate节点收到了来自其它节点的 AppendEntries RPC 请求，同时请求的任期号大约等于candidate节点，说明集群中已经存在新leader了，此时candidate节点主动切换至follower状态。但是，如果该RPC请求的任期号小于candidate节点，则直接拒绝并保持candidate状态。 对于第三种情况，选举超时都没有节点赢得选举。这种情况发生在集群节点数量为偶数，同时有两个candidate节点获得的选票数量都是一样时。此时candidate节点将递增任期号并再次发起一次新的选举。这种情况有可能一直无限发生下去，所以应尽量保证节点数为奇数，并设置随机选举超时时间，其范围在150ms~300ms间。 leader选举过程伪代码如下： 12345678910111213141516171819202122232425262728293031节点启动，进入follower状态，创建一个介于150ms~300ms之间的选举超时定时器。follower状态节点主循环： 如果收到leader节点心跳： 心跳标志位 置1 如果选举超时到期： 没有收到leader节点心跳： 任期号term+1，换到candidate状态。 如果收到leader节点心跳： 心跳标志位 置0 如果收到选举消息： 如果当前没有给任何节点投票过或者消息的任期号大于当前任期号： 投票给该节点 否则： 拒绝投票给该节点candidate状态节点主循环： 向集群中其他节点发送RequestVote请求，请求中带有当前任期号term 收到AppendEntries消息： 如果该消息的任期号大于等于本节点任期号： 切换到follower状态 否则： 拒绝该消息 收到其他节点应答RequestVote消息： 如果数量超过集群半数以上，切换到leader状态 如果选举超时到期： term+1，进行下一次的选举 2.4 日志复制日志复制的流程大体如下： 每个客户端的请求都会被重定向发送给leader，这些请求最后都会被输入到Raft状态机中去执行。 leader在收到这些请求之后，会首先在自己的日志中添加一条新的日志条目。 在本地添加完日志之后，leader将向集群中其他节点发送AppendEntries RPC请求同步这个日志条目，当这个日志条目被成功复制之后，leader节点将会将这条日志输入到Raft状态机中，然后应答客户端。 Raft日志的组织形式如下: 每个日志条目包含以下属性： index：日志索引号，即图中最上方的数字，是严格递增的。 term：日志任期号，就是在每个日志条目中上方的数字，表示这条日志在哪个任期生成的。 command：日志条目中对数据进行修改的操作。 一条日志如果被leader同步到超过半数的节点，那么被称为“成功复制”，leader节点在收到半数以上节点的应答之后，就会提交该日志，此时日志这个日志条目就是“已被提交”（committed）。如果一条日志已被提交，那么在这条日志之前的所有日志条目也是已被提交的，包括之前其他任期内的leader提交的日志。如上图中索引为7的日志条目之前的所有日志都是已被提交的日志。 下图说明了日志复制的流程： 客户端发送 SET a=1 的命令到leader节点上。 leader节点在本地添加一条日志，其对应的命令为 SET a=1。这里涉及到两个索引值，committedIndex存储的最后一条提交（commit）日志的索引，appliedIndex存储的是最后一条应用到状态机中的日志索引值，一条日志只有被提交了才能应用到状态机中，因此总有 committedIndex &gt;= appliedIndex不等式成立。在这里只是添加一条日志还并没有提交，两个索引值还指向上一条日志。 leader节点向集群中其他节点广播AppendEntries消息，带上SET a=1命令。 接下来经历以下步骤： 收到 AppendEntries 请求的follower节点，同样在本地添加了一条新的日志，也还并没有提交。 follower节点向leader节点应答 AppendEntries 消息。 当leader节点收到集群半数以上节点的 AppendEntries 请求的应答消息时，认为 SET a=1 命令成功复制，可以进行提交，于是修改了本地committed日志的索引指向最新的存储SET a=1的日志，而appliedIndex还是保持着上一次的值，因为还没有应用该命令到状态机中。 当这个命令提交完成了之后，就可以提交给应用层了。 提交命令完成，给应用层说明这条命令已经提交。此时修改 appliedIndex 与 committedIndex 一致。 leader节点在下一次给follower的 AppendEntries 请求中，会带上当前最新的 committedIndex 索引值，follower收到之后同样会修改本地日志的 committedIndex 索引。 其中，7和8这两个操作并没有严格的先后顺序，谁在前在后都没关系。 leader上保存着已被提交的最大日志索引信息，这个索引值被称为“nextIndex”，在每次向follower节点发送的 AppendEntries RPC 请求中都会带上这个索引信息，这样follower节点就知道哪个日志已经被提交了，被提交的日志将会输入Raft状态机中执行。 Raft算法保持着以下两个属性，这两个属性共同作用满足前面提到的日志匹配（LogMatch）属性： 如果两个日志条目有相同的索引号和任期号，那么这两条日志存储的是同一个指令。 如果在两个不同的日志数据中，包含有相同索引和任期号的日志条目，那么在这两个不同的日志中，位于这条日志之前的日志数据是相同的。 2.5 新 leader 与 follower 同步数据在正常的情况下，follower节点和leader节点的日志一直保持一致，此时 AppendEntries RPC 请求将不会失败。但是，当leader节点宕机时日志就可能出现不一致的情况，比如在这个leader节点宕机之前同步的数据并没有得到超过半数以上节点的应答。如下图所示就是一种出现前后日志不一致的情况。 在上图中，最上面的一排数字是日志的索引，盒子中的数据是该日志对应的任期号，左边的字母表示的是a-f这几个不同的节点。图中演示了好几种节点日志与leader节点日志不一致的情况，下面说明中以二元组&lt;任期号，索引号&gt;来说明各个节点的日志数据情况： leader节点：&lt;6, 10&gt;。 a节点：&lt;6,9&gt;，缺少日志。 b节点：&lt;4,4&gt;，任期号比leader小，因此缺少日志。 c节点：&lt;6,11&gt;，任期号与leader相同，但是有比leader日志索引更大的日志，这部分日志是未提交的日志。 d节点：&lt;7,12&gt;，任期号比leader大，这部分日志是未提交的日志。 e节点：&lt;4,7&gt;，任期号与索引都比leader小，因此既缺少日志，也有未提交的日志。 f节点：&lt;3,11&gt;，任期号比leader小，所以缺少日志，而索引比leader大，这部分日志又是未提交的日志。 在Raft算法中，解决日志数据不一致的方式是Leader节点同步日志数据到follower上，覆盖follower上与leader不一致的数据。为了解决与follower节点同步日志的问题，leader节点中有两个与follower节点日志相关的记录。 nextIndex：存储的是下一次给该节点同步日志时的日志索引。 matchIndex：存储的是该节点的最大日志索引。 从以上两个索引的定义可知，在follower与leader节点之间日志复制正常的情况下，nextIndex = matchIndex + 1。但是如果出现不一致的情况，则这个等式可能不成立。所以每个leader节点被选举出来时，将做如下初始化操作： nextIndex置为leader节点最后一条日志。 matchIndex置为0。 这么做的原因在于：leader节点将从后往前探索follower节点当前存储的日志位置，而在不知道follower节点日志位置的情况下只能置空matchIndex了。 leader节点通过 AppendEntries 消息来与follower之间进行日志同步的，每次给follower带过去的日志就是以 nextIndex 来决定，其可能有两种结果： 如果follower节点的日志与这个值匹配，将返回成功；否则将返回失败，同时带上本节点当前的最大日志ID（假设这个索引为hintIndex），方便leader节点快速定位到follower的日志位置以下一次同步正确的日志数据。 而leader节点在收到返回失败的情况下，将置 nextIndex = min(hintIndex+1, 上一次append消息的索引)，再次发出添加日志请求。 以上图的几个节点为例来说明情况。 初始状态下，leader节点将存储每个folower节点的nextIndex为10，matchIndex为0。因此在成为leader节点之后首次向follower节点同步日志数据时，将复制索引位置在10以后的日志数据，同时带上日志二元组&lt;6,10&gt;告知follower节点当前leader保存的follower日志状态。 a节点：由于节点的最大日志数据二元组是&lt;6,9&gt;，正好与leader发过来的日志&lt;6,10&gt;紧挨着，因此返回复制成功。 b节点：由于节点的最大日志数据二元组是&lt;4,4&gt;，与leader发送过来的日志数据&lt;6,10&gt;不匹配，将返回失败同时带上自己最后的日志索引4（即 hintIndex=4），leader节点在收到该拒绝消息之后，将修改保存该节点的nextIndex为min(4+1, 10)=5，所以下一次leader节点将同步从索引5到10的数据给b节点。 c节点：由于节点的最大日志数据二元组是&lt;6,11&gt;，与leader发送过来的日志数据&lt;6,10&gt;不匹配，由于两者任期号相同，节点C知道自己的索引11的数据需要删除，因为这个数据没有提交成功。 d节点：由于节点的最大日志数据二元组是&lt;7,12&gt;，与leader发送过来的日志数据&lt;6,10&gt;不匹配，索引11、12的数据将被删除。 e节点：由于节点的最大日志数据二元组是&lt;4,7&gt;，与leader发送过来的日志数据&lt;6,10&gt;不匹配，将返回最后一个与节点数据一致的索引5给leader，于是leader从min(5+1,10)=6开始同步数据给节点e，最终e节点上索引6之后的数据被覆盖。 f节点：由于节点的最大日志数据二元组是&lt;3,11&gt;，与leader发送过来的日志数据&lt;6,10&gt;不匹配，将返回最后一个与节点数据一致的索引3给leader，于是leader从min(3+1,10)=4开始同步数据给节点f，最终f节点上索引4之后的数据被覆盖。 2.6 安全性-选举限制Raft 算法中，并不是所有节点都能成为leader。一个节点要成为leader，需要得到集群中半数以上节点的投票，而一个节点会投票给一个节点，其中一个充分条件是：进行选举的节点的日志，比本节点的日志更新。之所以要求这个条件，是为了保证每个当选的节点都有当前最新的数据。为了达到这个检查日志的目的，RequestVote RPC 请求中需要带上参加选举节点的日志信息，如果节点发现选举节点的日志信息并不比自己更新，将拒绝给这个节点投票。 如果判断日志的新旧？这通过对比日志的最后一个日志条目数据来决定，首先将对比条目的任期号，任期号更大的日志数据更新；如果任期号相同，那么索引号更大的数据更新。 以上处理RequestVote请求的流程伪代码表示如下。 12345678follower节点收到RequestVote请求： 对比RequestVote请求中带上的最后一条日志数据： 如果任期号比节点的最后一条数据任期号小： 拒绝投票给该节点 如果索引号比节点的最后一条数据索引小： 拒绝投票给该节点 其他情况： 说明选举节点的日志信息比本节点更新，投票给该节点。 2.7 安全性-提交前面任期的日志条目如果leader在写入但是还没有提交一条日志之前崩溃，那么这条没有提交的日志是否能提交？有几种情况需要考虑，如下图所示： 在上图中，有以下的场景变更。 情况a：s1是leader，index 2位置写入了数据2，该值只写在了s1，s2上，但是还没有被提交。 情况b：s1崩溃，s5成为新的leader，该节点在index 2上面提交了另外一个值3，但是这个值只写在了s5上面，并没有被提交。 情况c：s5崩溃，s1重新成为leader，这一次，index 2的值2写到了集群的大多数节点上。 此时可能存在以下两种情况： 情况d1：s1崩溃，s5重新成为leader（投票给s5的是s4，s2和s5自身），那么index 2上的值3这一次成功的写入到集群的半数以上节点之上，并成功提交。 情况d2：s1不崩溃，而是将index 2为2的值成功提交。 从情况d的两种场景可以看出，在index 2值为2，且已经被写入到半数以上节点的情况下，同样存在被新的leader覆盖的可能性。 由于以上的原因，对于当前任期之前任期提交的日志，并不通过判断是否已经在半数以上集群节点写入成功来作为能否提交的依据。只有当前leader任期内的日志是通过比较写入数量是否超过半数来决定是否可以提交的。 对于任期之前的日志，Raft 采用的方式，是只要提交成功了当前任期的日志，那么在日志之前的日志就认为提交成功了。这也是为什么 etcd Raft 代码中，在成为leader之后，需要再提交一条dummy的日志的原因–只要该日志提交成功，leader上该日志之前的日志就可以提交成功。 3. 集群成员变更在上面描述 Raft 基本算法流程中，都假设集群中的节点是稳定不变的。但是在某些情况下，需要手动改变集群的配置。 3.1 安全性安全性是变更集群成员时首先需要考虑到的问题，任何时候都不能出现集群中存在多于一个leader的情况。为了避免出现这种情况，每次变更成员时不能一次添加或者修改超过一个节点，集群不能直接切换到新的状态，如下图所示。在上图中，server 1、2、3组成的是旧集群，server 4、5是准备新加入集群的节点。注意到如果直接尝试切换到新的状态，在某些时间点里，如图中所示，由于server 1、2上的配置还是旧的集群配置，那么可能这两个节点已经选定了一个leader；而server 3、4、5又是新的配置，它们也可能选定了一个leader，而这两个leader不是同一个，这就出现了集群中存在一个以上leader的情况了。相反，每次添加一个节点则不会出现同时有两个超过半数以上自己群的存在，即不可能选出多于一个leader。 raft采用将修改集群配置的命令放在日志条目中来处理，这样做的好处是： 可以继续沿用原来的AppendEntries命令来同步日志数据，只要把修改集群的命令做为一种特殊的命令就可以了。 在这个过程中，可以继续处理客户端请求。 3.2 可用性-添加新节点到集群中添加一个新的节点到集群时，需要考虑一种情况，即新节点可能落后当前集群日志很多的情况，在这种情况下集群出现故障的概率会大大提高，如下图所示：上图中的情况a中，s1、s2、s3是原有的集群节点，这时把节点s4添加进来，而s4中没有数据。如果此时s3发生故障，在集群中原来有三个节点的情况下，本来可以容忍一个节点的失败的；但是当变成四个节点的集群时，s3和s4同时不可用整个集群就不可用了。 因此Raft算法针对这种新添加进来的节点，是如下处理的。 添加进来的新节点首先将不加入到集群中，而是等待数据追上集群的进度。 leader同步数据给新节点的流程是划分为多个轮次，每一轮同步一部分数据，而在同步的时候，leader仍然可以写入新的数据，而新的数据在新的轮次继续同步。这个同步的轮次并不能一直持续下去，一般会有一个限制的轮次数量，比如最多同步10轮。 3.3 可用性-删除当前集群的leader节点当需要下线当前集群的leader节点时，leader节点将发出一个变更节点配置的命令，只有在该命令被提交之后，原先的leader节点才下线，然后集群会自然有一个节点选举超时而进行新的一轮选举。 3.4 可用性-处理移除集群的节点如果某个节点在一次配置更新之后，被移出了新的集群，但是这个节点又不知道这个情况，那么按照前面描述的 Raft 算法流程来说，它应该在选举超时之后，将任期号递增1，发起一次新的选举。虽然最终这个节点不会赢得选举，但是毕竟对集群运行的状态造成了干扰。而且如果这个节点一直不下线，那么上面这个发起新选举的流程就会一直持续下去。 为了解决这个问题，Raft 引入了一个成为“PreVote”的流程，在这个流程中，如果一个节点要发起一次新的选举，那么首先会广播给集群中的其它所有节点，询问下当前该节点上的日志是否足以赢下选举。只有在这个PreVote阶段赢得超过半数节点肯定的情况下，才真正发起一次新的选举。 然而，PreVote并不能解决所有的问题，因为很有可能该被移除节点上的日志也是最新的。所以不能完全依靠判断日志的方式来决定是否允许一个节点发起新一轮的选举。 Raft采用了另一种机制。如果leader节点一直保持着与其它节点的心跳消息，那么就认为leader节点是存活的，此时不允许发起一轮新的选举。这样follower节点处理 RequestVote 请求时，就需要加上判断，除了判断请求进行选举的节点日志是否最新以外，如果当前在一段时间内还收到过来自leader节点的心跳消息，那么也不允许发起新的选举。然而这种情况与前面描述的leader迁移的情况相悖，在leader迁移时是强制要求发起新的选举的，因此RequestVote请求的处理还要加上这种情况的判断。 总体来说，RequestVote 请求的处理逻辑大致如下： 12345678follower处理RequestVote请求： 如果请求节点的日志不是最新的： 拒绝该请求，返回 如果此时是leader迁移的情况： 接收该请求，返回 如果最近一段时间还有收到来自leader节点的心跳消息： 拒绝该请求，返回 接收该请求 4. 日志压缩日志数据如果不进行压缩处理掉的话，会一直增长下去。为此Raft使用快照数据来进行日志压缩，比如针对键值a的几次操作日志：a=1、delete a、a=3 最后可以被压缩成为最后的结果数据即a=3。 未压缩日志前，日志数据保存到了&lt;3,5&gt;的位置，而在&lt;2,3&gt;的位置之前的数据都已经进行提交了，所以可以对这部分数据进行压缩。 压缩日志之后，快照文件中存放了几个值：压缩时最后一条日志的二元数据是&lt;2,3&gt;，而针对a的几次操作最后的值为a=3，b的值为2。 5. 高效处理只读请求如前面所述，处理一个命令时，需要经历以下流程：leader向集群中其它节点广播日志，在日志被超过半数节点应答之后，leader提交该日志，最后应答客户端。这样的流程对于一个只读请求而言太久了，而且还涉及到日志落盘的操作，对于只读请求而言这些操作是不必要的。 但是如果不经过上面的流程，leader节点在收到一个只读请求时就将本节点上保存的数据应答客户端，也是不安全的，因为这可能返回已经过期的数据。一方面leader节点可能已经发生了变化，只是这个节点并不知道；另一方面可能数据也发生了改变。返回过期的数据不符合一致性要求，因此这样的做法也是不合理的。 Raft 对于只读请求是做如下处理： leader节点需要有当前已提交日志的信息。在前面提到过不能提交前面任期的日志条目，因此一个新leader产生之后，需要提交一条空日志，这样来确保上一个任期内的日志全部提交。 leader节点保存该只读请求到来时的commit日志索引为readIndex， leader需要确认自己当前还是集群的leader，因为可能会由于有网络分区的原因导致leader已经被隔离出集群而不自知。为了达到这个目的，leader节点将广播一个heartbeat心跳消息给集群中其它节点，当收到半数以上节点的应答时，leader节点知道自己当前还是leader，同时readIndex索引也是当前集群日志提交的最大索引。","link":"/2022/01/15/Raft%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/"},{"title":"RocksDB 简介","text":"TiKV 架构 RocksDB 的内存占用 RocksDB 的空间占用 RocksDB 后台线程与 Compact WriteStall RocksDB 是由 Facebook 基于 LevelDB 开发的一款提供键值存储与读写功能的 LSM-tree 架构引擎。用户写入的键值对会先写入磁盘上的 WAL (Write Ahead Log)，然后再写入内存中的跳表（SkipList，这部分结构又被称作 MemTable）。LSM-tree 引擎由于将用户的随机修改（插入）转化为了对 WAL 文件的顺序写，因此具有比 B 树类存储引擎更高的写吞吐。 内存中的数据达到一定阈值后，会刷到磁盘上生成 SST 文件 (Sorted String Table)，SST 又分为多层（默认至多 6 层），每一层的数据达到一定阈值后会挑选一部分 SST 合并到下一层，每一层的数据是上一层的 10 倍（因此 90% 的数据存储在最后一层）。 RocksDB 允许用户创建多个 ColumnFamily ，这些 ColumnFamily 各自拥有独立的内存跳表以及 SST 文件，但是共享同一个 WAL 文件，这样的好处是可以根据应用特点为不同的 ColumnFamily 选择不同的配置，但是又没有增加对 WAL 的写次数。 1. TiKV 架构TiKV 的系统架构如下图所示： RocksDB 作为 TiKV 的核心存储引擎，用于存储 Raft 日志以及用户数据。每个 TiKV 实例中有两个 RocksDB 实例，一个用于存储 Raft 日志（通常被称为 raftdb），另一个用于存储用户数据以及 MVCC 信息（通常被称为 kvdb）。kvdb 中有四个 ColumnFamily：raft、lock、default 和 write： raft 列：用于存储各个 Region 的元信息。仅占极少量空间，用户可以不必关注。 lock 列：用于存储悲观事务的悲观锁以及分布式事务的一阶段 Prewrite 锁。当用户的事务提交之后，lock cf 中对应的数据会很快删除掉，因此大部分情况下 lock cf 中的数据也很少（少于 1GB）。如果 lock cf 中的数据大量增加，说明有大量事务等待提交，系统出现了 bug 或者故障。 write 列：用于存储用户真实的写入数据以及 MVCC 信息（该数据所属事务的开始时间以及提交时间）。当用户写入了一行数据时，如果该行数据长度小于 255 字节，那么会被存储 write 列中，否则的话该行数据会被存入到 default 列中。由于 TiDB 的非 unique 索引存储的 value 为空，unique 索引存储的 value 为主键索引，因此二级索引只会占用 write cf 的空间。 default 列：用于存储超过 255 字节长度的数据。 2. RocksDB 的内存占用为了提高读取性能以及减少对磁盘的读取，RocksDB 将存储在磁盘上的文件都按照一定大小切分成 block（默认是 64KB），读取 block 时先去内存中的 BlockCache 中查看该块数据是否存在，存在的话则可以直接从内存中读取而不必访问磁盘。 BlockCache 按照 LRU 算法淘汰低频访问的数据，TiKV 默认将系统总内存大小的 45% 用于 BlockCache，用户也可以自行修改 storage.block-cache.capacity 配置设置为合适的值，但是不建议超过系统总内存的 60%。 写入 RocksDB 中的数据会写入 MemTable，当一个 MemTable 的大小超过 128MB 时，会切换到一个新的 MemTable 来提供写入。TiKV 中一共有 2 个 RocksDB 实例，合计 4 个 ColumnFamily，每个 ColumnFamily 的单个 MemTable 大小限制是 128MB，最多允许 5 个 MemTable 存在，否则会阻塞前台写入，因此这部分占用的内存最多为 4 x 5 x 128MB = 2.5GB。 3. RocksDB 的空间占用 多版本：RocksDB 作为一个 LSM-tree 结构的键值存储引擎，MemTable 中的数据会首先被刷到 L0。L0 层的 SST 之间的范围可能存在重叠（因为文件顺序是按照生成的顺序排列），因此同一个 key 在 L0 中可能存在多个版本。当文件从 L0 合并到 L1 的时候，会按照一定大小（默认是 8MB）切割为多个文件，同一层的文件的范围互不重叠，所以 L1 及其以后的层每一层的 key 都只有一个版本。 空间放大：RocksDB 的每一层文件总大小都是上一层的 x 倍，在 TiKV 中这个配置默认是 10，因此 90% 的数据存储在最后一层，这也意味着 RocksDB 的空间放大不超过 1.11（L0 层的数据较少，可以忽略不计）。 TiKV 的空间放大：TiKV 在 RocksDB 之上还有一层自己的 MVCC，当用户写入一个 key 的时候，实际上写入到 RocksDB 的是 key + commit_ts，也就是说，用户的更新和删除都是会写入新的 key 到 RocksDB。TiKV 每隔一段时间会删除旧版本的数据（通过 RocksDB 的 Delete 接口），因此可以认为用户存储在 TiKV 上的数据的实际空间放大为，1.11 加最近 10 分钟内写入的数据（假设 TiKV 回收旧版本数据足够及时）。 4. RocksDB 后台线程与 CompactRocksDB 中，将内存中的 MemTable 转化为磁盘上的 SST 文件，以及合并各个层级的 SST 文件等操作都是在后台线程池中执行的。后台线程池的默认大小是 8，当机器 CPU 数量小于等于 8 时，则后台线程池默认大小为 CPU 数量减一。通常来说，用户不需要更改这个配置。如果用户在一个机器上部署了多个 TiKV 实例，或者机器的读负载比较高而写负载比较低，那么可以适当调低 rocksdb/max-background-jobs 至 3 或者 4。 5. WriteStallRocksDB 的 L0 与其他层不同，L0 的各个 SST 是按照生成顺序排列，各个 SST 之间的 key 范围存在重叠，因此查询的时候必须依次查询 L0 中的每一个 SST。为了不影响查询性能，当 L0 中的文件数量过多时，会触发 WriteStall 阻塞写入。","link":"/2022/01/08/TiKV%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89/"},{"title":"TiDB 数据库的存储","text":"Key-Value Pairs（键值对） 本地存储 (RocksDB) TiKV 与 Raft 协议 Region MVCC 分布式 ACID 事务 这部分重点介绍TiKV的一些设计思想和关键概念。 1. Key-Value Pairs（键值对）作为保存数据的系统，首先要决定的是数据的存储模型，也就是数据以什么样的形式保存下来。TiKV 的选择是 Key-Value 模型，并且提供有序遍历方法。 TiKV 数据存储的两个关键点： 这是一个巨大的 Map（可以类比一下 C++ 的 std::map），也就是存储的是 Key-Value Pairs（键值对） 这个 Map 中的 Key-Value pair 按照 Key 的二进制顺序有序，也就是可以 Seek 到某一个 Key 的位置，然后不断地调用 Next 方法以递增的顺序获取比这个 Key 大的 Key-Value。注意，本文所说的 TiKV 的 KV 存储模型和 SQL 中的 Table 无关。TiKV 不讨论 SQL 中的任何概念，专注于讨论如何实现 TiKV 这样一个高性能、高可靠性、分布式的 Key-Value 存储。 2. 本地存储 (RocksDB)任何持久化的存储引擎，数据终归要保存在磁盘上，TiKV 也不例外。但是 TiKV 没有选择直接向磁盘上写数据，而是把数据保存在 RocksDB 中，具体的数据落地由 RocksDB 负责。这个选择的原因是开发一个单机存储引擎工作量很大，特别是要做一个高性能的单机引擎，需要做各种细致的优化，而 RocksDB 是由 Facebook 开源的一个非常优秀的单机 KV 存储引擎，可以满足 TiKV 对单机引擎的各种要求。这里可以简单的认为 RocksDB 是一个单机的持久化 Key-Value Map。 3. TiKV 与 Raft 协议在这里 Raft 解决了一个 TiKV 面临的难题：如何保证单机失效的情况下，数据不丢失，不出错？ 简单来说，需要想办法把数据复制到多台机器上，这样一台机器无法服务了，其他的机器上的副本还能提供服务；复杂来说，还需要这个数据复制方案是可靠和高效的，并且能处理副本失效的情况。TiKV 选择了 Raft 算法。Raft 是一个一致性协议。Raft 提供几个重要的功能： Leader（主副本）选举 成员变更（如添加副本、删除副本、转移 Leader 等操作） 日志复制 TiKV 利用 Raft 来做数据复制，每个数据变更都会落地为一条 Raft 日志，通过 Raft 的日志复制功能，将数据安全可靠地同步到复制组的每一个节点中。不过在实际写入中，根据 Raft 的协议，只需要同步复制到多数节点，即可安全地认为数据写入成功。 总结一下，通过单机的 RocksDB，TiKV 可以将数据快速地存储在磁盘上；通过 Raft，将数据复制到多台机器上，以防单机失效。数据的写入是通过 Raft 这一层的接口写入，而不是直接写 RocksDB。通过实现 Raft，TiKV 变成了一个分布式的 Key-Value 存储，少数几台机器宕机也能通过原生的 Raft 协议自动把副本补全，可以做到对业务无感知。 4. Region假设数据只有一个副本，为了实现存储的水平扩展，数据将被分散在多台机器上。对于一个 KV 系统，将数据分散在多台机器上有两种比较典型的方案： Hash：按照 Key 做 Hash，根据 Hash 值选择对应的存储节点。 Range：按照 Key 分 Range，某一段连续的 Key 都保存在一个存储节点上。 TiKV 选择了第二种方式，将整个 Key-Value 空间分成很多段，每一段是一系列连续的 Key，将每一段叫做一个 Region。TiKV 保持每个 Region 中保存的数据不超过一定的大小，目前在 TiKV 中默认是 96MB。每一个 Region 都可以用 [StartKey，EndKey) 这样一个左闭右开区间来描述。 注意，这里的 Region 还是和 SQL 中的表没什么关系，划分成 Region 后，TiKV 将会做两件事情： 以 Region 为单位，将数据分散在集群中所有的节点上，并且尽量保证每个节点上服务的 Region 数量差不多。 以 Region 为单位做 Raft 的复制和成员管理。 对于第一点，数据按照 Key 切分成很多 Region，每个 Region 的数据只会保存在一个节点上面（暂不考虑多副本）。TiDB 系统会有一个组件 (PD) 来负责将 Region 尽可能均匀的散布在集群中所有的节点上，这样一方面实现了存储容量的水平扩展（增加新的节点后，会自动将其他节点上的 Region 调度过来），另一方面也实现了负载均衡（不会出现某个节点有很多数据，其他节点上没什么数据的情况）。同时为了保证上层客户端能够访问所需要的数据，系统中也会有一个组件 (PD) 记录 Region 在节点上面的分布情况，也就是通过任意一个 Key 就能查询到这个 Key 在哪个 Region 中，以及这个 Region 目前在哪个节点上（即 Key 的位置路由信息）。 对于第二点，TiKV 是以 Region 为单位做数据的复制，也就是一个 Region 的数据会保存多个副本，TiKV 将每一个副本叫做一个 Replica。Replica 之间是通过 Raft 来保持数据的一致，一个 Region 的多个 Replica 会保存在不同的节点上，构成一个 Raft Group。其中一个 Replica 会作为这个 Group 的 Leader，其他的 Replica 作为 Follower。默认情况下，所有的读和写都是通过 Leader 进行，读操作在 Leader 上即可完成，而写操作再由 Leader 复制给 Follower。 理解了 Region 之后，应该可以理解下面这张图： 以 Region 为单位做数据的分散和复制，TiKV 就成为了一个分布式的具备一定容灾能力的 KeyValue 系统，不用再担心数据存不下（分布式），或者是磁盘故障丢失数据的问题（Raft）。 5. MVCCTiKV 同样实现了多版本并发控制 (MVCC)。设想这样的场景：两个客户端同时去修改一个 Key 的 Value，如果没有MVCC，就需要对数据上锁，在分布式场景下，这可能会带来性能以及死锁问题。TiKV 的 MVCC 实现是通过在 Key 后面添加版本号来实现。 简单来说，没有 MVCC 之前，可以把 TiKV 看做这样的： Key1 -&gt; ValueKey2 -&gt; Value……KeyN -&gt; Value 有了 MVCC 之后，TiKV 的 Key 排列是这样的： Key1_Version3 -&gt; ValueKey1_Version2 -&gt; ValueKey1_Version1 -&gt; Value……Key2_Version4 -&gt; ValueKey2_Version3 -&gt; ValueKey2_Version2 -&gt; ValueKey2_Version1 -&gt; Value……KeyN_Version2 -&gt; ValueKeyN_Version1 -&gt; Value…… 对于同一个 Key 的多个版本，版本号较大的会被放在前面。这样当用户通过一个 Key + Version 来获取 Value 的时候，可以通过 Key 和 Version 构造出 MVCC 的 Key_Version。然后可以直接通过 RocksDB 的 SeekPrefix(Key_Version) API，定位到第一个大于等于这个 Key_Version 的位置。 6. 分布式 ACID 事务TiKV 的事务采用的是 Google 在 BigTable 中使用的事务模型：Percolator ，","link":"/2022/01/07/TiKV%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"TiDB 整体架构","text":"TiDB Server PD (Placement Driver) Server 存储节点 与传统的单机数据库相比，TiDB 具有以下优势： 纯分布式架构，拥有良好的扩展性，支持弹性的扩缩容 支持 SQL，对外暴露 MySQL 的网络协议，并兼容大多数 MySQL 的语法，在大多数场景下可以直接替换 MySQL 默认支持高可用，在少数副本失效的情况下，数据库本身能够自动进行数据修复和故障转移，对业务透明 支持 ACID 事务，对于一些有强一致需求的场景友好，例如：银行转账 具有丰富的工具链生态，覆盖数据迁移、同步、备份等多种场景 在内核设计上，TiDB 分布式数据库将整体架构拆分成了多个模块。各模块之间互相通信，组成完整的 TiDB 系统。对应的架构图如下： 1. TiDB ServerSQL 层，对外暴露 MySQL 协议的连接 endpoint，负责接受客户端的连接，执行 SQL 解析和优化，最终生成分布式执行计划。TiDB 层本身是无状态的，实践中可以启动多个 TiDB 实例，通过负载均衡组件（如 LVS、HAProxy 或 F5）对外提供统一的接入地址，客户端的连接可以均匀地分摊在多个 TiDB 实例上以达到负载均衡的效果。TiDB Server 本身并不存储数据，只是解析 SQL，将实际的数据读取请求转发给底层的存储节点 TiKV（或 TiFlash）。 2. PD (Placement Driver) Server整个 TiDB 集群的元信息管理模块，负责存储每个 TiKV 节点实时的数据分布情况和集群的整体拓扑结构，提供 TiDB Dashboard 管控界面，并为分布式事务分配事务 ID。PD 不仅存储元信息，同时还会根据 TiKV 节点实时上报的数据分布状态，下发数据调度命令给具体的 TiKV 节点，可以说是整个集群的“大脑”。此外，PD 本身也是由至少 3 个节点构成，拥有高可用的能力。建议部署奇数个 PD 节点。 3. 存储节点3.1 TiKV Server负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 的 API 在 KV 键值对层面提供对分布式事务的原生支持，默认提供了 SI (Snapshot Isolation) 的隔离级别，这也是 TiDB 在 SQL 层面支持分布式事务的核心。TiDB 的 SQL 层做完 SQL 解析后，会将 SQL 的执行计划转换为对 TiKV API 的实际调用。所以，数据都存储在 TiKV 中。另外，TiKV 中的数据都会自动维护多副本（默认为三副本），天然支持高可用和自动故障转移。 3.2 TiFlashTiFlash 是一类特殊的存储节点。和普通 TiKV 节点不一样的是，在 TiFlash 内部，数据是以列式的形式进行存储，主要的功能是为分析型的场景加速。","link":"/2022/01/07/TiKV%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"TiDB 数据库的调度","text":"场景描述 调度的需求 调度的基本操作 信息收集 调度的策略 调度的实现 PD (Placement Driver) 是 TiDB 集群的管理模块，同时也负责集群数据的实时调度。下面介绍一下 PD 的设计思想和关键概念。 1. 场景描述TiKV 集群是 TiDB 数据库的分布式 KV 存储引擎，数据以 Region 为单位进行复制和管理，每个 Region 会有多个副本 (Replica)，这些副本会分布在不同的 TiKV 节点上，其中 Leader 负责读/写，Follower 负责同步 Leader 发来的 Raft log。 需要考虑以下场景： 为了提高集群的空间利用率，需要根据 Region 的空间占用对副本进行合理的分布。 集群进行跨机房部署的时候，要保证一个机房掉线，不会丢失 Raft Group 的多个副本。 添加一个节点进入 TiKV 集群之后，需要合理地将集群中其他节点上的数据搬到新增节点。 当一个节点掉线时，需要考虑快速稳定地进行容灾。 从节点的恢复时间来看 如果节点只是短暂掉线（重启服务），是否需要进行调度。 如果节点是长时间掉线（磁盘故障，数据全部丢失），如何进行调度。 假设集群需要每个 Raft Group 有 N 个副本，从单个 Raft Group 的副本个数来看 副本数量不够（例如节点掉线，失去副本），需要选择适当的机器的进行补充。 副本数量过多（例如掉线的节点又恢复正常，自动加入集群），需要合理的删除多余的副本。 读/写通过 Leader 进行，Leader 的分布只集中在少量几个节点会对集群造成影响。 并不是所有的 Region 都被频繁的访问，可能访问热点只在少数几个 Region，需要通过调度进行负载均衡。 集群在做负载均衡的时候，往往需要搬迁数据，这种数据的迁移可能会占用大量的网络带宽、磁盘 IO 以及 CPU，进而影响在线服务。 以上问题和场景如果多个同时出现，就不太容易解决，因为需要考虑全局信息。同时整个系统也是在动态变化的，因此需要一个中心节点，来对系统的整体状况进行把控和调整，所以有了 PD 这个模块。 2. 调度的需求对以上的问题和场景进行分类和整理，系统要考虑： 2.1 作为一个分布式高可用存储系统 副本数量不能多也不能少 副本需要根据拓扑结构分布在不同属性的机器上 节点宕机或异常能够自动合理快速地进行容灾 2.2 作为一个良好的分布式系统 维持整个集群的 Leader 分布均匀 维持每个节点的储存容量均匀 维持访问热点分布均匀 控制负载均衡的速度，避免影响在线服务 管理节点状态，包括手动上线/下线节点 满足第一类需求后，整个系统将具备强大的容灾功能。满足第二类需求后，可以使得系统整体的资源利用率更高且合理，具备良好的扩展性。 为了满足这些需求，首先需要收集足够的信息，比如每个节点的状态、每个 Raft Group 的信息、业务访问操作的统计等；其次需要设置一些策略，PD 根据这些信息以及调度的策略，制定出尽量满足前面所述需求的调度计划；最后需要一些基本的操作，来完成调度计划。 3. 调度的基本操作调度的基本操作指的是为了满足调度的策略。上述调度需求可整理为以下三个操作： 增加一个副本 删除一个副本 将 Leader 角色在一个 Raft Group 的不同副本之间 transfer（迁移）。 刚好 Raft 协议通过 AddReplica、RemoveReplica、TransferLeader 这三个命令，可以支撑上述三种基本操作。 4. 信息收集调度依赖于整个集群信息的收集，简单来说，调度需要知道每个 TiKV 节点的状态以及每个 Region 的状态。TiKV 集群会向 PD 汇报两类消息： TiKV 节点信息 Region 信息 4.1 TiKV 节点信息每个 TiKV 节点会定期向 PD 汇报节点的状态信息 TiKV 节点 (Store) 与 PD 之间存在心跳包，一方面 PD 通过心跳包检测每个 Store 是否存活，以及是否有新加入的 Store；另一方面，心跳包中也会携带这个 Store 的状态信息，主要包括： 总磁盘容量 可用磁盘容量 承载的 Region 数量 数据写入/读取速度 发送/接受的 Snapshot 数量（副本之间可能会通过 Snapshot 同步数据） 是否过载 labels 标签信息（标签是具备层级关系的一系列 Tag，能够感知拓扑信息） 通过使用 pd-ctl 可以查看到 Store 的状态信息。 TiKV Store 的状态具体分为 Up，Disconnect，Offline，Down，Tombstone。各状态的关系如下： Up：表示当前的 Store 处于提供服务的状态。 Disconnect：当 PD 和 TiKV 的心跳信息丢失超过 20 秒后，该 TiKV 的状态会变为 Disconnect 状态。 Down：表示该 TiKV 与集群失去连接的时间已经超过了 max-store-down-time 指定的时间，默认 30 分钟。超过该时间后，对应的 TiKV 会变为 Down，并且开始在存活的 TiKV 上补足各个 Region 的副本。 Offline：当对某个 TiKV 通过 pd-ctl 进行手动下线操作，该 TiKV 会变为 Offline 状态，该状态只是 TiKV 下线的中间状态，处于该状态的 TiKV 会进行 leader 的 transfer 和 Region balance 操作，当 leader_count/region_count (在 pd-ctl 中获取) 均显示 transfer 或 balance 完毕后，该 TiKV 会由 Offline 状态变为 Tombstone 状态。在 Offline 状态下，禁止关闭该 TiKV 服务以及其所在的物理服务器。 Tombstone：表示该 TiKV 已处于完全下线状态，可以使用 remove-tombstone 接口安全地清理该状态的 TiKV。 4.2 Region 信息每个 Raft Group 的 Leader 会定期向 PD 汇报 Region 的状态信息 每个 Raft Group 的 Leader 和 PD 之间存在心跳包，用于汇报这个 Region 的状态，主要包括下面几点信息： Leader 的位置 Followers 的位置 掉线副本的个数 数据写入/读取的速度 PD 不断的通过这两类心跳消息收集整个集群的信息，再以这些信息作为决策的依据。 除此之外，PD 还可以通过扩展的接口接受额外的信息，用来做更准确的决策。比如当某个 Store 的心跳包中断的时候，PD 并不能判断这个节点是临时失效还是永久失效，只能经过一段时间的等待（默认是 30 分钟），如果一直没有心跳包，就认为该 Store 已经下线，再决定需要将这个 Store 上面的 Region 都调度走。 但是有的时候，是运维人员主动将某台机器下线，这个时候，可以通过 PD 的管理接口通知 PD 该 Store 不可用，PD 就可以马上判断需要将这个 Store 上面的 Region 都调度走。 5. 调度的策略PD 收集了这些信息后，还需要一些策略来制定具体的调度计划。 5.1 一个 Region 的副本数量正确当 PD 通过某个 Region Leader 的心跳包发现这个 Region 的副本数量不满足要求时，需要通过 Add/Remove Replica 操作调整副本数量。出现这种情况的可能原因是： 某个节点掉线，上面的数据全部丢失，导致一些 Region 的副本数量不足 某个掉线节点又恢复服务，自动接入集群，这样之前已经补足了副本的 Region 的副本数量过多，需要删除某个副本 管理员调整副本策略，修改了 max-replicas 的配置 5.2 一个 Raft Group 中的多个副本不在同一个位置『同一个位置』不是『同一个节点』。一般情况下，PD 只会保证多个副本不落在一个节点上，以避免单个节点失效导致多个副本丢失。在实际部署中，还可能出现下面这些需求： 多个节点部署在同一台物理机器上 TiKV 节点分布在多个机架上，希望单个机架掉电时，也能保证系统可用性 TiKV 节点分布在多个 IDC 中，希望单个机房掉电时，也能保证系统可用性 这些需求本质上都是某一个节点具备共同的位置属性，构成一个最小的『容错单元』，希望这个单元内部不会存在一个 Region 的多个副本。这个时候，可以给节点配置 labels 并且通过在 PD 上配置 location-labels 来指名哪些 label 是位置标识，需要在副本分配的时候尽量保证一个 Region 的多个副本不会分布在具有相同的位置标识的节点上。 5.3 副本在 Store 之间的分布均匀分配由于每个 Region 的副本中存储的数据容量上限是固定的，通过维持每个节点上面副本数量的均衡，使得各节点间承载的数据更均衡。 5.4 Leader 数量在 Store 之间均匀分配Raft 协议要求读取和写入都通过 Leader 进行，所以计算的负载主要在 Leader 上面，PD 会尽可能将 Leader 在节点间分散开。 5.5 访问热点数量在 Store 之间均匀分配每个 Store 以及 Region Leader 在上报信息时携带了当前访问负载的信息，比如 Key 的读取/写入速度。PD 会检测出访问热点，且将其在节点之间分散开。 5.6 各个 Store 的存储空间占用大致相等每个 Store 启动的时候都会指定一个 Capacity 参数，表明这个 Store 的存储空间上限，PD 在做调度的时候，会考虑节点的存储空间剩余量。 5.7 控制调度速度，避免影响在线服务调度操作需要耗费 CPU、内存、磁盘 IO 以及网络带宽，需要避免对线上服务造成太大影响。PD 会对当前正在进行的操作数量进行控制，默认的速度控制是比较保守的，如果希望加快调度（比如停服务升级或者增加新节点，希望尽快调度），那么可以通过调节 PD 参数动态加快调度速度。 6. 调度的实现PD 不断地通过 Store 或者 Leader 的心跳包收集整个集群信息，并且根据这些信息以及调度策略生成调度操作序列。每次收到 Region Leader 发来的心跳包时，PD 都会检查这个 Region 是否有待进行的操作，然后通过心跳包的回复消息，将需要进行的操作返回给 Region Leader，并在后面的心跳包中监测执行结果。 注意这里的操作只是给 Region Leader 的建议，并不保证一定能得到执行，具体是否会执行以及什么时候执行，由 Region Leader 根据当前自身状态来定。","link":"/2022/01/07/TiKV%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/"},{"title":"TiKV简介","text":"整体架构 分布式事务 计算加速 TiKV 是一个分布式事务型的键值数据库，提供了满足 ACID 约束的分布式事务接口，并且通过 Raft 协议保证了多副本数据一致性以及高可用。TiKV 作为 TiDB 的存储层，为用户写入 TiDB 的数据提供了持久化以及读写服务，同时还存储了 TiDB 的统计信息数据。 1. 整体架构TiKV 没有采用传统整节点备份，而是设计了 multi-raft-group 的副本机制。将数据按照 key 的范围划分成大致相等的切片（Region），每一个切片会有多个副本（通常是 3 个），其中一个副本是 Leader，提供读写服务。TiKV 通过 PD 对这些 Region 以及副本进行调度，以保证数据和读写负载都均匀地分散在各个 TiKV 上，这样的设计保证了整个集群资源的充分利用并且可以随着机器数量的增加水平扩展。 1.1 Region 与 RocksDB虽然 TiKV 将数据按照范围切割成了多个 Region，但是同一个节点的所有 Region 数据仍然是不加区分地存储于同一个 RocksDB 实例上，而用于 Raft 协议复制所需要的日志则存储于另一个 RocksDB 实例。这样设计的原因是因为随机 I/O 的性能远低于顺序 I/O，所以 TiKV 使用同一个 RocksDB 实例来存储这些数据，以便不同 Region 的写入可以合并在一次 I/O 中。 1.2 Region 与 Raft 协议Region 与副本之间通过 Raft 协议来维持数据一致性，任何写请求都只能在 Leader 上写入，并且需要写入多数副本后（默认配置为 3 副本，即所有请求必须至少写入两个副本成功）才会返回客户端写入成功。 当某个 Region 的大小超过一定限制（默认是 144MB）后，TiKV 会将它分裂为两个或者更多个 Region，以保证各个 Region 的大小是大致接近的，这样更有利于 PD 进行调度决策。同样，当某个 Region 因为大量的删除请求导致 Region 的大小变得更小时，TiKV 会将比较小的两个相邻 Region 合并为一个。 当 PD 需要把某个 Region 的一个副本从一个 TiKV 节点调度到另一个上面时，PD 会先为这个 Raft Group 在目标节点上增加一个 Learner 副本（虽然会复制 Leader 的数据，但是不会计入写请求的多数副本中）。当这个 Learner 副本的进度大致追上 Leader 副本时，Leader 会将它变更为 Follower，之后再移除操作节点的 Follower 副本，这样就完成了 Region 副本的一次调度。 Leader 副本的调度原理也类似，不过需要在目标节点的 Learner 副本变为 Follower 副本后，再执行一次 Leader Transfer，让该 Follower 主动发起一次选举成为新 Leader，之后新 Leader 负责删除旧 Leader 这个副本。 2. 分布式事务TiKV 支持分布式事务，用户（或者 TiDB）可以一次性写入多个 key-value 而不必关心这些 key-value 是否处于同一个数据切片 (Region) 上，TiKV 通过两阶段提交保证了这些读写请求的 ACID 约束，详见 TiDB 乐观事务模型。 3. 计算加速TiKV 通过协处理器 (Coprocessor) 可以为 TiDB 分担一部分计算：TiDB 会将可以由存储层分担的计算下推。能否下推取决于 TiKV 是否可以支持相关下推。计算单元仍然是以 Region 为单位，即 TiKV 的一个 Coprocessor 计算请求中不会计算超过一个 Region 的数据。","link":"/2022/01/08/TiKV%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89/"},{"title":"TiDB 数据库的计算","text":"Key-Value 的映射关系 SQL 层简介 TiDB 在 TiKV 提供的分布式存储能力基础上，构建了兼具优异的交易处理能力与良好的数据分析能力的计算引擎。那么， TiDB 如何将库表中的数据映射到 TiKV 中的 (Key, Value) 键值对？ TiDB 元信息有怎样的管理方式？ TiDB SQL 层的主要架构又是什么呢？ 对于计算层依赖的存储方案，本文只介绍基于 TiKV 的行存储结构。针对分析型业务的特点，TiDB 推出了作为 TiKV 扩展的列存储方案 TiFlash。 1. Key-Value 的映射关系本小节介绍 TiDB 中数据到 (Key, Value) 键值对的映射方案。这里的数据主要包括以下两个方面： 表中每一行的数据，以下简称表数据 表中所有索引的数据，以下简称索引数据 1.1 表数据与 Key-Value 的映射关系考虑到数据库要具备快速读取一行数据的能力，和通过范围查询高效完成全表扫描的任务。TiDB 中的表数据与 Key-Value 的映射关系作了如下设计： 为了保证同一个表的数据放在一起，方便查找，TiDB 会为每个表分配一个表 ID，用 **TableID ** 表示。表 ID 是一个整数，在整个集群内唯一。 TiDB 会为表中每行数据分配一个行 ID，用 * RowID* 表示。行 ID 也是一个整数，在表内唯一。对于行 ID，TiDB 做了一个小优化，如果某个表有整数型的主键，TiDB 会使用主键的值当做这一行数据的行 ID。 每行数据按照如下规则编码成 (Key, Value) 键值对： Key: tablePrefix{TableID}_recordPrefixSep{RowID}Value: [col1, col2, col3, col4] 其中 tablePrefix 和 recordPrefixSep 都是特定的字符串常量，用于在 Key 空间内区分其他数据。 1.2 索引数据和 Key-Value 的映射关系TiDB 同时支持主键和二级索引（包括唯一索引和非唯一索引）。与表数据映射方案类似，TiDB 为表中每个索引分配了一个索引 ID，用 IndexID 表示。 对于主键和唯一索引，需要根据键值快速定位到对应的 RowID，因此，按照如下规则编码成 (Key, Value) 键值对： Key: tablePrefix{tableID}_indexPrefixSep{indexID}_indexedColumnsValueValue: RowID 对于不需要满足唯一性约束的普通二级索引，一个键值可能对应多行，需要根据键值范围查询对应的 RowID。因此，按照如下规则编码成 (Key, Value) 键值对： Key: tablePrefix{TableID}_indexPrefixSep{IndexID}_indexedColumnsValue_{RowID}Value: null 1.3 映射关系小结上述所有编码规则中的 tablePrefix、recordPrefixSep 和 indexPrefixSep 都是字符串常量，用于在 Key 空间内区分其他数据，定义如下： tablePrefix = []byte{‘t’}recordPrefixSep = []byte{‘r’}indexPrefixSep = []byte{‘i’} 另外请注意，上述方案中，无论是表数据还是索引数据的 Key 编码方案，一个表内所有的行都有相同的 Key 前缀，一个索引的所有数据也都有相同的前缀。这样具有相同的前缀的数据，在 TiKV 的 Key 空间内，是排列在一起的。因此只要小心地设计后缀部分的编码方案，保证编码前和编码后的比较关系不变，就可以将表数据或者索引数据有序地保存在 TiKV 中。采用这种编码后，一个表的所有行数据会按照 RowID 顺序地排列在 TiKV 的 Key 空间中，某一个索引的数据也会按照索引数据的具体的值（编码方案中的 indexedColumnsValue）顺序地排列在 Key 空间内。 1.4 Key-Value 映射关系示例最后通过一个简单的例子，来理解 TiDB 的 Key-Value 映射关系。假设 TiDB 中有如下这个表： CREATE TABLE User ( ID int, Name varchar(20), Role varchar(20), Age int, PRIMARY KEY (ID), KEY idxAge (Age)); 表中有 3 行数据： 1, “TiDB”, “SQL Layer”, 102, “TiKV”, “KV Engine”, 203, “PD”, “Manager”, 30 首先每行数据都会映射为一个 (Key, Value) 键值对，同时该表有一个 int 类型的主键，所以 RowID 的值即为该主键的值。假设该表的 TableID 为 10，则其存储在 TiKV 上的表数据为： t10_r1 –&gt; [“TiDB”, “SQL Layer”, 10]t10_r2 –&gt; [“TiKV”, “KV Engine”, 20]t10_r3 –&gt; [“PD”, “Manager”, 30] 除了主键外，该表还有一个非唯一的普通二级索引 idxAge，假设这个索引的 IndexID 为 1，则其存储在 TiKV 上的索引数据为： t10_i1_10_1 –&gt; nullt10_i1_20_2 –&gt; nullt10_i1_30_3 –&gt; null 1.5 元信息管理TiDB 中每个 Database 和 Table 都有元信息，也就是其定义以及各项属性。这些信息也需要持久化，TiDB 将这些信息也存储在了 TiKV 中。 每个 Database/Table 都被分配了一个唯一的 ID，这个 ID 作为唯一标识，并且在编码为 Key-Value 时，这个 ID 都会编码到 Key 中，再加上 m_ 前缀。这样可以构造出一个 Key，对应Value 中存储的是序列化后的元信息。 除此之外，TiDB 还用一个专门的 (Key, Value) 键值对存储当前所有表结构信息的最新版本号。这个键值对是全局的，每次 DDL 操作的状态改变时其版本号都会加 1。目前，TiDB 把这个键值对持久化存储在 PD Server 中，其 Key 是 “/tidb/ddl/global_schema_version”，Value 是类型为 int64 的版本号值。TiDB 采用 Online Schema 变更算法，有一个后台线程在不断地检查 PD Server 中存储的表结构信息的版本号是否发生变化，并且保证在一定时间内一定能够获取版本的变化。 2. SQL 层简介TiDB 的 SQL 层，即 TiDB Server，负责将 SQL 翻译成 Key-Value 操作，将其转发给共用的分布式 Key-Value 存储层 TiKV，然后组装 TiKV 返回的结果，最终将查询结果返回给客户端。 这一层的节点都是无状态的，节点本身并不存储数据，节点之间完全对等。 2.1 SQL 运算最简单的方案就是通过上一节所述的表数据与 Key-Value 的映射关系方案，将 SQL 查询映射为对 KV 的查询，再通过 KV 接口获取对应的数据，最后执行各种计算。 比如 select count(*) from user where name = “TiDB” 这样一个 SQL 语句，它需要读取表中所有的数据，然后检查 name 字段是否是 TiDB，如果是的话，则返回这一行。具体流程如下： 构造出 Key Range：一个表中所有的 RowID 都在 [0, MaxInt64) 这个范围内，使用 0 和 MaxInt64 根据行数据的 Key 编码规则，就能构造出一个 [StartKey, EndKey)的左闭右开区间。 扫描 Key Range：根据上面构造出的 Key Range，读取 TiKV 中的数据。 过滤数据：对于读到的每一行数据，计算 name = “TiDB” 这个表达式，如果为真，则向上返回这一行，否则丢弃这一行数据。 计算 Count(*)：对符合要求的每一行，累计到 Count(*) 的结果上面。 这个方案是直观且可行的，但是在分布式数据库的场景下有一些显而易见的问题： 在扫描数据的时候，每一行都要通过 KV 操作从 TiKV 中读取出来，至少有一次 RPC 开销，如果需要扫描的数据很多，那么这个开销会非常大。 并不是所有的行都满足过滤条件 name = “TiDB”，如果不满足条件，其实可以不读取出来。 此查询只要求返回符合要求行的数量，不要求返回这些行的值。 2.2 分布式 SQL 运算为了解决上述问题，计算应该需要尽量靠近存储节点，以避免大量的 RPC 调用。首先，SQL 中的谓词条件 name = “TiDB” 应被下推到存储节点进行计算，这样只需要返回有效的行，避免无意义的网络传输。然后，聚合函数 Count(*) 也可以被下推到存储节点，进行预聚合，每个节点只需要返回一个 Count(*) 的结果即可，再由 SQL 层将各个节点返回的 Count(*) 的结果累加求和。 以下是数据逐层返回的示意图： 2.3 SQL 层架构以上其实是简化后的SQL处理，实际上 TiDB 的 SQL 层要复杂得多，模块以及层次非常多，下图列出了重要的模块以及调用关系： 用户的 SQL 请求会直接或者通过 Load Balancer 发送到 TiDB Server，TiDB Server 会解析 MySQL Protocol Packet，获取请求内容，对 SQL 进行语法解析和语义分析，制定和优化查询计划，执行查询计划并获取和处理数据。数据全部存储在 TiKV 集群中，所以在这个过程中 TiDB Server 需要和 TiKV 交互，获取数据。最后 TiDB Server 需要将查询结果返回给用户。","link":"/2022/01/07/TiKV%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"Zookeeper中的Raft","text":"Zookeeper简介 Zab 协议 选举 崩溃恢复 广播 1. Zookeeper简介ZooKeeper是一个分布式协调服务，可用于服务发现、分布式锁、分布式领导选举、配置管理等。 这一切的基础，都是ZooKeeper提供了一个类似于Linux文件系统的树形结构（可认为是轻量级的内存文件系统，但只适合存少量信息，完全不适合存储大量文件或者大文件），同时提供了对于每个节点的监控与通知机制。 既然是一个文件系统，就不得不提ZooKeeper是如何保证数据的一致性的，如何进行领导选举，以及数据监控和通知机制的语义保证。 Zookeeper中的共识机制是一种改进型的Raft协议。称为ZAB协议。 2. Zab 协议Zab 协议分为三大块： 消息广播（boardcast）：Zab 协议中，所有的写请求都由 leader 来处理。正常工作状态下，leader 接收请求并通过广播协议来处理。 崩溃恢复（recovery）：当服务初次启动，或者 leader 节点挂了，系统就会进入恢复模式，直到选出了有合法数量 follower 的新 leader，然后新 leader 负责将整个系统同步到最新状态。 选举（Election）：Zab通过消息版本号选举出Leader来负责所在区域的写入工作。 3. 选举 epoch：选举的轮数。 zxid：事务id，值越大表示数据越新。 server：服务器的标示id。 选 epoch 最大的，epoch 相等时，选 zxid 最大的。epoch 和 zxid 都相等，选择 server id 最大的。 节点在选举开始都默认投票给自己，当接收其他节点的选票时，会根据上面的条件更改自己的选票并重新发送选票给其他节点，当有一个节点的得票超过半数，该节点会设置自己的状态为 leading，其他节点会设置自己的状态为 following。 选举状态： LOOKING: 竞选状态 FOLLOWING: 随从状态，同步 leader 状态，参与投票 OBSERVING: 观察状态，同步 leader 状态，不参与投票 LEADING: 领导者状态 4. 崩溃恢复在正常情况消息广播情况下能运行良好，但是一旦 Leader 服务器出现崩溃，或者由于网络原理导致 Leader 服务器失去了与过半 Follower 的通信，那么就会进入崩溃恢复模式，需要选举出一个新的 Leader 服务器。在这个过程中可能会出现两种数据不一致性的隐患，需要 ZAB 协议的特性进行避免。 1、Leader 服务器将消息 commit 发出后，立即崩溃。此时选举 zxid 最大的节点作为新的 leader2、Leader 服务器刚提出 proposal 后，立即崩溃。新 leader 还要将事务日志中尚未提交的消息进行处理。 5. 广播广播的过程实际上是一个简化的二阶段提交过程： Leader 接收到消息请求后，将消息赋予一个全局唯一的 64 位自增 id，叫做：zxid，通过 zxid 的大小比较即可实现因果有序这一特性。 Leader 通过先进先出队列（通过 TCP 协议来实现，以此实现了全局有序这一特性）将带有 zxid 的消息作为一个提案（proposal）分发给所有 follower。 当 follower 接收到 proposal，先将 proposal 写到硬盘，写硬盘成功后再向 leader 回一个 ACK。 当 leader 接收到合法数量的 ACKs 后，leader 就向所有 follower 发送 COMMIT 命令，同事会在本地执行该消息。 当 follower 收到消息的 COMMIT 命令时，就会执行该消息。","link":"/2022/01/11/Zookeeper%E4%B8%AD%E7%9A%84Raft/"},{"title":"etcd快速入门","text":"etcd概念 etcd 与 Zookeeper 的比较 etcd 应用场景 如何保证一致性？ 数据模型 1. etcd概念“A distributed, reliable key-value store for the most critical data of a distributed system” etcd 是一个分布式、可靠 key-value 存储的分布式系统。当然，它不仅仅用于存储，还提供共享配置及服务发现。 2. etcd 与 Zookeeper 的比较提供配置共享和服务发现的系统很多，其中Zookeeper较为知名。但在项目实现、一致性协议易理解性、运维、安全等多个维度上，etcd 相比 zookeeper 都占据优势。 一致性协议： etcd 使用 Raft 协议，Zookeeper 使用 ZAB协议，前者容易理解，方便工程实现。 运维方面：etcd 方便运维，Zookeeper 难以运维。 数据存储：etcd 多版本并发控制（MVCC）数据模型，支持查询先前版本的键值对。 项目活跃度：etcd 社区与开发活跃，Zookeeper 使用日益减少。 API：etcd 提供 HTTP+JSON, gRPC 接口，跨平台跨语言，而 Zookeeper 需要使用其客户端。 访问安全方面：etcd 支持 HTTPS 访问，Zookeeper 在这方面缺失。 3. etcd 应用场景etcd 比较多的应用场景是用于服务发现，服务发现 (Service Discovery) 要解决的是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务如何才能找到对方并建立连接。和 Zookeeper 类似，etcd 有很多使用场景，包括： 配置管理 服务注册发现 选举 应用调度 分布式队列 分布式锁 4. 如何保证一致性？etcd 使用 raft 协议来维护集群内各个节点状态的一致性。简单说，etcd 集群是一个分布式系统，由多个节点相互通信构成整体对外服务，每个节点都存储了完整的数据，并且通过 Raft 协议保证每个节点维护的数据是一致的。 每个 etcd 节点都维护了一个状态机，并且，任意时刻至多存在一个有效的主节点。主节点处理所有来自客户端写操作，通过 Raft 协议保证写操作对状态机的改动会可靠的同步到其他节点。 5. 数据模型etcd 的设计目标是用来存放非频繁更新的数据，提供可靠的 Watch插件，它暴露了键值对的历史版本，以支持低成本的快照、监控历史事件。这些设计目标要求它使用一个持久化的、多版本的、支持并发的数据数据模型。 当 etcd 键值对的新版本保存后，先前的版本依然存在。从效果上来说，键值对是不可变的，etcd 不会对其进行 in-place 的更新操作，而总是生成一个新的数据结构。为了防止历史版本无限增加，etcd 的存储支持压缩（Compact）以及删除老旧版本。 5.1 逻辑视图从逻辑角度看，etcd 的存储是一个扁平的二进制键空间，键空间有一个针对键（字节字符串）的词典序索引，因此范围查询的成本较低。 键空间维护了多个修订版本（Revisions），每一个原子变动操作（一个事务可由多个子操作组成）都会产生一个新的修订版本。在集群的整个生命周期中，修订版都是单调递增的。修订版同样支持索引，因此基于修订版的范围扫描也是高效的。压缩操作需要指定一个修订版本号，小于它的修订版会被移除。 一个键的一次生命周期（从创建到删除）叫做 “代 (Generation)”，每个键可以有多个代。创建一个键时会增加键的版本（version），如果在当前修订版中键不存在则版本设置为1。删除一个键会创建一个墓碑（Tombstone），将版本设置为0，结束当前代。每次对键的值进行修改都会增加其版本号 — 在同一代中版本号是单调递增的。 当压缩时，任何在压缩修订版之前结束的代，都会被移除。值在修订版之前的修改记录（仅仅保留最后一个）都会被移除。 5.2 物理视图etcd 将数据存放在一个持久化的 B+ 树中，处于效率的考虑，每个修订版仅仅存储相对前一个修订版的数据状态变化（Delta）。单个修订版中可能包含了 B+ 树中的多个键。 键值对的键，是三元组（major，sub，type）： major：存储键值的修订版 sub：用于区分相同修订版中的不同键 type：用于特殊值的可选后缀，例如 t 表示值包含墓碑键值对的值，包含从上一个修订版的 Delta。B+ 树 —— 键的词法字节序排列，基于修订版的范围扫描速度快，可以方便的从一个修改版到另外一个的值变更情况查找。 etcd 同时在内存中维护了一个 B 树索引，用于加速针对键的范围扫描。索引的键是物理存储的键面向用户的映射，索引的值则是指向 B+ 树修该点的指针。","link":"/2022/01/11/etcd%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"title":"etcd Raft库解析","text":"输入及输出 raft库代码结构及核心数据结构 节点状态 选举流程 集群成员变化流程 如何做到线性一致性 目录 1. 简介 2. 输入及输出 3. raft库代码结构及核心数据结构 3.1 日志存储：unstable 3.2 日志存储：Storage接口 3.3 日志存储：raftLog的实现 3.4 Raft 消息结构体 3.5 MsgHup消息 3.6 MsgBeat消息 3.7 MsgProp消息 3.8 MsgApp和MsgSnap消息 3.9 MsgAppResp消息 3.10 MsgVote/MsgPreVote/MsgVoteResp/MsgPreVoteResp 消息 3.11 MsgHeartbeat/MsgHeartbeatResp消息 3.12 MsgUnreachable消息 3.13 MsgSnapStatus消息 3.14 MsgCheckQuorum消息 3.15 MsgTransferLeader消息 3.16 MsgTimeoutNow消息 3.17 MsgReadIndex和MsgReadIndexResp消息 4. 节点状态 5. 选举流程 5.1 发起选举的节点 5.2 收到选举消息的节点 6. 集群成员变化流程 6.1 一般的成员删减 6.2 leader 转让 7. 如何做到线性一致性 8. 其他 8.1 节点的几种状态 8.2 Progress 上的数据索引 8.3 流量控制 1. 简介本文是继Raft算法原理一文之后的第二篇笔记，是对etcd Raft算法库的学习笔记，依旧是在codedump的网络日志基础之上所作。之所以详细的学习etcd对Raft算法原理的实现，是因为etcd的Raft实现最接近论文且应用广泛。 etcd Raft库的实现非常精妙，屏蔽了网络、存储等模块，提供了接口由上层应用来实现。 这里先给出部分名词的对照： 英文 中文 Term 选举任期，每次选举之后递增1 Vote 选举投票(的ID) Entry Raft算法的日志数据条目 leader 领导者 follower 跟随者 candidate 候选人 commit 提交 propose 提议 2. 输入及输出要想使用Raft库，就要确定它的输入和输出接口。作为一个一致性算法的库，不难想象使用的一般场景是这样的： 应用层接收到新的写入数据请求，向该算法库写入一个数据。 算法库返回是否写入成功。 应用层根据写入结果进行下一步的操作。 然而，Raft库却相对而言更复杂一些，因为还有下列问题存在： 写入的数据，可能是集群状态变更的数据，Raft库在执行写入这类数据之后，需要返回新的状态给应用层。 Raft库中的数据不可能一直以日志的形式存在，这样会导致数据越来越大，所以有必要压缩成快照的数据形式，这种情况下也需要返回这部分快照数据。 由于etcd的Raft库不包括持久化数据存储相关的模块，而是由应用层自己来做实现，所以也需要返回在某次写入成功之后，哪些数据可以进行持久化保存了。 同样的，etcd的Raft库也不自己实现网络传输，所以同样需要返回哪些数据需要进行网络传输给集群中的其他节点。 以上的这些内容，集中在raft/node.go的Ready结构体中，其包括以下成员： 成员名称 类型 作用 SoftState SoftState 软状态，软状态易变且不需要保存在WAL日志中的状态数据，包括：集群leader、节点的当前状态 HardState HardState 硬状态，与软状态相反，需要写入持久化存储中，包括：节点当前Term、Vote、Commit ReadStates []ReadStates 用于读一致性的数据，后续会详细介绍 Entries []pb.Entry 在向其他集群发送消息之前需要先写入持久化存储的日志数据 Snapshot pb.Snapshot 需要写入持久化存储中的快照数据 CommittedEntries []pb.Entry 需要输入到状态机中的数据，这些数据之前已经被保存到持久化存储中了 Messages []pb.Message 在entries被写入持久化存储中以后，需要发送出去的数据 根据上面的分析，应用层在写入一段数据之后，Raft库将返回这样一个Ready结构体，其中可能某些字段是空的，毕竟不是每次改动都会导致Ready结构体中的成员都发生变化，此时使用者就需要根据情况，取出其中不为空的成员进行操作。 在etcd项目中，也提供了使用Raft库的demo例子，在 contrib/raftexample 目录中，这里简单的演示了一下如何根据这个raft库实现一个简单的KV存储服务器，下面将根据代码结合着上面的Ready结构体，来分析etcd Raft库的使用。 Raft库对外提供一个Node的interface，其实现有 raft/node.go 中的node结构体实现，这也是应用层唯一需要与Raft库直接打交道的结构体，简单的来看看Node接口需要实现的函数： 函数 作用 Tick 应用层每次tick时需要调用该函数，将会由这里驱动raft的一些操作比如选举等。至于tick的单位是多少由应用层自己决定，只要保证是恒定时间都会来调用一次就好了 Campaign 调用该函数将驱动节点进入候选人状态，进而将竞争leader Propose 提议写入数据到日志中，可能会返回错误 ProposeConfChange 提交配置变更 Step 将消息msg灌入状态机中 Ready 这里是核心函数，将返回Ready的channel，应用层需要关注这个channel，当发生变更时将其中的数据进行操作 Advance Advance函数是当使用者已经将上一次Ready数据处理之后，调用该函数告诉raft库可以进行下一步的操作 我们暂且只看如何对接Ready结构体，在raftexample中，首先在main.go中创建了两个channel： proposeC：用于提交写入的数据 confChangeC：用于提交配置改动数据 然后分别启动如下核心的协程： 启动HTTP服务器，用于接收用户的请求数据，最终会将用户请求的数据写入前面的 proposeC/confChangeC channel 中。 启动raftNode结构体，该结构体中有上面提到的 raft/node.go 中的node结构体，也就是通过该结构体实现的Node接口与raft库进行交互。同时，raftNode还会启动协程监听前面的两个channel，收到数据之后通过Node接口的函数调用raft库对应的接口。 总结一下上面的交互流程：HTTP服务器负责接收用户数据，再写入到两个核心channel中，而raftNode负责监听这两个channel。 如果收到 proposeC channel 的消息，说明有数据提交，则调用Node.Propose函数进行数据的提交。 如果收到 confChangeC channel 的消息，说明有配置变更，则调用 Node.ProposeConfChange 函数进行配置变更。 设置一个定时器 tick，每次定时器到时时，调用 Node.Tick 函数。 监听 Node.Ready 函数返回的Ready结构体channel，有数据变更时根据Ready结构体的不同数据类型进行相应的操作，完成了之后需要调用Node.Advance函数进行收尾。 将以上流程用伪代码实现如下： 123456789101112131415161718// HTTP serverHttpServer主循环: 接收用户提交的数据： 如果是PUT请求： 将数据写入到proposeC中 如果是POST请求： 将配置变更数据写入到confChangeC中// raft NoderaftNode结构体主循环： 如果proposeC中有数据写入： 调用 node.Propose 向raft库提交数据 如果confChangeC中有数据写入： 调用 node.Node.ProposeConfChange 向raft库提交配置变更数据 如果tick定时器到期： 调用 node.Tick 函数进行raft库的定时操作 如果 node.Ready() 函数返回的Ready结构体channel有数据变更： 依次处理Ready结构体中各成员数据 处理完毕之后调用node.Advance函数进行收尾处理 看到这里，对raft的使用应该有了一个基本的概念，即通过node结构体实现的Node接口与raft库进行交互，涉及数据变更的核心数据结构就是Ready结构体，接下来可以进一步来分析该库的实现了。 3. raft库代码结构及核心数据结构在这一部分，来看下raft库的代码组织。 前面输入输出部分已经看到 raft/node.go 文件中，提供出去的是Node接口及其实现node结构体，这是外界与raft库交互的唯一接口，除此之外该路径下的其他文件并不直接与外界交互。 接着是raft算法的实现文件，raft/raft.go 文件，其中包含两个核心数据结构： Config：与raft算法相关的配置参数都包装在该结构体中。从这个结构体的命名是大写字母开头，就可以知道是提供给外部调用的。 raft：具体实现raft算法的结构体。 除去上面两个文件，raft目录下的其他文件，都是间接给raft结构体服务的，下面的表格做一个总结和罗列： 结构体/接口 所在文件 作用 Node接口 node.go 提供raft库与外界交互的接口 node node.go 实现Node接口 Config raft.go 封装raft算法相关配置参数 raft raft.go raft算法的实现 ReadState read_only.go 线性一致性读相关 readOnly read_only.go 线性一致性读相关 raftLog log.go 实现raft日志操作 Progress progress.go 该数据结构用于在leader中保存每个follower的状态信息，leader将根据这些信息决定发送给节点的日志 Storage接口 storage.go 提供存储接口，应用层可以按照自己的需求实现该接口 3.1 日志存储：unstable顾名思义，unstable数据结构用于还没有被用户层持久化的数据，而其中又包括两部分，如下图所示： 如图，前半部分是快照数据，而后半部分是日志条目组成的数组entries，另外 unstable.offset 成员保存的是entries数组中的第一条数据在raft日志中的索引，即第i条entries数组数据在raft日志中的索引为i + unstable.offset。 这两个部分，并不同时存在，同一时间只有一个部分存在。其中，快照数据只有当前节点在接收从leader发送过来的快照数据时存在，在接收快照数据的时候，entries数组中是没有数据的；除了这种情况之外，就只会存在entries数组的数据了。因此，当接收完毕快照数据进入正常的接收日志流程时，快照数据将被置空。 理解了以上unstable中数据的分布情况，就不难理解unstable各个函数成员的作用了： maybeFirstIndex：返回unstable数据的第一条数据索引。因为只有快照数据在最前面，因此这个函数只有当快照数据存在的时候才能拿到第一条数据索引，其他的情况下已经拿不到了。 maybeLastIndex：返回最后一条数据的索引。因为是entries数据在后，而快照数据在前，所以取最后一条数据索引是从entries开始查，查不到的情况下才查快照数据。 maybeTerm：这个函数根据传入的日志数据索引，得到这个日志对应的任期号。前面已经提过，unstable.offset是快照数据和entries数组的分界线，因为在这个函数中，会区分传入的参数与offset的大小关系，小于offset的情况下在快照数据中查询，否则就在entries数组中查询了。 stableTo：该函数传入一个索引号i和任期号t，表示应用层已经将这个索引之前的数据进行持久化了，此时unstable要做的事情就是在自己的数据中查询，只有在满足任期号相同以及i大于等于offset的情况下，可以将entries中的数据进行缩容，将i之前的数据删除。 stableSnapTo：该函数传入一个索引i，用于告诉unstable，索引i对应的快照数据已经被应用层持久化了，如果这个索引与当前快照数据对应的上，那么快照数据就可以被置空了。 restore：从快照数据中恢复，此时unstable将保存快照数据，同时将offset成员设置成这个快照数据索引的下一位。 truncateAndAppend：传入日志条目数组，这段数据将添加到entries数组中。但是需要注意的是，传入的数据跟现有的entries数据可能有重合的部分，所以需要根据unstable.offset与传入数据的索引大小关系进行处理，有些数据可能会被截断。 slice：返回索引范围在[lo-u.offset : hi-u.offset]之间的数据。 mustCheckOutOfBounds：检查传入的数据索引范围是否合理。 3.2 日志存储：Storage接口Storage接口，提供了存储持久化日志相关的接口操作. InitialState() (pb.HardState, pb.ConfState, error)：返回当前的初始状态，其中包括硬状态（HardState）以及配置（里面存储了集群中有哪些节点）。 Entries(lo, hi, maxSize uint64) ([]pb.Entry, error)：传入起始和结束索引值，以及最大的尺寸，返回索引范围在这个传入范围以内并且不超过大小的日志条目数组。 Term(i uint64) (uint64, error)：传入日志索引i，返回这条日志对应的任期号。找不到的情况下error返回值不为空，其中当返回ErrCompacted表示传入的索引数据已经找不到，说明已经被压缩成快照数据了；返回ErrUnavailable：表示传入的索引值大于当前的最大索引。 LastIndex() (uint64, error)：返回最后一条数据的索引。 FirstIndex() (uint64, error)：返回第一条数据的索引。 Snapshot() (pb.Snapshot, error)：返回最近的快照数据。 codedump对这个接口提供的接口函数存有疑问，因为在所有etcd代码中，该接口只有MemoryStorage一个实现，而实际上MemoryStorage这个结构体还有其他的函数，比如添加日志数据的操作，但是这个操作并没有在Storage接口中声明。而Storage接口的 MemoryStorage 结构体的实现，其成员主要包括以下几个部分： hardState pb.HardState：存储硬状态。 snapshot pb.Snapshot：存储快照数据。 ents []pb.Entry：存储紧跟着快照数据的日志条目数组，即ents[i]保存的日志数据索引位置为i + snapshot.Metadata.Index。 3.3 日志存储：raftLog的实现在unstable、Storage的基础上，我们来看一下raftLog的实现，这个结构体承担了raft日志相关的操作，它由一下成员组成： storage Storage：前面提到的存放已经持久化数据的Storage接口。 unstable unstable：前面分析过的unstable结构体，用于保存应用层还没有持久化的数据。 committed uint64：保存当前提交的日志数据索引。 applied uint64：保存当前传入状态机的数据最高索引。 在Raft算法原理中也提到过，一条日志数据，首先需要先被提交（committed）成功，才能被应用（applied）到状态机中。因此，以下不等式一直成立：applied &lt;= committed。 raftLog结构体中，几部分数据的排列如下图所示： 这个数据排布的情况，可以从raftLog的初始化函数中看出来： 12345678910111213141516171819202122232425func newLog(storage Storage, logger Logger) *raftLog { if storage == nil { log.Panic(&quot;storage must not be nil&quot;) } log := &amp;raftLog{ storage: storage, logger: logger, } firstIndex, err := storage.FirstIndex() if err != nil { panic(err) // TODO(bdarnell) } lastIndex, err := storage.LastIndex() if err != nil { panic(err) // TODO(bdarnell) } // offset从持久化之后的最后一个index的下一个开始 log.unstable.offset = lastIndex + 1 log.unstable.logger = logger // Initialize our committed and applied pointers to the time of the last compaction. // committed和applied从持久化的第一个index的前一个开始 log.committed = firstIndex - 1 log.applied = firstIndex - 1 return log} 在这里： firstIndex：该值取自storage.FirstIndex()，可以从MemoryStorage的实现看到，该值是MemoryStorage.ents数组的第一个数据索引，也就是MemoryStorage结构体中快照数据与日志条目数据的分界线。 lastIndex：该值取自storage.LastIndex()，可以从MemoryStorage的实现看到，该值是MemoryStorage.ents数组的最后一个数据索引。 unstable.offset：该值为lastIndex索引的下一个位置。 committed、applied：在初始的情况下，这两个值是firstIndex的上一个索引位置，这是因为在firstIndex之前的数据既然已经是持久化数据了，说明都是已经被提交成功的数据了。 因此，从这里的代码分析可以看出，raftLog的两部分，持久化存储和非持久化存储，它们之间的分界线就是lastIndex，在此之前都是Storage管理的已经持久化的数据，而在此之后都是unstable管理的还没有持久化的数据。 以上分析中还有一个疑问，为什么并没有初始化unstable.snapshot成员，即unstable结构体的快照数据？这是因为，上面这个是初始化函数，也就是节点刚启动的时候调用来初始化存储状态的函数，而 unstable.snapshot 数据，是在启动之后同步数据的过程中，如果需要同步快照数据时才会去进行赋值修改的数据，因此在这里并不需要对其操作。 3.4 Raft 消息结构体大体而言，raft算法本质上是一个大的状态机，任何的操作例如选举、提交数据等，最后的操作一定是封装成一个消息结构体，输入到raft算法库的状态机中。 在raft/raftpb/raft.proto文件中，定义了raft算法中传输消息的结构体。熟悉raft论文的都知道，raft算法其实由好几个协议组成，但是在这里，统一定义在了Message这个结构体之中，以下总结了该结构体的成员用途。 成员 类型 作用 type MessageType 消息类型 to uint64 消息接收者的节点ID from uint64 消息发送者的节点ID term uint64 任期ID logTerm uint64 日志所处的任期ID index uint64 日志索引ID，用于节点向leader汇报自己已经commit的日志数据ID entries Entry 日志条目数组 commit uint64 提交日志索引 snapshot Snapshot 快照数据 reject bool 是否拒绝 rejectHint uint64 拒绝同步日志请求时返回的当前节点日志ID，用于被拒绝方快速定位到下一次合适的同步日志位置 context bytes 上下文数据 由于这个Message结构体，全部将raft协议相关的数据都定义在了一起，有些协议不是用到其中的全部数据，所以这里的字段都是可选的，codedump认为这样不好，这会看起来杂乱无章，所以有必要将每个协议（即不同的消息类型）中使用的用途分别记录。 3.5 MsgHup消息 成员 类型 作用 type MsgHup 不用于节点间通信，仅用于发送给节点让节点进行选举 to uint64 消息接收者的节点ID from uint64 本节点ID 3.6 MsgBeat消息 成员 类型 作用 type MsgBeat 仅用于leader节点在heartbeat定时器到期时向集群中其他节点发送心跳消息 to uint64 消息接收者的节点ID from uint64 本节点ID 3.7 MsgProp消息 成员 类型 作用 type MsgProp raft库使用者提议（propose）数据 to uint64 消息接收者的节点ID from uint64 本节点ID entries Entry 日志条目数组 raft库的使用者向raft库propose数据时，最后会封装成这个类型的消息来进行提交，不同类型的节点处理不同: candidate由于candidate节点没有处理propose数据的责任，直接忽略这类消息。 follower首先检查集群内是否有leader存在，如果当前没有leader存在，说明还在选举过程中，直接忽略这类消息；否则转发给leader处理。 leaderleader对MsgProp消息的处理如下： 检查entries数组是否没有数据，这是一个保护性检查。 检查本节点是否还在集群之中，如果已经不在了则直接返回不进行下一步处理。什么情况下会出现一个leader节点发现自己不存在集群之中了？这在Raft算法原理中提到过，这种情况出现在本节点已经通过配置变化被移除出了集群的场景。 检查 raft.leadTransferee 字段，当这个字段不为0时说明正在进行leader迁移操作，这种情况下不允许提交数据变更操作，因此此时也是直接返回的。 检查消息的entries数组，看其中是否带有配置变更的数据。如果其中带有数据变更而 raft.pendingConf为true，说明当前有未提交的配置更操作数据，根据raft论文，每次不同同时进行一次以上的配置变更，因此这里会将entries数组中的配置变更数据置为空数据。 到了这里可以进行真正的数据propose操作了，将调用raft算法库的日志模块写入数据，根据返回的情况向其他节点广播消息。 3.8 MsgApp和MsgSnap消息MsgApp消息 成员 类型 作用 type MsgApp 用于leader向集群中其他节点同步数据的消息 to uint64 消息接收者的节点ID from uint64 本节点ID entries Entry 日志条目数组 logTerm uint64 日志所处的任期ID index uint64 索引ID MsgSnap消息 成员 类型 作用 type MsgSnap 用于leader向follower同步数据用的快照消息 to uint64 消息接收者的节点ID from uint64 本节点ID snapshot Snapshot 快照数据 如果说前面的MsgProp消息是集群中的节点向leader转发用户提交的数据，那么MsgApp消息就是相反的，是leader节点用于向集群中其他节点同步数据的。 之所以把MsgSnap消息和MsgApp消息放在一起，是因为MsgSnap消息做的事情其实跟前面提到的MsgApp消息是一样的：都是用于leader向follower同步数据。实际上对于leader而言，向某个节点同步数据这个操作，都封装在 raft.sendAppend 函数中，至于具体用的哪种消息类型由这个函数内部实现。 什么情况下会用到快照数据来同步呢？raft算法中，任何的数据要提交成功，首先leader会在本地写一份日志，再广播出去给集群的其他节点，只有在超过半数以上的节点同意，leader才能进行提交操作。 但是，日志文件不能无限的增长。因此某些时刻，节点会将日志数据进行压缩处理，即把数据写入一个快照文件中。而leader在向某一个节点进行数据同步时，是根据该节点上的日志记录进行数据同步的。例如，leader上有最大索引为10的日志数据，而节点A的日志索引是2，那么leader将从3开始向节点A同步数据。 如果前面的数据已经进行了压缩处理，转换成了快照数据，而压缩后的快照数据实际上已经没有日志索引相关的信息了，这时只能将快照数据全部同步给节点。假如leader上日志索引为7之前的数据都已经被压缩成了快照数据，那么这部分数据在同步时是需要整份传输过去的，只有当同步完成节点赶上了leader上的日志进度时，才开始正常的日志同步流程。而同步数据时，需要区分两种情况。 3.9 MsgAppResp消息 成员 类型 作用 type MsgAppResp 集群中其他节点针对leader的MsgApp/MsgSnap消息的应答消息 to uint64 消息接收者的节点ID from uint64 本节点ID index uint64 日志索引ID，用于节点向leader汇报自己已经commit的日志数据ID reject bool 是否拒绝同步日志的请求 rejectHint uint64 拒绝同步日志请求时返回的当前节点日志ID，用于被拒绝方快速定位到下一次合适的同步日志位置 在节点收到leader的 MsgApp/MsgSnap 消息时，可能出现leader上的数据与自身节点数据不一致的情况，这种情况下会返回reject为true的MsgAppResp消息，同时rejectHint字段是本节点raft最后一条日志的索引ID。 index字段则返回的是当前节点的日志索引ID，用于向leader汇报自己已经commit的日志数据ID，这样leader就知道下一次同步数据给这个节点时，从哪条日志数据继续同步了。 leader节点在收到MsgAppResp消息的处理流程大体如下（stepLeader 函数中 MsgAppResp case 的处理流程）。 首先，收到节点的MsgAppResp消息，说明该节点是活跃的，因此保存节点状态的RecentActive成员置为true。 接下来，再根据msg.Reject的返回值，即节点是否拒绝了这次数据同步，来区分两种情况进行处理： msg.Reject 等于 true 的情况如果msg.Reject为true，说明节点拒绝了前面的 MsgApp/MsgSnap 消息，根据 msg.RejectHint 成员回退leader上保存的关于该节点的日志记录状态。比如leader前面认为从日志索引为10的位置开始向节点A同步数据，但是节点A拒绝了这次数据同步，同时返回RejectHint为2，说明节点A告知leader在它上面保存的最大日志索引ID为2，这样下一次leader就可以直接从索引为2的日志数据开始同步数据到节点A。而如果没有这个RejectHint成员，leader只能在每次被拒绝数据同步后都递减1进行下一次数据同步，显然这样是低效的。 因为上面节点拒绝了这次数据同步，所以节点的状态可能存在一些异常，此时如果leader上保存的节点状态为 ProgressStateReplicate，那么将切换到 ProgressStateProbe 状态。 前面已经按照 msg.RejectHint 修改了leader上关于该节点日志状态的索引数据，接着再次尝试按照这个新的索引数据向该节点再次同步数据。 msg.Reject 等于 false 的情况这种情况说明该节点通过了leader的数据同步请求，这种情况下根据 msg.Index 来判断在leader中保存的该节点日志数据索引是否发生了更新，如果发生了更新那么就说明这个节点通过了新的数据，这种情况下会做以下的几个操作。 修改节点状态 如果该节点之前在 ProgressStateProbe 状态，说明之前处于探测状态，此时可以切换到 ProgressStateReplicate，开始正常的接收leader的同步数据了。 如果之前处于 ProgressStateSnapshot 状态，即还在同步副本，说明节点之前可能落后leader数据比较多才采用了接收副本的状态。在节点落后leader数据很多的情况下，可能leader会多次通过snapshot同步数据给节点，而当 pr.Match &gt;= pr.PendingSnapshot 的时候，说明通过快照来同步数据的流程完成了，这时可以进入正常的接收同步数据状态了，这就是函数 Progress.needSnapshotAbort 要做的判断。 如果之前处于 ProgressStateReplicate 状态，此时可以修改leader关于这个节点的滑动窗口索引，释放掉这部分数据索引，好让节点可以接收新的数据了。 判断是否有新的数据可以提交（commit）了。因为raft的提交数据的流程是这样的：首先节点将数据提议（propose）给leader，leader在将数据写入到自己的日志成功之后，再通过MsgApp把这些提议的数据广播给集群中的其他节点，在某一条日志数据收到超过半数（qurom）的节点同意之后，才认为是可以提交（commit）的。因此每次leader节点在收到一条MsgAppResp类型消息，同时msg.Reject又是false的情况下，都需要去检查当前有哪些日志是超过半数的节点同意的，再将这些可以提交（commit）的数据广播出去。而在没有数据可以提交的情况下，如果之前节点处于暂停状态，那么将继续向该节点同步数据。 最后还要做一个跟leader迁移相关的操作。如果该消息节点是准备迁移过去的新leader节点（raft.leadTransferee == msg.From），而且此时该节点上的Match索引已经跟旧的leader的日志最大索引一致，说明新旧节点的日志数据已经同步，可以正式进行集群leader迁移操作了。 3.10 MsgVote/MsgPreVote/MsgVoteResp/MsgPreVoteResp 消息之所以把这四种消息放在一起了，是因为Vote和PreVote流程的请求和应答时传输的数据是相同的。 请求数据 成员 类型 作用 type MsgVote/MsgPreVote 节点投票给自己以进行新一轮的选举 to uint64 消息接收者的节点ID from uint64 本节点ID term uint64 任期ID index uint64 日志索引ID，用于节点向leader汇报自己已经commit的日志数据ID logTerm uint64 日志所处的任期ID context bytes 上下文数据 应答数据 成员 类型 作用 type MsgVoteResp/MsgPreVoteResp 投票应答消息 to uint64 消息接收者的节点ID from uint64 本节点ID reject bool 是否拒绝 节点调用 raft.campaign 函数进行投票给自己进行一次新的选举，其中的参数 CampaignType 有以下几种类型： campaignPreElection：对应PreVote的场景。 campaignElection：正常的选举场景。 campaignTransfer：由于leader迁移发生的选举。如果是这种类型的选举，那么 msg.Context 字段保存的是“CampaignTransfer”字符串，这种情况下会强制进行leader的迁移。 MsgVote还需要带上几个与本节点日志相关的数据（Index、LogTerm），因为raft算法要求，一个节点要成为leader的一个必要条件之一就是这个节点上的日志数据是最新的。 PreVote这里需要特别解释一下PreVote的场景。 考虑到一种情况：当出现网络分区的时候，A、B、C、D、E五个节点被划分成了两个网络分区，A、B、C组成的分区和D、E组成的分区，其中的D节点，如果在选举超时到来时，都没有收到来自leader节点A的消息（因为网络已经分区），那么D节点认为需要开始一次新的选举了。 正常的情况下，节点D应该把自己的任期号term递增1，然后发起一次新的选举。由于网络分区的存在，节点D肯定不会获得超过半数以上的的投票，因为A、B、C三个节点组成的分区不会收到它的消息，这会导致节点D不停的由于选举超时而开始一次新的选举，而每次选举又会递增任期号。 在网络分区还没恢复的情况下，这样做问题不大。但是当网络分区恢复时，由于节点D的任期号大于当前leader节点的任期号，这会导致集群进行一次新的选举，即使节点D肯定不会获得选举成功的情况下（因为节点D的日志落后当前集群太多，不能赢得选举成功）。 为了避免这种无意义的选举流程，节点可以有一种PreVote的状态，在这种状态下，想要参与选举的节点会首先连接集群的其他节点，只有在超过半数以上的节点连接成功时，才能真正发起一次新的选举。 所以，在PreVote状态下发起选举时，并不会导致节点本身的任期号递增1，而只有在进行正常选举时才会将任期号加1进行选举。 MsgVote/MsgPreVote的处理流程节点对于投票消息的处理有两处，但都在raft.Step函数中。 首先该函数会判断 msg.Term 是否大于本节点的Term，如果消息的任期号更大则说明是一次新的选举。这种情况下将根据 msg.Context 是否等于“CampaignTransfer”字符串来确定是不是一次由于leader迁移导致的强制选举过程。同时也会根据当前的 electionElapsed 是否小于 electionTimeout 来确定是否还在租约期以内。如果既不是强制leader选举又在租约期以内，那么节点将忽略该消息的处理，这是为了避免已经离开集群的节点仍然频繁向集群内节点发起无意义的选举。如果以上检查流程通过了，说明可以进行选举了，如果消息类型还不是MsgPreVote类型，那么此时节点会切换到follower状态且认为发送消息过来的节点 msg.From 是新的leader。 1234567891011121314151617181920212223242526272829303132333435363738 case m.Term &gt; r.Term:// 消息的Term大于节点当前的Termlead := m.Fromif m.Type == pb.MsgVote || m.Type == pb.MsgPreVote { // 如果收到的是投票类消息 // 当context为campaignTransfer时表示强制要求进行竞选 force := bytes.Equal(m.Context, []byte(campaignTransfer)) // 是否在租约期以内 inLease := r.checkQuorum &amp;&amp; r.lead != None &amp;&amp; r.electionElapsed &lt; r.electionTimeout if !force &amp;&amp; inLease { // 如果非强制，而且又在租约期以内，就不做任何处理 // 非强制又在租约期内可以忽略选举消息，见论文的4.2.3，这是为了阻止已经离开集群的节点再次发起投票请求 // If a server receives a RequestVote request within the minimum election timeout // of hearing from a current leader, it does not update its term or grant its vote r.logger.Infof(&quot;%x [logterm: %d, index: %d, vote: %x] ignored %s from %x [logterm: %d, index: %d] at term %d: lease is not expired (remaining ticks: %d)&quot;, r.id, r.raftLog.lastTerm(), r.raftLog.lastIndex(), r.Vote, m.Type, m.From, m.LogTerm, m.Index, r.Term, r.electionTimeout-r.electionElapsed) return nil } // 否则将lead置为空 lead = None}switch {// 注意Go的switch case不做处理的话是不会默认走到default情况的case m.Type == pb.MsgPreVote: // Never change our term in response to a PreVote // 在应答一个prevote消息时不对任期term做修改case m.Type == pb.MsgPreVoteResp &amp;&amp; !m.Reject: // We send pre-vote requests with a term in our future. If the // pre-vote is granted, we will increment our term when we get a // quorum. If it is not, the term comes from the node that // rejected our vote so we should become a follower at the new // term.default: r.logger.Infof(&quot;%x [term: %d] received a %s message with higher term from %x [term: %d]&quot;, r.id, r.Term, m.Type, m.From, m.Term) // 变成follower状态 r.becomeFollower(m.Term, lead)} 在 raft.Step 函数的后面，会判断消息类型是MsgVote或者MsgPreVote来进一步进行处理。其判断条件是以下两个条件同时成立： 当前没有给任何节点进行过投票（r.Vote == None ），或者消息的任期号更大（m.Term &gt; r.Term ），或者是之前已经投过票的节点（r.Vote == m.From)）。这个条件是检查是否可以还能给该节点投票。 同时该节点的日志数据必须是最新的（r.raftLog.isUpToDate(m.Index, m.LogTerm) ）。这个条件是检查这个节点上的日志数据是否足够的新。 只有在满足以上两个条件的情况下，节点才投票给这个消息节点，将修改raft.Vote为消息发送者ID。如果不满足条件，将应答msg.Reject=true，拒绝该节点的投票消息。 1234567891011121314151617181920212223case pb.MsgVote, pb.MsgPreVote: // 收到投票类的消息 // The m.Term &gt; r.Term clause is for MsgPreVote. For MsgVote m.Term should // always equal r.Term. if (r.Vote == None || m.Term &gt; r.Term || r.Vote == m.From) &amp;&amp; r.raftLog.isUpToDate(m.Index, m.LogTerm) { // 如果当前没有给任何节点投票（r.Vote == None）或者投票的节点term大于本节点的（m.Term &gt; r.Term） // 或者是之前已经投票的节点（r.Vote == m.From） // 同时还满足该节点的消息是最新的（r.raftLog.isUpToDate(m.Index, m.LogTerm)），那么就接收这个节点的投票 r.logger.Infof(&quot;%x [logterm: %d, index: %d, vote: %x] cast %s for %x [logterm: %d, index: %d] at term %d&quot;, r.id, r.raftLog.lastTerm(), r.raftLog.lastIndex(), r.Vote, m.Type, m.From, m.LogTerm, m.Index, r.Term) r.send(pb.Message{To: m.From, Type: voteRespMsgType(m.Type)}) if m.Type == pb.MsgVote { // Only record real votes. // 保存下来给哪个节点投票了 r.electionElapsed = 0 r.Vote = m.From } } else { // 否则拒绝投票 r.logger.Infof(&quot;%x [logterm: %d, index: %d, vote: %x] rejected %s from %x [logterm: %d, index: %d] at term %d&quot;, r.id, r.raftLog.lastTerm(), r.raftLog.lastIndex(), r.Vote, m.Type, m.From, m.LogTerm, m.Index, r.Term) r.send(pb.Message{To: m.From, Type: voteRespMsgType(m.Type), Reject: true}) } MsgVoteResp/MsgPreVoteResp的处理流程接下来看节点收到投票应答数据之后的处理。 节点调用 raft.poll 函数，其中传入 msg.Reject 参数表示发送者是否同意这次选举，根据这些来计算当前集群中有多少节点给这次选举投了同意票。如果有半数的节点同意了，如果选举类型是PreVote，那么进行Vote状态正式进行一轮选举；否则该节点就成为了新的leader，调用 raft.becomeLeader 函数切换状态，然后开始同步日志数据给集群中其他节点了。而如果半数以上的节点没有同意，那么重新切换到follower状态。 1234567891011121314151617case myVoteRespType: // 计算当前集群中有多少节点给自己投了票 gr := r.poll(m.From, m.Type, !m.Reject) r.logger.Infof(&quot;%x [quorum:%d] has received %d %s votes and %d vote rejections&quot;, r.id, r.quorum(), gr, m.Type, len(r.votes)-gr) switch r.quorum() { case gr: // 如果进行投票的节点数量正好是半数以上节点数量 if r.state == StatePreCandidate { r.campaign(campaignElection) } else { // 变成leader r.becomeLeader() r.bcastAppend() } case len(r.votes) - gr: // 如果是半数以上节点拒绝了投票 // 变成follower r.becomeFollower(r.Term, None) } 3.11 MsgHeartbeat/MsgHeartbeatResp消息心跳请求消息 成员 类型 作用 type MsgHeartbeat 用于leader向follower发送心跳消息 to uint64 消息接收者的节点ID from uint64 本节点ID commit uint64 提交日志索引 context bytes 上下文数据，在这里保存一致性读相关的数据 心跳请求应答消息 成员 类型 作用 type MsgHeartbeatResp 用于follower向leader应答心跳消息 to uint64 消息接收者的节点ID from uint64 本节点ID context bytes 上下文数据，在这里保存一致性读相关的数据 leader中会定时向集群中其他节点发送心跳消息，该消息的作用除了探测节点的存活情况之外，还包括： commit成员：leader选择min(节点上的Match，leader日志最大提交索引)，用于告知节点哪些日志可以进行提交（commit）。 context：与线性一致性读相关，后文会做解释。 3.12 MsgUnreachable消息 成员 类型 作用 type MsgUnreachable 用于应用层向raft库汇报某个节点当前已不可达 to uint64 消息接收者的节点ID from uint64 不可用的节点ID 仅leader才处理这类消息，leader如果判断该节点此时处于正常接收数据的状态（ProgressStateReplicate），那么就切换到探测状态。 3.13 MsgSnapStatus消息 成员 类型 作用 type MsgSnapStatus 用于应用层向raft库汇报某个节点当前接收快照状态 to uint64 消息接收者的节点ID from uint64 节点ID reject bool 是否拒绝 仅leader处理这类消息： 如果reject为false：表示接收快照成功，将切换该节点状态到探测状态。 否则接收失败。 3.14 MsgCheckQuorum消息 成员 类型 作用 type MsgCheckQuorum 用于leader检查集群可用性的消息 to uint64 消息接收者的节点ID from uint64 节点ID leader的定时器函数，在超过选举时间时，如果当前打开了 raft.checkQuorum 开关，那么leader将给自己发送一条 MsgCheckQuorum 消息，对该消息的处理是：检查集群中所有节点的状态，如果超过半数的节点都不活跃了，那么leader也切换到follower状态。 3.15 MsgTransferLeader消息 成员 类型 作用 type MsgTransferLeader 用于迁移leader to uint64 消息接收者的节点ID from uint64 新leader的节点ID 这类消息由follower将转发给leader处理，因为follower并没有修改集群配置状态的权限。leader在收到这类消息时，是以下的处理流程： 如果当前的 raft.leadTransferee 成员不为空，说明有正在进行的leader迁移流程。此时会判断是否与这次迁移是同样的新leader ID，如果是则忽略该消息直接返回；否则将终止前面还没有完毕的迁移流程。 如果这次迁移过去的新节点，就是当前的leader ID，也直接返回不进行处理。 到了这一步就是正式开始这一次的迁移leader流程了，一个节点能成为一个集群的leader，其必要条件是上面的日志与当前leader的一样多，所以这里会判断是否满足这个条件，如果满足那么发送MsgTimeoutNow消息给新的leader通知该节点进行leader迁移，否则就先进行日志同步操作让新的leader追上旧leader的日志数据。 123456789101112131415161718192021222324252627282930313233343536case pb.MsgTransferLeader: leadTransferee := m.From lastLeadTransferee := r.leadTransferee if lastLeadTransferee != None { // 判断是否已经有相同节点的leader转让流程在进行中 if lastLeadTransferee == leadTransferee { r.logger.Infof(&quot;%x [term %d] transfer leadership to %x is in progress, ignores request to same node %x&quot;, r.id, r.Term, leadTransferee, leadTransferee) // 如果是，直接返回 return } // 否则中断之前的转让流程 r.abortLeaderTransfer() r.logger.Infof(&quot;%x [term %d] abort previous transferring leadership to %x&quot;, r.id, r.Term, lastLeadTransferee) } // 判断是否转让过来的leader是否本节点，如果是也直接返回，因为本节点已经是leader了 if leadTransferee == r.id { r.logger.Debugf(&quot;%x is already leader. Ignored transferring leadership to self&quot;, r.id) return } // Transfer leadership to third party. r.logger.Infof(&quot;%x [term %d] starts to transfer leadership to %x&quot;, r.id, r.Term, leadTransferee) // Transfer leadership should be finished in one electionTimeout, so reset r.electionElapsed. r.electionElapsed = 0 r.leadTransferee = leadTransferee if pr.Match == r.raftLog.lastIndex() { // 如果日志已经匹配了，那么就发送timeoutnow协议过去 r.sendTimeoutNow(leadTransferee) r.logger.Infof(&quot;%x sends MsgTimeoutNow to %x immediately as %x already has up-to-date log&quot;, r.id, leadTransferee, leadTransferee) } else { // 否则继续追加日志 r.sendAppend(leadTransferee) } 3.16 MsgTimeoutNow消息 成员 类型 作用 type MsgTimeoutNow leader迁移时，当新旧leader的日志数据同步后，旧leader向新leader发送该消息通知可以进行迁移了 to uint64 新的 leader ID from uint64 旧的 leader ID 新的leader节点，在还未迁移之前仍然是follower，在收到这条消息后，就可以进行迁移了，此时会调用前面分析MsgVote时说过的campaign函数，传入的参数是 campaignTransfer，表示这是一次由于迁移leader导致的选举流程。 3.17 MsgReadIndex和MsgReadIndexResp消息这两个消息一一对应，使用的成员也一样。 成员 类型 作用 type MsgReadIndex 用于读一致性的消息 to uint64 接收者节点ID from uint64 发送者节点ID entries Entry 日志条目数组 其中，entries数组只会有一条数据，带上的是应用层此次请求的标识数据，在follower收到MsgReadIndex消息进行应答时，同样需要把这个数据原样带回返回给leader，详细的线性读一致性的实现在后文展开分析。 4. 节点状态每个raft的节点，分为以下三种状态： candidate：候选人状态，节点切换到这个状态时，意味着将进行一次新的选举。 follower：跟随者状态，节点切换到这个状态时，意味着选举结束。 leader：领导者状态，所有数据提交都必须先提交到leader上。 每一个状态都有其对应的状态机，每次收到一条提交的数据时，都会根据其不同的状态将消息输入到不同状态的状态机中。同时，在进行tick操作时，每种状态对应的处理函数也不同。 所以raft结构体中将不同的状态，及其不同的处理函数独立出来几个成员变量： 成员 作用 state 保存当前节点状态 tick函数 tick函数，每个状态对应的tick函数不同 step函数 状态机函数，同样每个状态对应的状态机也不相同 raft库中提供函数 becomeCandidate、becomeFollower、becomeLeader 分别进入这三种状态，这些函数中做的事情，概况起来就是： 切换raft.state成员到对应状态。 切换raft.tick函数到对应状态的处理函数。 切换raft.step函数到对应状态的状态机。 5. 选举流程raft算法的第一步是首先选举出一个leader出来，在没有产生leader的情况下，其他数据提交等操作都无从谈起，所以先从选举的流程开始说起。 5.1 发起选举的节点只有在candidate或者follower状态下的节点，才有可能发起一个选举流程，而这两种状态的节点，其对应的tick函数都是raft.tickElection函数，这个函数的主要流程是： 将选举超时递增1。 当选举超时到期，同时该节点又在集群中时，说明此时可以进行一轮新的选举。此时会向本节点发送HUP消息，这个消息最终会走到状态机函数raft.Step中进行处理。 明白了raft.tickElection函数的作用，可以来看选举流程了： 节点启动时都以follower状态启动，同时随机选择自己的选举超时时间，这是为了避免同时有两个节点同时进行选举，这种情况下会出现没有节点赢得半数以上投票从而这一轮选举失败，继续再进行下一轮选举。 在follower的tick函数 tickElection 函数中，当选举超时到时，节点向自己发送HUP消息。 在状态机函数 raft.Step 函数中，在收到HUP消息之后，节点首先判断当前有没有没有apply的配置变更消息，如果有就忽略该消息。其原因在于，当有配置更新的情况下不能进行选举操作，即要保证每一次集群成员变化时只能同时变化一个，不能同时有多个集群成员的状态发生变化。 否则进入 campaign 函数中进行选举：首先将任期号+1，然后广播给其他节点选举消息，带上的其它字段包括：节点当前的最后一条日志索引（Index字段），最后一条日志对应的任期号（LogTerm字段），选举任期号（Term字段，即前面已经进行+1之后的任期号），Context字段（目的是为了告知这一次是否是leader转让类需要强制进行选举的消息）。 如果在一个选举超时之内，该发起新的选举流程的节点，得到了超过半数的节点投票，那么状态就切换到leader状态，成为leader的同时，leader将发送一条dummy的append消息，目的是为了提交该节点上在此任期之前的值（见疑问部分如何提交之前任期的值） 5.2 收到选举消息的节点 当收到任期号大于当前节点任期号的消息，同时该消息类型如果是选举类的消息（类型为prevote或者vote）时，会做以下判断： 首先会判断一下该消息是否为强制要求进行选举的类型（context为campaignTransfer，context为这种类型时表示在进行leader转让，流程见下面的leader转让流程） 判断当前是否在租约期以内，判断的条件包括：checkQuorum为true，当前节点保存的leader不为空，没有到选举超时，前面这三个条件同时满足。 如果不是强制要求选举，同时又在租约期以内，那么就忽略该选举消息返回不进行处理，这么做是为了避免出现那些离开集群的节点，频繁发起新的选举请求（见论文4.2.3）。 如果不是前面的忽略选举消息的情况，那么除非是prevote类的选举消息，在收到其他消息的情况下，该节点都切换为follower状态。 此时需要针对投票类型中带来的其他字段进行处理了，需要同时满足以下两个条件： 只有在没有给其他节点进行过投票，或者消息的term任期号大于当前节点的任期号，或者之前的投票给的就是这个发出消息的节点 进行选举的节点，它的日志是更新的，条件为：logterm比本节点最新日志的任期号大，在两者相同的情况下，消息的index大于等于当前节点最新日志的index，即总要保证该选举节点的日志比自己的大。 只有在同时满足以上两个条件的情况下，才能同意该节点的选举，否则都会被拒绝。这么做的原因是：保证最后能胜出来当新的leader的节点，它上面的日志都是最新的。 6. 集群成员变化流程大原则是不能同时进行两个以上的成员变更，因为同时进行两个以上的成员变更，可能会出现集群中有两个leader即导致了集群分裂的情况出现。 成员变化分为以下几种情况：成员删减、leader转让，下面分开讲解。 6.1 一般的成员删减成员变化操作做为日志的特殊类型，当可以进行commit的情况下，各个节点拿出该消息进行节点内部的成员删减操作。 6.2 leader 转让 旧leader在接收到转让leader消息之后，会做如下的判断： a. 如果新的leader上的日志，已经跟当前leader上的日志同步了，那么发送timeout消息。 b. 否则继续发append消息到新的leader上，目的为了让其能够与旧leader日志同步。 当旧leader处于转让leader状态时，将停止接收新的prop消息，这样就避免出现在转让过程中新旧leader一直日志不能同步的情况。 当旧leader收到append消息应答时，如果当前处于leader转让状态，那么会判断新的leader日志是否已经与当前leader同步，如果是将发送timeout消息。 新的leader当收到timeout消息时，将使用context为campaignTransfer的选举消息发起新一轮选举，当context为该类型时，此时的选举是强制进行的。 7. 如何做到线性一致性线性一致性（Linearizable Read）通俗来讲，就是保证读到最新的且已经commit的数据，不会读到老数据。 由于所有的leader和follower都能处理客户端的读请求，所以存在可能造成返回读出的旧数据的情况： leader和follower之间存在状态差，因为follower总是由leader同步过去的，可能会返回同步之前的数据。 如果发生了网络分区，某个leader实际上已经被隔离出了集群之外，但是该leader并不知道，如果还继续响应客户端的读请求，也可能会返回旧的数据。 因此，在接收到客户端的读请求时，需要保证返回的数据都是当前最新的。 ReadOnlySafe方式leader在接收到读请求时，需要向集群中的超半数server确认自己仍然是当前的leader，这样它返回的就是最新的数据。 在etcd-raft中，为了实现 ReadOnlySafe，有如下的数据结构： 1234type ReadState struct { Index uint64 RequestCtx []byte} 其中： Index：接收到该读请求时，当前节点的commit索引。 RequestCtx：客户端读请求的唯一标识。ReadState结构体用于保存读请求到来时的节点状态。 12345type readIndexStatus struct { req pb.Message index uint64 acks map[uint64]struct{}} readIndexStatus 数据结构用于追踪leader向follower发送的心跳信息，其中： req：保存原始的 readIndex 请求。 index：leader当前的commit日志索引。 acks：存放该 readIndex 请求有哪些节点进行了应答，当超过半数应答时，leader就可以确认自己还是当前集群的leader。 12345type readOnly struct {option ReadOnlyOptionpendingReadIndex map[string]*readIndexStatusreadIndexQueue []string} readOnly用于管理全局的readIndx数据，其中： option：readOnly选项。 pendingReadIndex：当前所有待处理的readIndex请求，其中key为客户端读请求的唯一标识。 readIndexQueue：保存所有readIndex请求的请求唯一标识数组。 以上是对数据结构的介绍，接下来是对流程的介绍： server收到客户端的读请求，此时会调用 raft.ReadIndex 函数发起一个 MsgReadIndex 的请求，带上的参数是客户端读请求的唯一标识（此时可以对照前面分析的MsgReadIndex及其对应应答消息的格式）。 follower将向leader直接转发 MsgReadIndex 消息，而leader收到不论是本节点还是由其他server发来的 MsgReadIndex 消息，其处理都是： 首先如果该leader在成为新的leader之后没有提交过任何值，那么会直接返回不做处理。 调用 r.readOnly.addRequest(r.raftLog.committed, m) 保存该 MsgreadIndex 请求到来时的commit索引。 r.bcastHeartbeatWithCtx(m.Entries[0].Data)，向集群中所有其他节点广播一个心跳消息 MsgHeartbeat，并且在其中带上该读请求的唯一标识。 follower在收到leader发送过来的 MsgHeartbeat，将应答 MsgHeartbeatResp 消息，并且如果 MsgHeartbeat 消息中有ctx数据，MsgHeartbeatResp 消息将原样返回这个ctx数据。 leader在接收到 MsgHeartbeatResp 消息后，如果其中有ctx字段，说明该 MsgHeartbeatResp 消息对应的 MsgHeartbeat 消息，是收到 ReadIndex 时leader消息为了确认自己还是集群leader发送的心跳消息。首先会调用 r.readOnly.recvAck(m) 函数，根据消息中的ctx字段，到全局的 pendingReadIndex 中查找是否有保存该ctx的带处理的readIndex请求，如果有就在acks map中记录下该follower已经进行了应答。 当ack数量超过了集群半数时，意味着该leader仍然还是集群的leader，此时调用 r.readOnly.advance(m) 函数，将该 readIndex 之前的所有 readIndex 请求都认为是已经成功进行确认的了，所有成功确认的 readIndex 请求，将会加入到 readStates 数组中，同时leader也会向follower发送 MsgReadIndexResp。 follower收到 MsgReadIndexResp 消息时，同样也会更新自己的 readStates 数组信息。 readStates数组的信息，将做为ready结构体的信息更新给上层的raft协议库的使用者。 补充一点，在处理读请求时，实际上leader需要确保当前自己是不是leader、该读请求对应的commit索引是否得到了半数投票，而当一个节点刚成为leader的时候，如果没有提交过任何数据，那么在它所在的这个任期（term）内的commit索引当时是并不知道的，因此在成为leader之后，需要马上提交一个 no-op 的空日志，这样拿到该任期的第一个commit索引。 上图中，在leader收到 MsgReadIndex 后： 向readOnly中添加与这次请求ctx相关的数据： 向pendingReadIndex中添加以ctx为key的readIndexStatus，其中保存了当前的commitIndex、原始的MsgReadIndex消息、以及用于存放有哪些节点应答了该消息的acks数组。 向readIndexQueue数组中添加ctx。 leader向集群中其他节点广播 MsgHeartbeat 消息，其中带上这次 MsgReadIndex 的ctx。 在这之后，follower应答leader的MsgHeartbeat消息，如果消息中存在ctx字段都会带上应答，于是leader中的处理： 收到 MsgHeartbeatResp 消息之后，如果发现其中有ctx，就去计算应答有没有超过半数，没有超过半数则返回。 走到这里就是超过半数应答了，此时拿到新的 readIndexStatus 数组。 遍历前面拿到的 readIndexStatus 数组，生成新的readStates数组。 放到Ready中下一次给客户端。 总结一下，分为四步： leader检查自己在当前任期有没有commit过一条entry，没有提交过则不允许处理readIndex请求。 leader记录下来收到readIndex请求时候的commit index，然后leader向集群中所有节点发心跳广播，其中带上readIndex相关的ctx字段。 当超过半数的节点应答了第二部的心跳消息，说明此时leader还是集群的leader。 生成新的readStates数组放入Ready结构体中，等待下一次客户端来获取该数据。 8. 其他8.1 节点的几种状态一个节点在leader上保存的状态有: 12345const ( ProgressStateProbe ProgressStateType = iota ProgressStateReplicate ProgressStateSnapshot) 以下来分开解释这几种状态。 探测状态：ProgressStateProbe探测状态，当节点拒绝了最近的append消息时，那么就会进入探测状态，此时leader会试图继续往前追述该节点的日志从哪里开始丢失的，让该节点的日志能跟leader同步上。在probe状态时，只能向它发送一次append消息，此后除非状态发生变化，否则就暂停向该节点发送新的append消息了。 只有在以下情况出现时才会恢复取消暂停状态（调用Progress的resume函数）： 收到该节点的心跳消息。 该节点成功应答了前面的最后一条append消息。 至于Probe状态，只有在该节点成功应答了Append消息之后，在leader上保存的索引值发生了变化，才会修改其状态切换到Replicate状态。 接收数据状态：ProgressStateReplicate正常接收副本数据的状态，当处于该状态时，leader在发送副本消息之后，就修改该节点的next索引为发送消息的最大索引+1。 接收快照状态：jieshouProgressStateSnapshot接收快照状态。 当leader向某个follower发送append消息，试图让该follower状态跟上leader时，发现此时leader上保存的索引数据已经对不上了，比如leader在index为10之前的数据都已经写入快照中了，但是该follower需要的是10之前的数据，此时就会切换到该状态下，发送快照给该follower。 因为快照数据可能很多，不知道会同步多久，所以单独把这个状态抽象出来。当快照数据同步追上之后，并不是直接切换到Replicate状态，而是首先切换到Probe状态。 8.2 Progress 上的数据索引Progress 结构体中有两个保存该follower节点日志索引的数据，其中： Next：保存下一次leader发送append消息给该follower时的日志索引。 Match：保存该follower节点上的最大日志索引。 正常情况下，Next == Match + 1，即Next总是节点当前保存最大日志索引的下一条索引。但有两种情况除外： 接收快照状态：此时Next = max(pr.Match+1, pendingSnapshot+1) 当该follower不在Replicate状态时，说明不是正常的接收副本状态。此时当leader与follower同步leader上的日志时，可能出现覆盖的情况，即此时follower上面假设Match为3，但是索引为3的数据会被leader覆盖，此时Next指针可能会一直回溯到与leader上日志匹配的位置，再开始正常同步日志，此时也会出现Next != Match + 1的情况出现。 如上图所示，follower节点s1上最大日志索引为2，即Match = 2，Next = 3。 但是，由于新选出来的leader s2，其最大日志索引为3，此时s3需要同步日志到s1上，发现s1上的日志与自己的不匹配，所以会一直找到两者最开始匹配的索引位置，即最终找到索引1，因此最终保存s1的Next索引为1，而Match还是2（此时还没有修改s1上的日志）。当最终s1上的数据与s2同步时，此时Next = 4，Match=3。 8.3 流量控制Progress结构体中，使用另一个 inflights 的数据结构用于流量控制。 该结构体使用一个固定大小的循环缓冲区来控制给一个节点同步数据的流量控制，每当给该follower发送同步消息时，就占用该缓冲区的一个空间；反之，当收到该follower的成功接收了该同步消息的应答之后，就释放缓冲区的空间。 当该缓冲区数据饱和时，将暂停继续同步数据到该follower。","link":"/2022/01/15/etcd-Raft%E5%BA%93%E8%A7%A3%E6%9E%90/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/12/30/hello-world/"},{"title":"openGauss 存储引擎概述","text":"系统架构 系统功能 源码目录 目录 1 系统架构 2 系统功能 3 源码目录 1 存储引擎系统架构openGauss的存储引擎在整个系统架构中，向上对接SQL引擎，为SQL引擎提供或接收标准化的数据格式（元组或向量数组）；向下对接存储介质，按照特定的数据组织方式，通过存储介质提供的特定接口，对存储介质中的数据完成读、写操作。在此基础之上，存储引擎: 通过日志系统提供数据的持久化和可靠性能力。 通过并发控制（事务）系统保证同时执行的、多个读写操作之间的原子性、一致性和隔离性。 通过索引系统提供对特定数据的加速寻址和查询能力。 通过主备复制系统提供整个数据库服务的高可用能力。 1.2 存储引擎系统功能统一的日志系统在openGauss的存储引擎中，日志系统保证在数据库故障恢复场景下，各个引擎内和各个引擎间数据的持久性和一致性。基于上述统一的日志系统，openGauss支持主、备机之间的流式日志复制，并通过Quorum复制协议，在保证复制一致性的前提下，尽可能降低日志同步对主机业务的影响。 多种并发控制和事务系统在openGauss的存储引擎中，有两种并发控制和事务系统： 适合高并发、高冲突、追求确定性结果的悲观并发控制机制 适合低冲突、短平快、低时延的乐观并发控制机制在磁盘引擎中，采用读写冲突优化的悲观并发控制机制： 对于读、写并发操作，采用多版本并发控制（MVCC） 对于写、写并发操作，采用基于两阶段锁协议（2PL）的悲观并发控制（PCC） 在内存引擎中，采用乐观并发控制来尽可能降低并发控制系统对业务的阻塞，以获得极致的事务处理性能和时延。 表级存储格式/存储引擎和跨格式事务在openGauss的存储引擎中，支持在建表语句中指定目标表的存储格式和存储引擎，即行存储astore、列存储cstore、内存mstore和后续扩展的其他存储格式或存储引擎。因此，在同一个数据库中，为了适配不同的业务场景，用户可以创建不同存储格式或不同存储引擎的表。 进一步，当前openGauss在同一个事务内，支持对同一引擎不同存储格式的表的读写查询，这将极大地简化不同存储格式表中数据一致性、同步性和实时性的运维难度。 统一的行存储访存接口为了便于后续新型行存储格式的扩展，在openGauss中提供了统一的行存储访存接口层，为上层SQL引擎屏蔽了底层不同的行存储数据组织形式。 对于不同的行存储数据格式，它们向上对接统一的行存储访存接口，向下共享缓冲区管理、事务并发控制、日志系统、持久化和故障恢复、主备系统、索引机制。 1.3 源码目录openGauss存储引擎的代码主要位于“src/gausskernel/storage/”目录下，具体目录结构如下： 12345678910111213141516171819--src --gausskernel --storage --access --buffer --bulkload --cmgr --cstore --dfs --file --freespace --ipc --large_object --lmgr --mot --page --remote --replication --smgr 其中每个子目录都是一个相对独立的模块： 模块名 子目录 说明 访存模块 access子目录 主要包括：各种行存储格式中，元组格式；元组与页面之间的转换和访存管理；元组扫描、插入、删除和更新功能的接口实现；几类索引，包括B-Tree、hash、GIN（generalized inverted index，通用倒排索引）、GiST（generalized search tree，通用搜索树）、psort（列存储局部排序索引），的访存管理和接口实现；各类数据库操作对应的日志实现和恢复机制；以及事务模块实现 行存储共享缓冲区模块 buffer子目录 主要包括：行存储共享缓冲区的结构；物理页面和缓冲区页面的映射管理；缓存页面的加载和淘汰算法等 列存储只读共享缓冲区模块 cmgr子目录 主要包括：cstore列存储格式只读共享缓冲区的结构；压缩单元和缓冲区的映射管理；缓冲压缩单元的加载和淘汰算法等 列存储访存模块 cstore子目录 主要包含：cstore列存储格式中，向量数组与压缩单元之间的转换和访存管理；以及在此基础之上向量数组的扫描、插入、删除和更新功能的接口实现 文件操作和虚拟文件描述符模块 file子目录 主要包含：磁盘文件系统存储介质的文件和目录操作；虚拟文件描述符的实现和管理 行存储空闲空间管理模块 freespace子目录 主要包含：各种行存储格式中，页面空闲空间的管理 内存引擎模块 mot子目录 主要包含：内存引擎的实现 页面模块 page子目录 主要包含：各种行存储格式中，页面格式、页面校验、页面加密和页面压缩 备机页面修复模块 remote子目录 主要包含：从备机获取完整页面或压缩单元，用于修复主机损坏的页面或压缩单元 主备日志复制模块 replication子目录 主要包含：主备日志发送和接收线程的实现；流式日志同步功能的实现；Quorum复制协议的实现，逻辑日志的实现以及主备重建；主备心跳检测功能的实现 存储介质管理模块 smgr子目录 主要包含：存储介质管理层的实现；磁盘文件系统（当前默认的存储介质）的基本功能接口实现 其余还有，外表批量导入模块（bulkload子目录）、外表服务器连接模块（dfs子目录）、进程间通信模块（ipc子目录）、大对象模块（large_object子目录）、锁管理模块（lmgr子目录）。 而 openGauss存储引擎相关的后台线程实现代码包含在“src/gausskernel/process/postmaster”目录下。","link":"/2022/03/22/openGauss-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"title":"icarus 修改笔记","text":"为博客更换 Logo 为文章添加封面和缩略图 添加瀑布流相册 为文章添加分类 为文章添加标签 显示网站安全运行时间 补充 Icarus 图标 1. 为博客更换Logoicarus 主题默认的logo是 icarus 的图标，我们希望将其替换为自己的logo。设置你站点的logo后，logo会显示在导航栏和页脚。 1.1 替换文字版logoicarus 提供了一种便捷的更改图标方法，可以像下面这样设置成文字。打开根目录下的 _config.icarus.yml 文件，修改logo字段： 12logo: text: My Beautiful Site 1.2 替换图标版logo如果你有愿意花时间制作图标的话，可以像下面这样设置成路径。打开根目录下的 _config.icarus.yml 文件，修改logo字段： 1logo: /img/logo.svg 2. 为文章添加封面和缩略图若要为文章添加封面图，请在文章的 front-matter 中添加 cover 选项： 1234title: 这是一篇文章cover: /_posts/这是一篇文章/cover.jpg---文章的内容... 类似地，可以在文章的 front-matter 中为文章设置缩略图： 1234title: 这是一篇文章thumbnail: /_posts/这是一篇文章/thumbnail.jpg---文章的内容... 文章的缩略图会显示在归档页面和最新文章挂件中。要注意，如果你在front-matter中使用的是图片的路径，你需要确保它是绝对或者相对于你的source目录的路径。 3. 添加瀑布流相册Icarus的主题已经默认支持瀑布流的相册布局，我们可以添加到文章的任意位置。 3.1 创建新页面在 Git Bash Here 里输入指令： hexo new page “photos” 然后检查 source 文件夹里是否出现了 photos 文件夹。 3.2 设置配置文件打开根目录下的 _config.icarus.yml 文件，在menu字段中添加一条： 相册: /photos 并在 plugins 字段下，修改： gallery: true 3.3 制作相册页面打开 source\\photos 文件夹，找到 index.md 文件，并在旁边创建 img 文件夹。 在 img 文件夹中放入照片并统一命名，此处建议对照片进行处理，单张图片大小不要过大。 打开 index.md，以如下的格式写入： 1234567&lt;div class=&quot;justified-gallery&quot;&gt;![](/photos/img/img2.jpg)![](/photos/img/img1.jpg)![](/photos/img/img0.jpg)&lt;/div&gt; 注意 &lt;div&gt;&lt;/div&gt; 和它们中的语句间要加空行。 4 为文章添加分类在每篇博客 .md 文章的头部添加 categories 字段，如： 123456---title: icarus 修改笔记date: 2022-01-05 09:31:41type: - icarus--- 注意：hexo一篇文章只能属于一个分类，也就是说如果在“- web前端”下方添加“-xxx”，hexo不会产生两个分类，而是把分类嵌套（即该文章属于 “- web前端”下的 “-xxx ”分类）。 5. 为文章添加标签在每篇博客 .md 文章的头部添加 tags 字段，如： 12345678910---title: icarus 修改笔记date: 2022-01-05 09:31:41categories: - icarustags:- 笔记- hexo- icarus--- 6. 显示网站安全运行时间在想要要显示时间的地方添加如下代码： 1234567891011121314151617181920212223242526272829&lt;span id=&quot;timeDate&quot;&gt;载入天数...&lt;/span&gt;&lt;span id=&quot;times&quot;&gt;载入时分秒...&lt;/span&gt;&lt;script&gt; var now = new Date(); function createtime() { var grt = new Date(&quot;12/30/2021 10:16:51&quot;); now.setTime(now.getTime() + 250); days = (now - grt) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if (String(hnum).length == 1) { hnum = &quot;0&quot; + hnum; } minutes = (now - grt) / 1000 / 60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if (String(mnum).length == 1) { mnum = &quot;0&quot; + mnum; } seconds = (now - grt) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if (String(snum).length == 1) { snum = &quot;0&quot; + snum; } document.getElementById(&quot;timeDate&quot;).innerHTML = &quot; | 本站已安全运行 &quot; + dnum + &quot; 天 &quot;; document.getElementById(&quot;times&quot;).innerHTML = hnum + &quot; 小时 &quot; + mnum + &quot; 分 &quot; + snum + &quot; 秒 | &quot;; } setInterval(&quot;createtime()&quot;, 250);&lt;/script&gt; 效果如下： 载入天数…载入时分秒… var now = new Date(); function createtime() { var grt = new Date(\"12/30/2021 10:16:51\"); now.setTime(now.getTime() + 250); days = (now - grt) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if (String(hnum).length == 1) { hnum = \"0\" + hnum; } minutes = (now - grt) / 1000 / 60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if (String(mnum).length == 1) { mnum = \"0\" + mnum; } seconds = (now - grt) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if (String(snum).length == 1) { snum = \"0\" + snum; } document.getElementById(\"timeDate\").innerHTML = \" | 本站已安全运行 \" + dnum + \" 天 \"; document.getElementById(\"times\").innerHTML = hnum + \" 小时 \" + mnum + \" 分 \" + snum + \" 秒 | \"; } setInterval(\"createtime()\", 250); 7. 补充 Icarus 图标Hexo + Icarus 采用了 FontAwesome 图标，并未包含部分图标和 bilibili 这类国产网站图标。所以我们需要让 hexo 添加对这些网站图标的支持，使博客正常显示他们图标。 7.1 下载图标在Iconfont+图库选择所需的图标，点击加入购物车。再点击右上方进入购物车，选择 Add to Project。然后在 Font class 中，点击 .css 文件，在新页面中右键另存为，将其保存至根目录下 themes\\icarus\\source\\css 文件夹中。如果想对下载的图标的颜色、大小等进行修改，则打开所下载的文件，找到对应项进行修改。 7.2 引入图标如果想使用所下载的文件，需要在 html 中将其引入。打开根目录下的 themes\\icarus\\layout\\common\\head.jsxw 文件，在其它链接后添加一条： 1&lt;link rel=&quot;stylesheet&quot; href=&quot;/css/font.css&quot; /&gt; 7.3 使用图标做完上面的工作就可以将开始将新图标添加至界面上了。打开 _config.icarus.yml 配置文件，在需要使用图标的地方做如下格式的修改： 123Zhihu: icon: iconfont icon-zhihu url: 'https://www.zhihu.com/people/lamber-51'","link":"/2022/01/05/icarus-%E4%BF%AE%E6%94%B9%E7%AC%94%E8%AE%B0/"},{"title":"openGauss 中的 DCF","text":"openGauss 什么是DCF？ DCF 搭建 DCF 说明文档 目录 1 openGauss 1.1 openGauss 概述 1.2 openGauss 系统架构 1.3 openGauss 代码结构 2 什么是DCF？ 2.1 DCF 概述 2.2 DCF 架构 3 DCF 搭建 4 DCF 说明文档 1 openGauss1.1 openGauss 概述openGauss是关系型数据库，采用客户端/服务器、单进程多线程架构；支持单机和一主多备部署方式，同时支持备机可读、双机高可用等特性。 openGauss有如下基本功能： 支持标准SQL 支持标准开发接口 混合存储引擎支持 事务支持 软硬件结合 智能优化器 AI支持 安全性 函数及存储过程支持 PostgreSQL接口兼容 支持SQL hint Copy接口支持容错机制 1.2 openGauss 系统架构openGauss主要包含了openGauss服务器、客户端驱动、OM等模块，官方架构如下所示。 openGauss 模块说明: 名称 描述 OM 运维管理模块（Operation Manager）。提供openGauss日常运维、配置管理的管理接口、工具。 客户端驱动 客户端驱动（Client Driver）。负责接收来自应用的访问请求，并向应用返回执行结果；负责与openGauss实例的通信，下发SQL在openGauss实例上执行，并接收命令执行结果。 openGauss主（备） openGauss主（备）。负责存储业务数据（支持行存、列存、内存表存储）、执行数据查询任务以及向客户端驱动返回执行结果。 Storage 服务器的本地存储资源，持久化存储数据。 1.3 openGauss 代码结构openGauss 代码主要由三部分组成： 通信管理 SQL引擎 存储引擎 当服务器的 GaussMaster 线程接收到客户端程序发送过来的服务请求后，会根据收到的信息会立即 fork() 一个子线程，这个子线程对请求进行身份验证成功后成为对应的后端业务处理子线程（gaussdb）。之后该客户端发送的请求将由此业务处理子线程（gaussdb）负责处理。当业务处理子线程（gaussdb）接收到客户端发送过来的查询（SQL）后，会调用openGauss的SQL引擎对SQL语句进行词法解析、语法解析、语义解析、查询重写等处理操作，然后使用查询优化器生成最小代价的查询路径计划。之后，SQL执行器会按照已制定的最优执行计划对SQL语句进行执行，并将执行结果反馈给客户端。 2 DCF2.1 DCF 概述DCF是openGauss的日志共识框架，DCF全称是Distributed Consensus Framework，即分布式一致性共识框架。解决分布式一致性问题典型算法是Paxos、Raft等，DCF实现了Paxos算法。使用DCF可以提供日志复制、集群高可用等能力。DCF提供了基于Paxos多种角色节点类型，并能进行调整。日志复制支持动态流量调整，支持少数派强起能力，自选主能力。 DCF是一款高性能、高度成熟可靠、易扩展、易使用的独立基础库，其他系统通过接口与DCF简单对接，就能够轻松拥有Paxos算法赋予的强一致、高可用、自动容灾等能力。 2.2 DCF 架构DCF功能架构图如上图所示主要包括：算法模块、存储模块、通信模块、服务层等。 接口层：与DB kernel中的日志模块做对接，对外提供读写、查询、注册回调的接口。内核会将DCF看作磁盘进行写入，收到达成共识后返回的成功信息后，继续推进事务。 元数据模块：记录与管理集群配置信息，IP端口、角色类型、超时时间等。 选举模块：负责选举、心跳维持、状态发布等功能。 复制模块：推进日志的复制、分发、达成一致等。 存储模块：负责日志数据的持久化。 通信模块：负责节点间数据的通信。 服务层：提供基础功能。 更多对于系统的讲解推荐看Gauss松鼠会的视频 3 DCF 搭建3.1 配置 dcf 白名单切换至omm用户： su - omm 打开配置文件： cd /opt/ogdatavim pg_hba.conf 在做后面添加白名单： host all all 192.168.1.17/24 trusthost all all 192.168.1.18/24 trusthost all all 192.168.1.19/24 trust 3.2 配置dcf参数将以下信息依次添加到所有主机的/opt/ogdata/postgresql.conf 的最后面 vim /opt/ogdata/postgresql.conf 192.168.1.17 添加下列信息： port=21000dcf_node_id = 1dcf_ssl=offdcf_data_path = ‘/opt/ogdata/dcf_data’dcf_log_path= ‘/opt/ogdata/dcf_log’dcf_config=’[{“stream_id”:1,”node_id”:1,”ip”:”192.168.1.17”,”port”:21000,”role”:”LEADER”},{“stream_id”:1,”node_id”:2,”ip”:”192.168.1.18”,”port”:21000,”role”:”FOLLOWER”},{“stream_id”:1,”node_id”:3,”ip”:”192.168.1.19”,”port”:21000,”role”:”FOLLOWER”}]’replconninfo1 = ‘localhost=192.168.1.17 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=192.168.1.18 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’replconninfo2 = ‘localhost=192.168.1.17 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=192.168.1.19 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’enable_dcf = on 192.168.1.18 添加下列信息： port=21000dcf_node_id = 2dcf_ssl=offdcf_data_path = ‘/opt/ogdata/dcf_data’dcf_log_path= ‘/opt/ogdata/dcf_log’dcf_config=’[{“stream_id”:1,”node_id”:1,”ip”:”192.168.1.17”,”port”:21000,”role”:”LEADER”},{“stream_id”:1,”node_id”:2,”ip”:”192.168.1.18”,”port”:21000,”role”:”FOLLOWER”},{“stream_id”:1,”node_id”:3,”ip”:”192.168.1.19”,”port”:21000,”role”:”FOLLOWER”}]’replconninfo1 = ‘localhost=192.168.1.18 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=192.168.1.17 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’replconninfo2 = ‘localhost=192.168.1.18 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=192.168.1.19 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’enable_dcf = on 192.168.1.19 添加下列信息： port=21000dcf_node_id = 3dcf_ssl=offdcf_data_path = ‘/opt/ogdata/dcf_data’dcf_log_path= ‘/opt/ogdata/dcf_log’dcf_config=’[{“stream_id”:1,”node_id”:1,”ip”:”192.168.1.17”,”port”:21000,”role”:”LEADER”},{“stream_id”:1,”node_id”:2,”ip”:”192.168.1.18”,”port”:21000,”role”:”FOLLOWER”},{“stream_id”:1,”node_id”:3,”ip”:”192.168.1.19”,”port”:21000,”role”:”FOLLOWER”}]’replconninfo1 = ‘localhost=192.168.1.19 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=192.168.1.17 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’replconninfo2 = ‘localhost=192.168.1.19 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=192.168.1.18 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’enable_dcf = on 3.3 启动opengauss集群全部节点以standby的模式启动： gs_ctl start -D /opt/ogdata -M standby 全部节点查看状态： gs_ctl query -D /opt/ogdatasteam://rungameid/1225570 其中，dcf_replication_info表示当前节点dcf信息。 role：表示当前节点角色，角色一共有如下几种，LEADER、FOLLOWER、LOGGER、PASSIVE、PRE_CANDICATE、CANDIDATE、UNKNOW。从上图可以看出当前节点是LEADER节点。term：选举任期。run_mode：DCF运行模式，当前0表示自动选举模式，2表示关闭自动选举模式。work_mode:DCF工作模式。hb_interval:DCF节点间心跳间隔时间，单位ms。elc_timeout:DCF选举超时时间，单位ms。applied_index:被应用到状态机的日志位置。commit_index:已被大多数DCF节点保存的日志位置，此commit_index之前日志均已持久化。first_index:DCF节点保存的首条日志位置，此位置会随着DN调用dcf_truncate而向后推进，之前的日志会被清理。last_index:DCF节点保存的最后一条日志位置，此日志位置包含DCF节点存储在内存里但是没有持久化的日志，故而last_index &gt;= commit_index。cluster_min_apply_idx:集群最小已应用的日志位置。leader_id:leader节点ID。leader_ip:leader节点IP。leader_port:leader节点端口，DCF内部使用 。nodes:集群其他节点信息。 DCF 说明文档一、工程说明1、编程语言：C2、编译工程：cmake3、目录说明： DCF：主目录，CMakeLists.txt为主工程入口； src:：源代码目录，按子目录划分模块解耦； test：测试用例 build：工程构建脚本 二、编译指导1、概述编译DCF需要dcf和binarylibs两个组件。 dcf：dcf的主要代码。可以从开源社区获取。 binarylibs：依赖的第三方开源软件，你可以直接编译openGauss-third_party代码获取，也可以从开源社区下载已经编译好的并上传的一个副本。 2、操作系统和软件依赖要求支持以下操作系统： CentOS 7.6（x86） openEuler-20.03-LTS适配其他系统，可参照openGauss数据库编译指导当前DCF依赖第三方软件有securec、lz4、zstd、openssl、cjson;编译dcf依赖的第三方软件要求与编译opengauss对依赖的第三方软件要求一致。 3、下载dcf可以从开源社区下载dcf和openGauss-third_party。可以通过以下网站获取编译好的binarylibs。https://opengauss.obs.cn-south-1.myhuaweicloud.com/2.0.0/openGauss-third_party_binarylibs.tar.gz 4、编译第三方软件在编译dcf之前，需要先编译dcf依赖的开源及第三方软件。这些开源及第三方软件存储在openGauss-third_party代码仓库中，通常只需要构建一次。如果开源软件有更新，需要重新构建软件。用户也可以直接从binarylibs库中获取开源软件编译和构建的输出文件。 5、代码编译使用DCF/build/linux/opengauss/build.sh编译代码, 参数说明请见以下表格。 选项 参数 说明 -3rd [binarylibs path] 指定binarylibs路径。该路径必须是绝对路径。 现在只需使用如下命令即可编译：[user@linux dcf]$ sh build.sh -3rd [binarylibs path]完成编译后，动态库生成在DCF/lib目录中 三、接口说明1、API列表DCF角色定义：typedef enum en_dcf_role { DCF_ROLE_UNKNOWN = 0, DCF_ROLE_LEADER, DCF_ROLE_FOLLOWER, DCF_ROLE_LOGGER, DCF_ROLE_PASSIVE, DCF_ROLE_PRE_CANDIDATE, DCF_ROLE_CANDIDATE, DCF_ROLE_CEIL,} dcf_role_t; int dcf_set_param(const char *param_name, const char *param_value); 功能说明：设置DCF配置参数参数说明：param_name是需要设置的参数名称，param_value是需要设置的参数值。 参数名称有以下类型： “ELECTION_TIMEOUT” –选举超时时间，单位ms “HEARTBEAT_INTERVAL” –心跳间隔，单位ms “RUN_MODE” –运行模式，ELECTION_AUTO或ELECTION_MANUAL “INSTANCE_NAME” –实例名称 “DATA_PATH” –数据文件路径 “LOG_PATH” –日志文件路径 “LOG_LEVEL” –最大日志级别”RUN_ERR|RUN_WAR|RUN_INF|DEBUG_ERR|DEBUG_WAR|DEBUG_INF|MEC|OPER|TRACE|PROFILE”, 需要开启自定义级别,从上述字符串中选取并使用|分割; 默认级别”RUN_ERR|RUN_WAR|DEBUG_ERR|OPER” 若需要关闭日志打印，配置”NONE” “LOG_BACKUP_FILE_COUNT” –日志备份文件数 “MAX_LOG_FILE_SIZE” –日志文件最大size，单位MB “LOG_FILE_PERMISSION” –日志文件权限,权限不高于700 “LOG_PATH_PERMISSION” –日志路径权限,权限不高于700 “MEC_AGENT_THREAD_NUM” –通信agent线程数量 “MEC_REACTOR_THREAD_NUM” –通信reactor线程数量 “MEC_CHANNEL_NUM” –通信通道数量 “MEM_POOL_INIT_SIZE” –共用buddy pool的初始size “MEM_POOL_MAX_SIZE” –共用buddy pool的最大size “COMPRESS_ALGORITHM” –通信压缩算法, 0:COMPRESS_NONE, 1:COMPRESS_ZSTD, 2:COMPRESS_LZ4 “COMPRESS_LEVEL” –压缩级别 “SOCKET_TIMEOUT” –socket收发报文超时时间，单位ms “CONNECT_TIMEOUT” –连接超时时间，单位ms “REP_APPEND_THREAD_NUM” –leader节点发送日志的线程数 “MEC_FRAGMENT_SIZE” –通信消息buffer size “STG_POOL_INIT_SIZE” –存储pool初始size “STG_POOL_MAX_SIZE” –存储pool最大size，存储有读写两个pool，这里是单个pool的size “MEC_POOL_MAX_SIZE” –通信pool最大size，通信有收发两个pool，这里是单个pool的size “FLOW_CONTROL_CPU_THRESHOLD” – CPU使用率超过此值时会对passive节点的日志同步进行流控，单位% “FLOW_CONTROL_NET_QUEUE_MESSAGE_NUM_THRESHOLD” – DCF发送日志队列中消息超过此值时会对passive节点的日志同步进行流控 “FLOW_CONTROL_DISK_RAWAIT_THRESHOLD” – 磁盘读延时超过此值时会对passive节点的日志同步进行流控，单位us “DN_FLOW_CONTROL_RTO” – DN流控参数，结合接口dcf_pause_rep使用 “DN_FLOW_CONTROL_RPO” – DN流控参数，结合接口dcf_pause_rep使用 int dcf_get_param(const char *param_name, const char *param_value, unsigned int size); 功能说明：设置DCF配置参数参数说明：param_name是需要设置的参数名称，参数名称如dcf_set_param中参数param_name一致 param_value是获取的参数值，需提前分配内存 size是param_value的大小 int dcf_register_after_writer(usr_cb_after_writer_t cb_func); 功能说明：注册leader节点写入数据成功的回调函数参数说明：回调函数形式如下，其中stream_id是分组编号，相同编号的组成一个一致性group; index是落盘日志的index; buf是落盘的日志buf; size是落盘的日志size; key是落盘日志的key，可以唯一标识一条日志; error_no是错误码 typedef int (*usr_cb_after_writer_t)(unsigned int stream_id, unsigned long long index, const char *buf, unsigned int size, unsigned long long key, int error_no); int dcf_register_consensus_notify(usr_cb_consensus_notify_t cb_func); 功能说明：注册follower节点写入数据成功的回调函数参数说明：回调函数形式如下，参数解释同上 typedef int (*usr_cb_consensus_notify_t)(unsigned int stream_id, unsigned long long index, const char *buf, unsigned int size, unsigned long long key); int dcf_register_status_notify(usr_cb_status_notify_t cb_func); 功能说明：注册节点角色变化的回调函数参数说明：回调函数形式如下，new_role是节点新角色 typedef int (*usr_cb_status_notify_t)(unsigned int stream_id, dcf_role_t new_role); int dcf_register_log_output(usr_cb_log_output_t cb_func); 功能说明：注册日志输出的回调函数参数说明：回调函数形式如下，log_type是日志类型，LOG_RUN、LOG_DEBUG等; log_level是日志级别，LEVEL_ERROR、LEVEL_WARN等; code_file_name是代码文件名，如__FILE__; code_line_num是代码行号，如__LINE__; module_name是模块名，如”DCF”; format, …是格式化字符串 typedef void (*usr_cb_log_output_t)(int log_type, int log_level, const char *code_file_name, unsigned int code_line_num, const char *module_name, const char *format, …); int dcf_register_exception_report(usr_cb_exception_notify_t cb_func); 功能说明：注册异常处理函数参数说明：回调函数形式如下，dcf_exception_t异常类型，见dcf_interface.h中定义 typedef int(*usr_cb_exception_notify_t)(unsigned int stream_id, dcf_exception_t exception); int dcf_register_election_notify(usr_cb_election_notify_t cb_func); 功能说明：注册选举leader变化的回调函数参数说明：回调函数形式如下，new_leader 是新主的nodeid typedef int (*usr_cb_election_notify_t)(unsigned int stream_id, unsigned int new_leader); int dcf_register_msg_proc(usr_cb_msg_proc_t cb_func); 功能说明：注册选举leader变化的回调，follower调用函数参数说明：回调函数形式如下， typedef int (usr_cb_msg_proc_t)(unsigned int stream_id, unsigned int src_node_id, const char msg, unsigned int msg_size); int dcf_start(unsigned int node_id, const char *cfg_str); 功能说明：启动工作线程参数说明：node_id是节点id; cfg_str是集群节点列表，按照json字符串的格式进行配置，每个json item的配置信息包括stream_id/node_id/ip/port/role; 例如三个节点”[{ “stream_id”:1, “node_id”:1, “ip”:”127.0.0.1”, “port”:1711, “role”:”LEADER” },{ “stream_id”:1, “node_id”:2, “ip”:”127.0.0.1”, “port”:1712, “role”:”FOLLOWER” },{ “stream_id”:1, “node_id”:3, “ip”:”127.0.0.1”, “port”:1713, “role”:”FOLLOWER” }]” int dcf_write(unsigned int stream_id, const char* buffer, unsigned int length, unsigned long long key, unsigned long long *index); 功能说明：写入数据，仅leader节点调用参数说明：buffer是待写入数据的buffer; length是待写入数据的size; key是待写入数据的key，可以唯一标识一条日志; index是leader分配的日志index int dcf_read(unsigned int stream_id, unsigned long long index, char *buffer, unsigned int length); 功能说明：查询已写入的数据，成功返回实际读到的字节数，失败返回ERROR(-1)参数说明：参考前述 int dcf_stop(); 功能说明：停止工作线程参数说明： int dcf_truncate(unsigned int stream_id, unsigned long long first_index_kept); 功能说明：丢弃索引first_index_kept之前的日志参数说明：first_index_kept是保留的第一个日志index int dcf_set_applied_index(unsigned int stream_id, unsigned long long index); 功能说明：设置applied index,在函数dcf_start调用前调用参数说明：index是日志index int dcf_get_cluster_min_applied_idx(unsigned int stream_id, unsigned long long* index); 功能说明：获取集群所有节点最小的applied index参数说明：*index是获取到的最小applied index int dcf_get_leader_last_index(unsigned int stream_id, unsigned long long* index); 功能说明：查询leader节点的last index参数说明：返回值index为last index int dcf_get_last_index(unsigned int stream_id, unsigned long long* index); 功能说明：查询当前节点的last index参数说明：返回值index为last index int dcf_get_node_last_disk_index(unsigned int stream_id, unsigned int node_id, unsigned long long* index); 功能说明：获取node_id节点的last disk index，只可在leader调用。成功返回SUCCESS，失败返回ERROR参数说明：*index为获取到的last disk index。 int dcf_query_cluster_info(char* buffer, unsigned int length); 功能说明：查询集群信息，streamlist、node等参数说明：buffer是查询信息输出空间; length是最大输出长度; 函数返回值是实际输出长度 例如三个节点的cluster查询信息： { “local_node_id”:1, “stream_list”:[{“stream_id”:1,”local_node_id”:1,”role”:”FOLLOWER”,”term”:3,”work_mode”:0, “applied_index”:0,”commit_index”:0,”first_index”:1,”last_index”:5733936, “leader_id”:3,”leader_ip”:”127.0.0.1”,”leader_port”:1713, “nodes”:[{“node_id”:1,”ip”:”127.0.0.1”,”port”:1711,”role”:”FOLLOWER”}, {“node_id”:2,”ip”:”127.0.0.1”,”port”:1712,”role”:”FOLLOWER”}, {“node_id”:3,”ip”:”127.0.0.1”,”port”:1713,”role”:”LEADER”}] }] } int dcf_query_stream_info(unsigned int stream_id, char *buffer, unsigned int length); 功能说明：查询stream信息参数说明：stream_id是待查询stream的id; buffer是查询信息输出空间; length是最大输出长度; 函数返回值是实际输出长度 例如三个节点的stream查询信息： { “stream_id”:1,”local_node_id”:3,”role”:”FOLLOWER”,”term”:2,”work_mode”:0, “applied_index”:0,”commit_index”:0,”first_index”:1,”last_index”:0, “leader_id”:2,”leader_ip”:”127.0.0.1”,”leader_port”:1712, “nodes”:[{“node_id”:1,”ip”:”127.0.0.1”,”port”:1711,”role”:”FOLLOWER”}, {“node_id”:2,”ip”:”127.0.0.1”,”port”:1712,”role”:”LEADER”}, {“node_id”:3,”ip”:”127.0.0.1”,”port”:1713,”role”:”FOLLOWER”}] } int dcf_query_leader_info(unsigned int stream_id, char *ip, unsigned int ip_len, unsigned int *port, unsigned int *node_id); 功能说明：查询leader信息参数说明：ip是输出leader ip的buffer; ip_len是ip buffer长度; port输出leader的port; node_id输出leader的node_id int dcf_get_errorno(); 功能说明：获取错误码参数说明： const char* dcf_get_error(int code); 功能说明：获取错误信息参数说明：code错误码 const char *dcf_get_version(); 功能说明：获取版本信息参数说明： int dcf_add_member(unsigned int stream_id, unsigned int node_id, const char *ip, unsigned int port, dcf_role_t role, unsigned int wait_timeout_ms); 功能说明：添加节点，只可在leader调用。成功返回SUCCESS(0)，失败返回ERROR(-1)，超时返回TIMEOUT(1),超时最终也可能成功，可以重试。参数说明：node_id是待添加节点id; ip是待添加节点ip; port是待添加节点port，调用者需保证port可用; role是待添加节点角色; wait_timeout_ms是超时时间，单位ms int dcf_remove_member(unsigned int stream_id, unsigned int node_id, unsigned int wait_timeout_ms); 功能说明：删除节点，只可在leader调用。成功返回SUCCESS(0)，失败返回ERROR(-1)，超时返回TIMEOUT(1),超时最终也可能成功，可以重试。参数说明：node_id是待删除节点id; wait_timeout_ms是超时时间，单位ms int dcf_change_member_role(unsigned int stream_id, unsigned int node_id, dcf_role_t new_role, unsigned int wait_timeout_ms); 功能说明：改变节点角色，在leader调用可改变其他节点角色，在follower节点调用只能改变自己角色。成功返回SUCCESS(0)，失败返回ERROR(-1)，超时返回TIMEOUT(1),超时最终也可能成功，可以重试。参数说明：node_id为被修改角色节点id; new_role是节点新角色 int dcf_promote_leader(unsigned int stream_id, unsigned int node_id, unsigned int wait_timeout_ms); 功能说明：推选指定节点为leader。在leader调用可推选其他节点，在follower节点调用只能推选自己。参数说明：node_id为被推选节点id; wait_timeout_ms是超时时间，单位ms，为0表示不阻塞leader直接发起推选。 int dcf_timeout_notify(unsigned int stream_id, unsigned int node_id); 功能说明：外部触发超时参数说明：stream_id≠0表示触发指定stream_id超时，stream_id=0表示触发所有stream_id超时 int int dcf_set_work_mode(unsigned int stream_id, dcf_work_mode_t work_mode, unsigned int vote_num)； 功能说明：设置运行模式（正常、少数派）参数说明：work_mode为正常或少数派，如果是少数派模式，需指定票数。 int dcf_query_statistics_info(char *buffer, unsigned int length); 功能说明：获取统计信息，需要日志级别开启PROFILE。参数说明：buffer是查询信息输出空间; length是最大输出长度 int dcf_check_if_all_logs_applied(unsigned int stream_id, unsigned int *all_applied); 功能说明：一般在节点升主时使用，检查当前欲升主节点的dcf日志是否都完成apply。调用成功返回SUCCESS，失败返回ERROR，调用成功后可从all_applied获取结果。参数说明：all_applied为获取到的结果，0表示日志没有都完成apply，非0表示日志都完成apply。 int dcf_send_msg(unsigned int stream_id, unsigned int dest_node_id, const char* msg, unsigned int msg_size); 功能说明：用于节点间对指定节点发送消息。调用成功返回SUCCESS，失败返回ERROR。参数说明：dest_node_id为指定节点，msg表示待发送的消息，msg_size表示消息大小。 int dcf_broadcast_msg(unsigned int stream_id, const char* msg, unsigned int msg_size); 功能说明：用于对除当前节点外所有节点广播发送消息。调用成功返回SUCCESS，失败返回ERROR。参数说明：msg表示待发送的消息，msg_size表示消息大小。 int dcf_pause_rep(unsigned int stream_id, unsigned int node_id, unsigned int time_us); 功能说明：对指定节点暂停日志复制。调用成功返回SUCCESS，失败返回ERROR。参数说明：node_id指定暂停的节点; time_us是暂停时间(不超过1s)，单位us。 2、DEMO示例123参见：DCF/test/test_main目录 四、测试工程1、编译2、执行测试用例待续… 五、应用实例1、GaussDB(for openGauss)使能paxos特性实践具体可参考：https://gitee.com/opengauss/blog/blob/master/content/zh/post/yanghaiyan/openGauss%E4%BD%BF%E8%83%BDpaxos%E7%89%B9%E6%80%A7%E5%AE%9E%E8%B7%B5.md","link":"/2022/02/10/openGauss%20%E4%B8%AD%E7%9A%84%20DCF/"},{"title":"openGauss存储技术","text":"存储概览 行存储引擎 列存储引擎 内存引擎 目录 1 存储概览 1.1 存储引擎要解决的问题 1.2 存储引擎概述 2 行存储引擎 2.1 行存储引擎总体架构 2.2 行存储的基本模型与页面组织结构 2.3 行存储的多版本管理以及 DML操作 2.4 基于CSN的MVCC机制 2.5 行存储的空间回收 2.6 行存储的共享缓存管理 2.7 并行日志系统设计 2.8 持久化与故障恢复系统设计 3 列存储引擎 4 内存引擎 1 openGauss存储概览早期计算机程序通过文件系统管理数据，到了20世纪60年代，用户逐渐对数据并发写入的完整性、高效的检索提出更高的要求。由于机械磁盘的随机读写性能问题，从20世纪80年代开始，大多数数据库一直围绕着减少随机读写磁盘进行设计。主要思路是把对数据页面的随机写盘转化为对WAL(Write Ahead Log，预写式日志)的顺序写盘，WAL持久化完成，事务就算提交成功，数据页面异步将数据刷新到磁盘上。 但是随着内存容量变大和保电内存、非易失性内存的发展，以及SSD(固态硬盘)技术的逐渐成熟，磁盘的IO性能得到极大提高，经历了几十年发展的存储引擎需要调整架构来发挥SSD的性能和充分利用大内存计算的优势。随着互联网、移动互联网的发展，数据量剧增，业务场景呈现多样化，一套固定不变的存储引擎不可能满足所有应用场景的诉求。因此现在的DBMS需要设计支持多种存储引擎，根据业务场景来选择合适的存储模型。 1.1 存储引擎要解决的问题 存储的数据必须要保证原子性(A)、一致性(C)、隔离性(I)、持久性(D)。 支持高并发读写，高性能。 充分发挥硬件的性能，解决数据的高效存储和检索能力。 1.2 存储引擎概述openGauss整个系统设计是可插拔、自组装的，支持多个存储引擎以满足不同场景的业务诉求。当前openGauss存储引擎有以下3种: 行存储引擎，主要面向 OLTP场景设计，例如订货、发货、银行交易系统。 列存储引擎，主要面向 OLAP场景设计，例如数据统计报表分析。创建表的时候可以指定为行存储引擎表、列存储引擎表、内存引擎表，支持一个事务中包含对三种引擎表的DML(数据操作语言)操作，可以保证事务的 ACID性质。 2 行存储引擎openGauss行存储引擎采用原地更新(in-place update)设计，支持 MVCC(Multi- Version Concurrency Control，多版本并发控制)，同时支持本地存储和存储与计算分离的部署方式。行存储引擎的特点是支持高并发读写，时延小，适合OLTP交易类业务场景。 2.1 总体架构openGauss的行存储引擎在设计上支持MVCC，采用集中式垃圾版本回收机制，可以提供 OLTP业务系统的高并发读写要求，支持存储、计算分离架构，存储层异步回放日志。 数据页面缓存池中缓存数据页面,在数据页面中存放元组以及元组的历史版本并集中管理,使用Vacuum(垃圾清理)线程进行定期的空间回收。 行存储引擎的关键技术有: 基于事务ID以及ctid(行号)的多版本管理。 基于CSN(CommitSequenceNumber，待提交事务的序列号，它是一个64位递增无符号数)的多版本可见性判断以及MVCC机制。页面，在数据页面中存放元组以及元组的历史版本并集中管理，使用Vacuum(垃圾清理)线程进行定期的空间回收。 基于大内存设计的缓冲区管理。 平滑无性能波动的增量检查点(checkpoint)。 基于并行回放的快速故障实例恢复。 2.2 基本模型与页面组织结构行存储的元组结构以及页面组织，是行存储DML实现、可见性判断以及行存储各种功能与管理机制的基石。 行存储是基于磁盘的存储引擎，存储格式的设计遵从段页式设计。存储结构需要以页面为单位，方便与操作系统内核以及文件系统的接口进行交互。也是由于这个原因，页面的大小需要和目标系统中一个block(块)的大小对齐。在比较通用的Linux内核中，页面大小一般默认为8KB。一个基本的Heap(堆)页面如下图所示。 页面开头的位置为整个页面的头部信息，记录了这个页面的公用信息以及一些关键标识。line_pointer被放置于Header后面，并向页面尾部扩展。line_pointer为指向Tuple实际数据的一个指针，类似于行指针的作用。 而每个Tuple在系统中的唯一标识ItemPointer，也被称为ctid，存储的是这一行所在的页面号以及其对应的line_pointer的偏移量(offset)。这样由一个系统内记录的ctid，可以快速定位到这个Tuple的line_pointer，就可以根据line_pointer的指针快速定位到Tuple的实际数据。 line_pointer的必要性显而易见。由于Tuple的数据内容是变长的，因此读取Tuple需要遍历页面结构；而line_pointer结构本身为定长，因此可以直接以常数的复杂度找到数据所在内存位置。line_pointer的sentinel效果也十分明显：line_pointer的存在使得Tuple的对应改动局限于页面内部，而保持全局标识ctid不发生变化；如果没line_pointer，行更新则需要连带更新的元信息、索引以及系统各处信息，复杂度会上升。 被line_pointer指向的行记录本身，从页面结尾开始向页面头部延展，避免在页面填充过程中的数据移动以及空间浪费。 页面头部的Header中储存了如下信息: pd_lsn为最后一次改动此页面事务写下的WAL(xlog)的下一位，被xlog机制以及检查点机制所使用。 pd_checksum 为页面中的checksum，为了检查页面的完整性和一致性使用。 pd_flags是此页面的标识位，可以让上层通过对此页面进行处理的接口快速识别此页面的一些特征，比如页面是否有空行，页面是否写满，页面是否已经对所有事务全部可见，页面是否被压缩等。 pd_lower和pd_upper是指向页面空闲空间起止的指针，即pd_lower指向下一个line_pointer的位置，而pd_upper指向下一个行记录数据填充的位置，这样既可以快速进行页面的填充修改，也可以方便计算页面的空闲空间。 pd_special指针用于记录一些特殊的存储管理方式以及接口所需的内存区域。 pd_prune_xid记录上一次对此页面进行清理的xid(事务ID，事务号)。 pd_xid_base以及pd_multi_base为这个页面上xid的base基准，即该页面上所有的记录的xid都由页面自身记录的 xid(32位)与 base(64位)计算得到，是64位xid的实现方式。 记录(元组的数据部分)是数据库中最基本的数据存储单位，其自身的结构以及记录的信息也是系统中数据存储方式、DML、事务 ACID 特性的关键。数据部分结构图如下： xmin是最初始的事务ID(Transaction ID，简称xid)，即插入此条记录的事务ID。 xmax是删除或更新此条记录的xid。如果此记录未被更改或删除，那么xmax为0。 t_cid记录的是命令ID(Command ID)，命令ID 用于一个事务内部多步操作的一种记录与跟踪。 t_ctid记录了此条记录的ctid值，或者是更新版本的ctid值。这个会在后面展开 DML时讲到。 两个t-infomask是事务以及存储数据状态的标识位，用于快速判断。 xmin、xmax两个事务ID，结合其映射的 Clog(提交日志)和 CSN Log，一同构成了可见性判断的核心关键要素。 2.3 行存储的多版本管理以及 DML操作openGauss行存储的多版本机制与业界比较常见的关系数据库有较大的不同，核心区别为行存储的多版本在更新的时候并不是就地更新，而是在原有页面中保留上一个版本，转而在这个页面(如果空间不够会在新页面中)中创建一个新的版本进行历史版本的累积与更新。 相应的页面中会同时存有不同版本的同一行数据，拿到不同快照的事务，在读写这些不同版本时互不冲突，有着很好的并发性能。对历史版本的检索可以在页面本身或邻近页面进行，也不需要额外的CPU开销以及IO开销，有着非常高的效率。同时，事务管理以及持久化角度也变得非常清晰简洁，省去了类似于就地更新所需要的记录、执行以及持久化的 Undo(回退)等相关操作。 以下就以一个 DML的例子简单介绍行存储结构以及 MVCC的实现。 假设我们在一个xid为10的事务中，在一个只有一列varchar(变长字符串类型) 数据的表中插入一条数据 ‘A’，该行数据存入编号为0的数据页面上，则该行存储结构如图所示。","link":"/2022/05/06/openGauss%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF/"},{"title":"openGauss的DCF组件详解","text":"组件介绍 功能介绍 模块介绍 代码仓库 数据库对接 目录 1 组件介绍 1.1 需求背景与优势 1.2 一致性协议 2 功能介绍 3 模块介绍 3.1 选举流程 3.2 主机异常的处理 3.3 网络分区的处理 3.4 复制流程 4 代码仓库 5 数据库对接 1 DCF 组件介绍DCF（分布式共识框架）目标：构建稳定可靠、低时延、高吞吐的一致性数据复制组件。 这一技术组件需要承载以下工作： 副本高可用 主备之间备份 容灾性自动/手动升主降备 跨AZ（可用区）的多副本复制 多日志流的复制 简化集群管理 集群状态发布 集群配置管理 委托选主 分布式全局锁 1.1 需求背景与优势传统主备集群管理常采用第三方仲裁，如采用Etcd集群实现主备节点间的切换： 这样的第三方仲裁会出现一些问题，如脑裂。有可能第三方仲裁认为节点故障，但实际上没有，此时会出现脑裂的情况。此外，还会出现因中间状态而出现的日志分叉的情况。 openGauss引入DCF自仲裁，DCF作为一个动态库集成在openGauss存储引擎中，在DB内核中自检测。DCF通过一致性协议，协商哪一节点作为主节点，以保证在任何情况下都不会出现脑裂既双主的情况，也不会出现日志分叉的情况。并且相比传统主备集群管理，大大简化了故障检测环节，进而减小集群RTO（容许服务中断的时间长度）。 自仲裁具有很多优势： 并且在openGauss中，同过解耦使得DCF作为一个独立模块，既降低了复杂度，又使得后续的优化更方便。 1.2 一致性协议 DCF组件采用Paxos协议。当前被广泛采用的一致性协议还是Paxos族协议，Paxos算法在这些年已经经过了很多代演进。 1.2.1 两阶段Paxos 1.2.2 Multi-Paxos 在经典Paxos基础上添加租约机制，维持Leader节点状态。 1.2.3 Raft 在Multi-Paxos上进一步做了简化，更容易实现可靠性。 1.2.4 Paxos演进趋势 不同的Paxos算法都是在经典Paxos基础上，根据业务的情况选择了不同的侧重点。 DCF的目标是做一个适用于数据库的一致性日志复制组件。 2 功能介绍对照数据库中想实现的一些特性，总结出以下想实现的功能： 设计的DCF为一个独立的组件，与内核解耦，最终实现一个位于底层的Paxos日志复制的共识框架，使得DCF不仅可以用在内核中，还可以用于集群管理等地方。DCF通过对节点进行多种角色的分类，使得集群管理更加灵活，降低容灾、数据备份等过程中的成本。 关键设计: 支持自选主 支持异步多线程框架和无锁cache设计 支持多级batch. pipeline操作， 以及日志压缩能力V支持日志多流多复制 不同分区主备副本可以在同-节点，方便实现负载均衡和异地多活 基于网络带宽及网络时延自动探测的流控算法 支持batch size、pipeline并发数自适应调整, 提升系统最大吞吐量 openGauss引入基于Paxos协议的DCF组件，能够保证数据一致性的同时，在高可用方面得到极大增强，主要包括: 通过自仲裁、多数派选主能力摆脱第三方仲裁组件,极大缩短RTO时间,且可预防任何故障下的脑裂双主 基于Paxos协议拓展的多样化节点角色，能够提供节点同步同异步混合部署等多种集群部署方式 高性能、低时延的复制能力，使得openGauss在高可用方面得到极大增强的同时，还提升了主备节点间日志复制效率，提升系统最大吞吐能力 3 模块介绍 DCF模块划分如上图所示，作为一个动态库集成到数据库内核中。 interface：DCF通过interface接口层与数据库日志模块对接，提供读写等接口。flash刷盘的时候，数据库调DCF的interface接口写入，达成共识后，DCF会异步的通知上层写入成功。 metadata：元数据管理，定义集群节点信息，如IP端口，角色类型，选举超时时间等。 election：负责主节点的选举、心跳维持、状态发布。 replication：推进日志的分发并达成一致。 storage：负责日志数据的持久化。 communication：提供节点间的数据通信能力（TCP/UDP）。 Base：提供基础能力，如线程、日志、锁、队列等。 Gitee上可以查到DCF仓库。 3.1 选举流程 preVote优化: 为防止网络断连导致节点频繁发起选主请求，term持续增加 在Follower变为Candidate前加入pre-candidate状态，发起term不变的预选举流程，成功后才将term++发起正式选主流程 Lease优化: Leader与多数派断连主动降备，防止事实双主 在lease时间内不响应term更高的选主消息 DCF在Paxos上增添了预选举环节，增加一次探测，当与大多数节点通信正常时才会发起选举，获得大多数节点的投票后当选为主节点，然后所有Follower跟随主节点做日志的同步。 选举核心之一是多数派原则，通过逻辑推理可以证明数据一定不会丢，因为无论是当选还是日志推进，多数派总是重叠的，以保证数据不丢失。 3.2 主机异常的处理 网络异常或节点宕机，导致Leader心跳停止，日志复制停止。 Follower检测到心跳超时， 转换为candidate, 发起新任期选举 Follower若接收到其他节 点发起的选举，则判断任期和日志长度，确定是否投票给他 candidate若得到超过半数的选票，则成为leader 新leader开始将自 己的日志发送给其他follower Follower接收新leader来的日志信息，判断日志是否跟自己连续匹配，连续匹配则接受。若不连续则返回，leader重新发送前段日志;若term不匹配，则将新leader的日志覆盖到原来的位置，并将后面的日志truncate掉 3.3 网络分区的处理 集群网络异常分区,分裂出两个小集群 一个集群存在一个原leader, 新集群选举一个新leader, 任期增1 原leader也能接受写请求进行写入操作，但是无法达成大多数一致,导致无法提交 新leader也能接受写请求进行写入操作，能够达成一致,进行日志提交脑裂消失之后，由于原leader的term比较旧，会切换成follower 新leader的日 志复制给就leader，将就leader未提交日志覆盖 主机异常和网络分区都是每个自己检测的，所以节点的状态切换是根据自身的状态，不需要第三方去通知节点状态变更。 3.4 复制流程 client thread指的是xlog中负责落盘的线程，通过调DCF的write接口，把数据写到buffer队列里面，写完后无阻塞立即返回。当本次写入得到大多认可后，会异步的write callback。而buffer里的数据会经过一系列的复制流水线，经过组包发送给备机。备机收到数据包后会回调Replay callback通知数据库内核，然后将数据拷贝到xlog日志里面。 异步流水线 日志采用全异步进行发送，不采用一问一答同步方式，提高系统整体吞吐量 Leader发送完一批log之后，直接更新next index,下次发送从这个点持续发送，不等follower响应回来; Follower等落盘线程写完一批log之后，将最新的落盘match_index发送给leader，持续反馈最新的落盘index; Leader通过这个来更新各节点的最新match_index，推进commit_index; 数据合并&amp;压缩 通信模块将包按大小进行压缩发送，减少网络带宽; 根据发送队列情况自动合并数据包; 批量并行落盘 应用端调用API write接口，写入内存buffer就返回，不阻塞应用其他流程处理，批量写盘和批量发送，日志到buffer之后，并行的将日志落入本地磁盘和发送到follower节点 多日志流 支持DN粒度和分区粒度日志分组能力 吞吐量随时间变化平滑，平且相比同类产品吞吐量有提升。 4 代码仓库DCF作者在Gitee上建有代码仓库，DCF编译后在数据库中以动态库的形式存在，内核通过 DCF/src/interface/dcf_interface.h 文件调用DCF的能力，那么打开dcf_interface.h看一下几个最核心的接口： dcf_start：启动DCF模块，内核调用 dcf_start 将模块拉起。 dcf_write：拉起后调用 dcf_write 做数据写，DCF支持多日志流，但目前鸿蒙gauss里面只需要用一份日志。其中，通过 key 标识哪一份数据得到了承认，index 则标识着序列中的第几个数据得到了承认。 dcf_read：dcf_read 方法可以根据 dcf_write 方法中的 index 关键字读取DCF中对应的数据。 dcf_start：停止DCF模块。 使用步骤: 参数设置:设置buffer大小、压缩参数、心跳超时时间等 注册回调函数：leader方 日志达成一致的回调函数、follower apply/replay回调函数、身份变更通知回调函数 初始化启动：初始化模块，启动各线程 写入log 读取已存储的log 查询集群状态 5 数据库对接 数据库参数配置： enable_ dcf = on dcf_ node_ id = 3 dcf_ data_ path = ‘/dcf_ perf_ 03/px01/cluster/data/dn1/dcf_ _data’ dcf_ log_ path = ‘/dcf_ perf_ 03/px01/cluster/gaussdb_ log/px01/dcf_ log’ dcf_ config =‘[“stream_ id”:1,”node_ id”:1,”ip”:”8.92.1.85”,”port”:16683,”role”:”LEADER”),(“stream_ id”:1,”node_ id”:2,”ipp”:”8.92.1 .86”,”port”:16683,”role”:”FOLLOWER”),”stream_ id”:1,”node_ id”:3,”ip”:”8.92.1.87”,”port”:16683,”role”:”FOLLOWER”]] dcf_ Ssl = off dcf_ mec_ batch_ size=0","link":"/2022/04/18/openGauss%E7%9A%84DCF%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"title":"使用etcd实现存储服务","text":"etcd server与raft的交互 WAL backend store的实现 applierV3 目录 1. 概述 2. etcd server与raft的交互 3. WAL 4. backend store的实现 4.1 revision概念 4.2 keyIndex结构 4.3 treeIndex结构 4.4 store 4.5 KV接口 5. applierV3 6. 综述 1. 概述这篇笔记是继解析Raft算法原理及etcd Raft库解析的第三篇笔记，这篇笔记依旧是在codedump的网络日志基础之上记录的。在这篇笔记我们接着分析etcd如何使用Raft实现存储服务的。 这篇笔记的分析主要针对etcd V3版本的实现，下图中展示了etcd如何处理一个客户端请求的涉及到的模块和流程，其中两个大模块为： etcd server：对外接收客户端的请求，对应etcd代码中的etcdserver目录，其中还有一个raft.go的模块与etcd-raft库进行通信。etcdserver中与存储相关的模块是applierV3，这里封装了V3版本的数据存储，WAL（write ahead log），用于写数据日志，etcd启动时会根据这部分内容进行恢复。 etcd raft：etcd的raft库，前面的文章已经具体分析过这部分代码。除了与本节点的etcd server通信之外，还与集群中的其他etcd server进行交互做一致性数据同步的工作。 在上图中，一个请求与一个etcd集群交互的主要流程分为两大部分： 写数据到某个etcd server中。 该etcd server与集群中的其他etcd节点进行交互，当确保数据已经被存储之后应答客户端。 请求流程划分为了以下的子步骤： 1.1：etcd server收到客户端请求。 1.2：etcd server将请求发送给本模块中的raft.go，这里负责与etcd raft模块进行通信。 1.3：raft.go将数据封装成raft日志的形式提交给raft模块。 1.4：raft模块会首先保存到raftLog的unstable存储部分。 1.5：raft模块通过raft协议与集群中其他etcd节点进行交互。 注意在以上流程中，假设这里写入数据的etcd是leader节点，因为在raft协议中，如果提交数据到非leader节点的话需要路由到etcd leader节点去。而应答步骤如下： 2.1：集群中其他节点向leader节点应答接收这条日志数据。 2.2：当超过集群半数以上节点应答接收这条日志数据时，etcd raft通过Ready结构体通知etcd server中的raft该日志数据已经commit。 2.3：raft.go收到Ready数据将首先将这条日志写入到WAL模块中。 2.4：通知最上层的etcd server该日志已经commit。 2.5：etcd server调用applierV3模块将日志写入持久化存储中。 2.6：etcd server应答客户端该数据写入成功。 2.7：最后etcd server调用etcd raft，修改其raftLog模块的数据，将这条日志写入到raftLog的storage中。 从上面的流程可以看到： etcd raft模块在应答某条日志数据已经commit之后，是首先写入到WAL模块中的，因为这个模块只是添加一条日志，所以速度会很快，即使在后面applierV3写入失败，重启的时候也可以根据WAL模块中的日志数据进行恢复。 etcd raft中的raftLog，按照前面文章的分析，其中的数据是保存到内存中的，重启即失效，上层应用真实的数据是持久化保存到WAL和applierV3中的。 以下就来分析etcd server与这部分相关的几个模块。 2. etcd server与raft的交互EtcdServer 结构体，负责对外与客户端进行通信。内部有一个 raftNode 结构的成员，负责与etcd的raft库进行交互。 etcd V3版本的API，通过GRPC协议与客户端进行交互，其相关代码在 etcdserver/v3_server.go 中。以一次Put请求为例，最后将会调用的代码在函数 EtcdServer::processInternalRaftRequestOnce 中，代码的主要流程分析如下： 拿到当前raft中的apply和commit索引，如果commit索引比apply索引超出太多，说明当前有很多数据都没有apply，返回 ErrTooManyRequests 错误。 调用 s.reqIDGen.Next() 函数生成一个针对当前请求的ID，注意这个ID并不是一个随机数而是一个严格递增的整数。同时将请求序列化为byte数据，这会做为raft的数据进行存储。 根据第2步中的ID，调用 Wait.Register 函数进行注册，这会返回一个用于通知结果的channel，后续就通过监听该channel来确定是否成功储存了提交的值。 调用 Raft.Process 函数提交数据，这里传入的参数除了前面序列化的数据之外，还有使用超时时间创建的Context。 监听前面的Channel以及Context对象： a. 如果 context.Done 返回，说明数据提交超时，使用 s.parseProposeCtxErr 函数返回具体的错误。 b. 如果channel返回，说明已经提交成功。 从以上的流程可以看出，在调用 Raft.Process 函数向Raft库提交数据之后，等待被唤醒的Channel才是正常提交数据成功的路径。 在 EtcdServer.run 函数中，最终会进入一个死循环中，等待 raftNode.apply 返回的channel被唤醒，而raftNode继承了 raft.Node 的实现，从前面分析etcd raft的流程中可以明白，EtcdServer就是在向raft库提交了数据之后，做为其上层消费Ready数据的应用层。 自此，整体的流程大体如下： EtcdServer对外通过GRPC协议接收客户端请求，对内有一个raftNode类型的成员，该类型继承了raft.Node的实现。 客户端通过EtcdServer提交的数据修改都会通过raftNode来提交，而EtcdServer本身通过监听channel与raft库进行通信，由Ready结构体来通过EtcdServer哪些数据已经提交成功。 由于每个请求都会一个对应的ID，ID绑定了Channel，所以提交成功的请求通过ID找到对应的Channel来唤醒提交流程，最后通知客户端提交数据成功。 3. WAL以上介绍了EtcdServer的大体流程，接下来看WAL的实现。 前面已经分析过了，etcd raft提交数据成功之后，将通知上面的应用层（在这里就是EtcdServer），然后再进行持久化数据存储。而数据的持久化可能会花费一些时间，因此在应答应用层之前，EtcdServer中的raftNode会首先将这些数据写入WAL日志中。这样即使在做持久化的时候数据丢失了，启动恢复的时候也可以根据WAL的日志进行数据恢复。 etcdserver模块中，给raftNode用于写WAL日志的工作，交给了接口Storage来完成，而这个接口由storage来具体实现： 1234type storage struct { *wal.WAL *snap.Snapshotter} 可以看到，这个结构体组合了WAL和snap.Snapshotter结构，Snapshotter负责的是存储快照数据。 WAL日志文件中，每条日志记录有以下的类型： Type：日志记录类型，下面详细解释都有哪些类型。 Crc：这一条日志记录的校验数据。 Data：真正的数据，根据类型不同存储的数据也不同。 日志记录又有如下的类型： metadataType：存储的是元数据（metadata），每个WAL文件开头都有这类型的一条记录数据。 entryType：保存的是raft的数据，也就是客户端提交上来并且已经commit的数据。 stateType：保存的是当前集群的状态信息，即前面提到的HardState。 crcType：校验数据。 snapshotType：快照数据。 etcd使用两个目录分别存放WAL文件以及快照文件。其中，WAL文件的文件名格式是“16位的WAL文件编号-该WAL第一条entry数据的index号.wal”，这样就能从WAL文件名知道该WAL文件中保存的entry数据至少大于什么索引号。而快照文件名的格式则是“16位的快照数据最后一条日志记录任期号-16位的快照数据最后一条记录的索引号.snap”。 Etcd会管理WAL目录中的所有WAL文件，但是在生成快照文件之后，在快照数据之前的WAL文件将被清除掉，保证磁盘不会一直增长。比如当前etcd中有三个WAL文件，可以从这些文件的文件名知道其中存放数据的索引范围。 在生成快照文件之后，此时就只剩一个WAL文件和一个快照文件了： 那么，又是在什么情况下生成快照文件呢？Etcdserver在主循环中通过监听channel获知当前raft协议返回的Ready数据，此时会做判断如果当前保存的快照数据索引距离上一次已经超过一个阈值（EtcdServer.snapCount），此时就从raft的存储中生成一份当前的快照数据，写入快照文件成功之后，就可以将这之前的WAL文件释放了。 以上流程和对应的具体函数见下面的流程图： 4. backend store的实现4.1 revision概念Etcd存储数据时，并不是像其他的KV存储那样，存放数据的键做为key，而是以数据的revision做为key，键值做为数据来存放。如何理解revision这个概念，将用以下面的例子来说明。 比如通过批量接口两次更新两对键值，第一次写入数据时，写入&lt;key1,value1&gt;和&lt;key2,value2&gt;，在Etcd这边的存储看来，存放的数据就是这样的： 12revision={1,0}, key=key1, value=value1revision={1,1}, key=key2, value=value2 而在第二次更新写入数据&lt;key1,update1&gt;和&lt;key2,update2&gt;后，存储中又记录（注意不是覆盖前面的数据）了以下数据： 12revision={2,0}, key=key1, value=update1revision={2,1}, key=key2, value=update2 其中revision有两部分组成，第一部分成为main revision，每次事务递增1；第二部分称为sub revision，一个事务内的一次操作递增1。 两者结合，就能保证key的唯一性且单调递增。 但是，客户端是根据Key值来进行操作的，所以需要一个Key映射到当前revision的操作。由此etcd引入了一个内存中的Btree索引，整个操作过程如下面的流程所示： 查询时，先通过内存中的btree索引来查询该key对应的keyIndex结构体，然后再根据这个结构体才能去boltDB中查询真实的数据返回。 所以，下面先展开讨论这个keyIndex结构体和btree索引。 4.2 keyIndex结构keyIndex结构体有以下成员： key：存储数据真实的键。 modified：最后一次修改该键对应的revision。 generations：generation数组。 如何理解generation结构呢，可以认为每个generation对应一个数据从创建到删除的过程。每次删除key的操作，都会导致一个generation最后添加一个tombstone记录，然后创建一个新的空generation记录添加到generations数组中。 generation结构体存放以下数据： ver：当前generation中存放了多少次修改，其实就是revs数组的大小-1（因为需要去掉tombstone）。 created：创建该generation时的revision。 revs：存放该generation中存放的revision数组。 keyIndex结构体如下： 如上图所示，存放的键为test的keyIndex结构。它的generations数组有两条记录，其中generations[0]在revision 1.0时创建，当revision2.1的时候进行tombstone操作，因此该generation的created是1.0；对应的generations[1]在revision3.3时创建，紧跟着就做了tombstone操作。 所以该 keyIndex.modifiled 成员存放的是3.3，因为这是这条数据最后一次被修改的revision。一个已经被tombstone的generation是可以被删除的，如果整个generations数组都已经被删除空了，那么整个keyIndex记录也可以被删除了。 如上图所示，keyIndex.compact(n) 函数可以对keyIndex数据进行压缩操作，将删除满足main revision &lt; n的数据。 compact(2)：找到了generations[0]的1.0 revision的数据进行了删除。compact(3)：找到了generations[0]的2.1 revision的数据进行了删除，此时由于generations[0]已经没有数据了，所以这一整个generation被删除，原先的generations[1]变成了generations[0]。compact(4)：找到了generations[0]的3.3 revision的数据进行了删除。由于所有的generation数据都被删除了，此时这个keyIndex数据可以删除了。 4.3 treeIndex结构Etcd中使用treeIndex来在内存中存放keyIndex数据信息，这样就可以快速的根据输入的key定位到对应的keyIndex。 treeIndex使用开源的 github.com/google/btree 来在内存中存储btree索引信息，因为用的是外部库，所以不打算就这部分做解释。而如果很清楚了前面keyIndex结构，其实这部分很好理解。 所有的操作都以key做为参数进行操作，treeIndex使用btree根据key查找到对应的keyIndex，再进行相关的操作，最后重新写入到btree中。 4.4 store前面讲到了WAL数据的存储、内存索引数据的存储，这部分讨论持久化存储数据的模块。 etcd V3版本中，使用BoltDB来持久化存储数据，所以这里先简单解释一下BoltDB中的相关概念。 4.4.1 BoltDB相关概念BoltDB中涉及到的几个数据结构，分别为DB、Bucket、Tx、Cursor、Tx： DB：表示数据库，类比于Mysql。 Bucket：数据库中的键值集合，类比于Mysql中的一张数据表。 键值对：BoltDB中实际存储的数据，类比于Mysql中的一行数据。 Cursor：迭代器，用于按顺序遍历Bucket中的键值对。 Tx：表示数据库操作中的一次只读或者读写事务。 4.4.2 Backend 与 BackendTx 接口Backend和BackendTx内部的实现，封装了BoltDB，在此不做分析。 4.4.3 Lessor接口etcd中没有提供针对数据设置过期时间的操作，通过租约（Lease）来实现数据过期的效果。而Lessor就提供了管理租约的相关接口。 比如，使用 etcdctl 命令可以创建一个lease： etcdctl lease grant 10 lease 694d67ed2bfbea03 granted with TTL(10s) 这样就创建了一个ID为694d67ed2bfbea03的Lease，此时可以将键值与这个lease进行绑定： etcdctl put –lease=694d67ed2bfbea03 a b 当时间还没超过过期时间10S时，能通过etcd拿到这对键值的数据。如果超时了就获取不到数据了。从上面的命令可以看出，一个Lease可以与多个键值对应，由这个Lease通过管理与其绑定的键值数据的生命周期。 etcd中，将Lease ID存放在名为“lease”的Bucket中，注意在这里只存放Lease相关的数据，其键值为：&lt;Lease ID，序列化后的Lease数据包括TTL、ID&gt;，之所以不存放与Lease绑定的键值，是因为这些键值已经存放到另外的Bucket里了，写入数据的时候也会将这些键值绑定的Lease ID写入，这样在恢复数据的时候就可以将键值与Lease ID绑定的关系写入内存中。 即：Lease这边需要持久化的数据只有Lease ID与TTL值，而键值对这边会持久化所绑定的Lease ID，这样在启动恢复的时候可以将两者对应的关系恢复到内存中。 明白了以上关系再来理解Lessor的实现就很简单了，lessor中主要包括以下的成员： leaseMap map[LeaseID]*Lease：存储LeaseID与Lease实例之间的对应关系。 itemMap map[LeaseItem]LeaseID：leaseItem实际存放的是键值，所以这个map管理的就是键值与Lease ID之间的对应关系。 b backend.Backend：持久化存储，每个Lease的持久化数据会写入名为“lease”的Bucket中。 minLeaseTTL int64：最小过期时间，设置给每个lease的过期时间不得小于这个数据。 expiredC chan []*Lease：通过这个channel通知外部有哪些Lease过期了。 其他的就很简单了: lessor启动之后会运行一个goroutine协程，在这个协程里定期查询哪些Lease超时，超时的Lease将通过expiredC channel通知外部。 而针对Lease的CRUD操作，都需要进行加锁才能操作。 4.5 KV接口有了以上的准备，可以开始分析数据存储相关的内容了。在etcd V3中，所有涉及到数据的存储，都会通过KV接口。 store结构体实现了KV接口，其中最重要的就是封装了前面提到的几个数据结构： b backend.Backend：用于将持久化数据写入BoltDB中。 kvindex index：保存key索引。 changes []mvccpb.KeyValue：保存每次写操作之后进行了修改的数据，用于通知watch了这些数据变更的客户端。 在store结构体初始化时，根据传入的 backend.Backend，初始化 backend.BatchTx 结构，后面的任何涉及到事务的操作，都可以通过这个 backend.BatchTx 来进行。 其实有了前面的准备，理解store结构做的事情已经不难，以一次Put操作为例，其流程主要如下图所示： 5. applierV3EtcdServer 内部实现中，实际使用的是applierV3接口来进行持久化数据的操作。 这个接口有以下几个实现，但是其中applierV3backend的实现是最重要的，其内部使用了前面提到的KV接口来进行数据的处理。 另外，applierV3接口还有其他几个实现，这里分别列举一下： applierV3backend：基础的applierV3接口实现，其他几个实现都在此实现上做功能扩展。内部调用EtcdServer中的KV接口进行持久化数据读写操作。 applierV3Capped：磁盘空间不足的情况下，EtcdServer中的applierV3切换到这个实现里面来，这个实现的任何写入操作都会失败，这样保证底层存储的数据量不再增加。 authApplierV3：在applierV3backend的基础上扩展出权限控制的功能。 quotaApplierV3：在applierV3backend的基础上加上了限流功能，即底层的存储到了上限的话，会触发限流操作。 6. 综述下图将上面所提及到的关键数据结构串联起来，我们可以看到EtcdServer在收到Raft库通过Ready channel通知的可以持久化数据之后，都做了什么操作： raft库通过Ready Channel通知上层的raftNode哪些数据可以进行持久化。 raftNode启动之后也是会启动一个Goroutine来一直监听这个Ready Channel，以便收到可以持久化数据的通知。 raftNode在收到Ready数据之后，将首先写入WAL日志中。这里的WAL日志由storage结构体来管理，分为两大部分：WAL日志以及WAL快照文件数据Snapshotter，后者用来避免WAL文件一直增大。 raftNode在写WAL数据完成之后，通过apply Channel通知EtcdServer。 EtcdServer启动之后也是启动一个Goroutine来监听这个channel，以便收到可以持久化数据的通知。 EtcdServer通过调用applierV3接口来持久化数据。applierV3backend结构体实现applierV3接口, applierV3backend结构体实现applierV3接口，内部通过调用KV接口进行持久化操作。而在实现KV接口的store结构体中，treeIndex负责在内存中维护数据键值与revision的对应关系即keyIndex数据，Backend接口负责持久化数据，最后持久化的数据将落盘到BoltDB中。","link":"/2022/01/19/%E4%BD%BF%E7%94%A8etcd%E5%AE%9E%E7%8E%B0%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1/"},{"title":"《In Search of an Understandable Consensus Algorithm》译文","text":"Replicated state machines What’s wrong with Paxos? Designing for understandability The Raft consensus algorithm Cluster membership changes Clients and log compaction Implementation and evalution 目录论文链接 Abstract 1 Introduction 2 Replicated state machines 3 What’s wrong with Paxos? 4 Designing for understandability 5 The Raft consensus algorithm 5.1 Raft basics 5.2 Leader election 5.3 Log replication 5.4 Safety 5.4.1 Election restriction 5.4.2 Committing entries from previous terms 5.4.3 Safety argument 5.5 Follower and candidate crashes 5.6 Timing and availability 6 Cluster membership changes 7 Clients and log compaction 8 Implementation and evalution AbstractRaft是一种用于管理复制日志（replicated log）的共识算法。它能产生和(multi-)Paxos相同的结果，且和Paxos一样有效。但是，它的结构却不同于Paxos；这让Raft比Paxos更易于理解，也为构建实际系统提供了更好的基础。为了增强可理解性，Raft将例如领导者选举, 日志复制与安全性等关键共识元素进行了分离，并且提供了更强的一致性，目的是减少必须考虑的状态。用户调查的结果显示，Raft比Paxos更易于学生学习。Raft包含了一种改变集群成员的新机制，通过大量重叠（overlapping majority）来保证安全性。 1 Introduction共识算法允许一组机器像一致的的整体一样工作，即使其中一员发生故障也不会出现问题。因此，它在构建可靠的大规模软件系统的过程中起着关键的作用。Paxos一直主导着过去十年间对共识算法的讨论：大多数共识的实现都基于Paxos或者受其影响。Paxos已经成为了用来教授共识算法给学生的主要工具。 不幸的是，尽管已经做了大量努力去化简Paxos，但它还是太难以理解了。另外，它的结构需要做复杂的改变来支持实际的系统。因此，系统架构师和学生都对Paxos感到困扰。 在切身的被Paxos困扰之后，我们决定实现一种新的共识算法，使之可以为系统的构建和教学提供更好的基础。我们的主要目标是让它更易于理解，所以我们的方法有些不同寻常：我们是否能以一种比Paxos更易于理解的方式为实际的系统定义一个共识算法？此外，我们想要该算法能更好的被直观理解，而这对系统构建者很重要。算法生效很重要，但是，能清楚地显示它为什么生效也同样重要。 这项工作的结果就是一个名为Raft的共识算法。在设计Raft的时候，我们使用了一些额外的技术用于提供可理解性，包括分解（Raft分离了领导者选举, 日志复制与安全性）以及状态空间的缩减（相较于Paxos，Raft降低了不确定性以及sever间达到一致的方法）。一个由来自两个大学的43位学生参与的用户调查显示Raft要比Paxos易于理解的多；在同时学习了两种方法之后，他们中的33名学生回答Raft的问题要好于Paxos。 Raft在很多方面和现存的共识算法类似（最值得注意的是Oki和Liskov的Viewstamped Replication [27, 20]），但是它有以下这些独特的特性： Strong leader：Raft比其他共识算法使用了更强形式的leadership。比如，日志记录（log entry）只能从leader传给其他server。这简化了对于replicated log的管理并且使Raft更加易于理解。 Leader election：Raft使用随机的时钟来选举leader。这只是在原来所有共识算法都需要的heartbeats基础上增加了一小部分机制，但是却简单快速地解决了冲突。 Membership changes：Raft通过一种新的joint consensus的方法来实现server集合的改变，其中两个不同配置下的majority在过度阶段会发生重合。这能让集群在配置改变时也能继续正常运行。 不论对于教学还是作为实现系统的基础，我们相信Raft都要优于Paxos和其他的共识算法。它比其他算法更简答也更加易于理解；它能完全满足实际系统的需求；它有很多开源的实现并且已经被很多公司使用；它的安全性已经被充分证实了；并且它和其他算法一样地有效。 论文的剩余部分介绍了replicated state machine问题（Section 2）、讨论了Paxos的优缺点（Section 3）、描述了可理解性的一般方法（Section 4）、描述了Raft 共识算法（Section 5-7）、评估Raft（Section 8）、最后论述有关工作（Section 9）。受限于篇幅，Raft中的一些元素在这里省略了，但是它们可以在一份扩展的技术报告[29]中找到。其余内容描述了client如何和系统进行交互以及如何回收Raft log空间。 2 Replicated state machines共识算法通常出现在replicated state machiness[33]的上下文中。在这种方法中，一组server上的状态机（state machine）对同一个状态的拷贝进行计算，即使其中一些server宕机了也能正常运行。Replicated state machine通常用于解决分布式系统中的容错问题。例如，拥有单一集群 leader的大规模系统，例如GFS[7]、HDFS[34]和RAMCloud[30]通常会用一个单独的replicated state machine来管理leader选举以及存储用于挽救leader崩溃的配置信息。Replicated state machine典型的例子包括Chubby[2]和ZooKeeper[9]。 Replicated state machine通常用replicated log来实现，如Figure 1所示。每一个server存储了一个包含一系列命令的log，而它的状态机按顺序执行这些命令。每个日志以同样的顺序包含了同样的指令，所以每一个状态机都会处理相同的命令。由于每一个状态机都是确定的，因此计算将得到同样的状态和输出结果。 共识算法的作用是保证replicated log的一致性。server中的共识模块用于从client处接收命令并且将它们加入log。它会和其他server的共识模块进行通信，从而确保每一个log都以同样的顺序包含同样的请求，每一个server的状态机都按顺序处理它们的log，并且将输出返回给client。最终，这些server呈现出的是一个单一的，高度可靠的状态机。 用于实际系统的共识算法通常具有以下特性： 在所有的非拜占庭（non-Byzantine）条件下要确保正确性（从不返回一个错误的结果），包括网络延迟或分区，以及网络包的丢失、重复和乱序。 只要大多数server是可操作的、能相互通信的、并且可以和client进行通信的，那么系统必须是可用的。因此，一个由五台server组成的集群必须能忍受两台server的故障。一个server发生故障时，可能是暂停了；它可能稍后会恢复到存储在stable storage中的状态并且重新加入集群。 它们不依赖于时间来确保log的一致性：最差的情况下，fault clocks和extreme message delays会导致系统的不可用问题。 通常情况下，当集群中的大多数server已经对单一的RPC做出相应时，可以认为一个命令完成了。少数反应慢的server不应该影响整个系统的性能。 3 What’s wrong with Paxos?在过去的十年中，Leslie Lamport的Paxos协议[13]几乎成为了共识的代名词：它是在课堂上最常被教授的协议，并且很多共识的实现都以它作为起点。Paxos首先定义了在单一decision上能够达到一致的协议，例如一个单一的replicated log entry。我们将这样的一个子集称之为single-decree Paxos。接下来，Paxos可以将该协议的多个实例组合在一起去形成一系列的decision作为log（multi-Paxos）。Paxos保证了safety和liveness，并且支持cluster membership的改变。它的正确已经经过证明，并且在一般的情况下也是高效的。 不幸的是，Paxos有两个严重的缺陷。第一个缺陷是Paxos太难以理解了。它的完整描述[13]是有名的难懂；很少有人能完全理解它，即使可以也需要巨大的努力。因此，已经做了很多尝试，尝试以更简单的版本[14,18,19]去解释Paxos。虽然这些尝试都着力于single-decree版本，但是仍面临着挑战。在一项针对NSDI 2012与会者的调查中，我们发现很少有人对Paxos感到舒服，即便是那些经验丰富的研究人员。我们自身也对Paxos感到非常痛苦，我们在不能理解完整的协议，直到我们阅读了几个简化版的描述并设计了我们的替代协议，整个过程持续了近一年。 我们认为Paxos的晦涩来源于它将single-decree subset作为自己的基础。Single-decree Paxos很难懂，也很隐晦：它被划分为两个不能用直觉来解释的阶段并且不能单独理解。因此，这就导致了很难对single-decree protocol是如何工作的建立起直觉。而multi-Paxos的composition rule则更加添加了复杂性。我们坚信对于在multiple decision的情况下到达consensus这个问题肯定能以其他更直接，更明显的方式被分解。 Paxos的第二个问题是它没有为具体实现提供一个很好的基础。一个原因是对于multi-Paxos没有一个广受认可的算法。Lamport的描述主要针对的是single-decree Paxos；他概述了实现multi-Paxos的可能途径，如[24],[35]和[11]，但是缺少很多细节。对于充实以及优化Paxos已经做过很多努力，但是它们之间，以及和Lamport的概述都不相同。像Chubby[4]这样的系统已经实现了类Paxos算法，但是它的很多细节并没有公开。 另外，Paxos的架构也不适合构建实际系统；这是它按single-decree分解的另一个后果。例如，独立地选取一组log entry并且将它们融合成一个顺序的log并没有什么好处，仅仅只是增加了复杂度。相反，围绕按顺序扩展的log来设计一个系统是更简单和高效的。Paxos的另一个问题是它将对称的peer-to-peer作为核心（虽然在最后为了优化性能提出了一种弱形式的leadership）。这在只需要做一个decision的简单场景中是可行的，但是很少有实际的系统会使用这种方法。如果要有一系列的decision要决定，那么简单且快速的做法是先选出一个leader，然后再让leader去协调decision。 因此，实际系统和Paxos都没什么相同之处。各种实现都以Paxos开始，然后发现实现起来很困难，最后只能开发出了一个完全不同的架构。这是极其费时且易出错的，而Paxos的难以理解则更加加剧了这个问题。Paxos的正确性理论很好证明，但是具体实现和Paxos太过不同，因此这些证明就没什么价值了。接下来这段来自Chubby的评论是非常典型的： “Paxos算法的描述和现实世界的系统的需求之间有巨大的矛盾….而最终的系统都将建立在一个未经证明的协议之上” 因为这些问题的存在，我们得出这样的结论，Paxos并没有为实际系统的构建和教学提供一个很好的基础。基于在大规模软件系统中consensus的重要性，我们决定尝试能否设计出另外一种比Paxos有着更好性质的共识算法。而Raft就是我们实践的结果。 4 Designing for understandability我们在设计Raft的时候有以下几个目标：它必须为系统的构建提供完整并且实际有效的基础，而这能极大地减少开发者的设计工作；它必须在所有条件下都是安全的，在典型的操作条件下是可用的；它在通常的操作中也必须是高效的。但我们最重要的目标，也是最大的挑战，就是可理解性。我们必须让广大的读者能相对轻松地理解这个算法。并且要能够构建对这个算法的感觉，从而让系统构建者能做一些实际实现中必要的扩展。 在设计Raft的很多点上，我们要在很多可选方法之间做出选择。在这些情况下，我们基于可理解性对这些方法进行评估：对于每一个可选方案的描述是否困难（比如，它的状态空间的复杂度是多少，以及它是否有subtle implication？）以及读者是否能轻松地完全理解这种方法和它的含义。 后来我们意识到这种分析方法具有很强的主观性；于是我们使用了两种方法让分析变得更具通用性。第一种是广为人知的问题分解方法：我们能否将问题分解为可以被相对独立地解释，理解并且被解决的几部分。例如，在Raft中，我们分解了leader election, log replication, safety和membership changes这几部分。 我们的第二种方法是通过减少需要考虑的状态数，尽量让系统更一致以及尽可能地减少非确定性，以此简化状态空间。具体来说，log不允许存在漏洞（hole），Raft限制了log之间产生不一致的途径。虽然在大多数情况下，我们都要减少不确定性，但是在某些情况下，不确定性确实提高了可理解性。特别地，随机化的方法会引入不确定性，但是通过以相同的方式处理所有可能的选择（choose any; it doesn’t matter），确实减少了状态空间。我们就使用了随机化来化简Raft的leader election算法。 5 The Raft consensus algorithmRaft是一种用于管理Section 2中所描述的形式的replicated log的算法。Figure 2以精简的形式总结了这一算法，而Figure 3列出了该算法的关键特性，而这些特性将在本节的剩余部分分别进行讨论。 Raft首先通过选举一个顶层的leader来实现共识，然后把管理replicated log的责任全部给予这个leader。leader从client处接收log entry，再将它备份到其他server中，接着告诉server什么时候能安全地将log entry加入state machine中。leader的存在简化了replicated log的管理。比如，leader可以在不询问其他server的情况下决定将新的entry存放在log的什么位置并且数据简单地从leader传给其他server。leader可能会发生故障或者和其他server断开，在这种情况下会有新的leader被选举出来。 通过选举leader，Raft将共识问题分解成三个相对独立的子问题，它们会在接下来的子章节中讨论： Leader election：如果现存的leader发生故障，必须选举出一个新的leader（Section 5.2） Log replication：leader必须从client处接收log entry并且将它们在集群中进行备份，强制使其他log与它自己一致（Section 5.3） Safety：Raft中最关键的safety property就是Figure 3所示的State Machine Safety Property：如果有任何的server已经将一个特定的log entry加入它的state machine中，那么其他的server对于同一个log index的log entry必须相同。Section 5.4 描述了Raft如何确保这个性质; 该解决方案涉及对Section 5.2中描述的选举机制的额外限制。 在展示了共识算法之后，本节将讨论可用性以及时间在系统中扮演的角色。 5.1 Raft basics一个Raft集群包含多个server；一般是五个，因此系统能忍受两台机器的故障。在任意给定时刻，每个server都处于以下三个状态中的一个：leader、follower或者candidate。在正常情况下，只有一个leader，其他都是follower。follower是被动，它们不会自己发送请求，只是简单地对来自leader和candidate的请求进行回复。leader会对所有来自client的请求进行处理（如果一个client和follower进行交互，follower会将它重定向给leader），第三种状态candidate，是用来选举Section 5.2中描述的新的leader。Figure 4显示了各种server状态以及它们之间的转换；关于转换将在下文进行讨论。 Raft将时间划分成任意长度的term，如Figure 5所示。Term以连续的整数进行编号。每个term以一次election开始，这个阶段会有一个或多个candidate竞选leader，如Section 5.2所示。如果一个candidate竞选成功，那么它将在term剩下的时间里作为leader。在有些情况下，一个election可能导致一次分裂投票（split vote）。在这种情况下，term将以一种没有leader的状态结束；而一个新的term（伴随新的选举）将立即开始。Raft将保证在一个term中，最多只有一个leader产生。 不同的server可能在不同的时间观察到term的转换，而在有些情况下，一个server可能会观察不到选举甚至是一个完整的term。term在Raft中起到的是逻辑时钟的作用，它能够让server去检测那些需要淘汰的信息，如过时的leader。每个server都存储了一个当前任期数（current term number），它会随时间单调递增。当前任期数会随着server之间的通信而改变；如果一个server的当前任期数比其他的小，那么它就会将自己的当前任期数更新到更大的值。如果一个candidate或者leader发现它的term已经过时了，那么它就会自觉恢复到follower状态。如果一个server收到另一个过时任期的server请求，那么会拒绝它。 Raft servers之间通过RPC进行通信，而共识算法需要两种类型的RPC。RequestVote RPC由candidate在election期间发起（Section 5.2），AppendEntries RPC由leader发起，用于备份log entry和提供heartbeat（Section 5.3）。如果一个server没有收到回复，那么它会及时重发RPC，并以并行方式发送RPC来提高性能。 5.2 Leader electionRaft使用一种heartbeat机制来触发leader选举。当server启动的时候，默认作为follower。server如果能持续地从leader或者candidate处获取有效的RPC，那么它将始终保持follower状态。为了保持自己的权威性，leader会阶段性地发送heartbeats（不带有log entry的AppendEntry RPC）给所有的follower。如果一个server在名为election timeout的时间段中没有收到交互信息，那么它就会认为不存在一个 有效的leader，并且发起新的一轮选举来选出一个新的leader。 为了开始一轮选举，follower会增加它的当前任期数并且转换为candidate状态，接着投票给自己，然后并行地给集群中的其他server发送RequestVote RPC。candidate将持续保持这种状态，直到以下三个条件中的一个被触发：(a)它赢得了选举，(b)另一个server宣布它自己是leader，(c)过了一段时间之后也没有赢得选举的server。这些情况将在接下来分别进行讨论。 如果一个candidate在一个term内收到了来自集群中的大多数server的投票，那么它将赢得选举。每一个server在每个term中都最多会给一个candidate投票，并且基于first-come-first-serverd原则（Section 5.4中将对于投票添加一个额外的约束）。大多数原则确保了在一个给定的term中最多只有一个candidate可以赢得选举（Figure 3中的Election Safety Property）。一旦一个candidate赢得了选举，它将成为leader。之后它将向所有其他的server发送hearbeat用以明确自己的权威并且阻止新一轮的选举。 当在等待投票时，一个candidate可能会收到来自另一个server的AppendEntry RPC声称自己是leader。如果该leader的term（包含在该RPC中）大于等于candidate的当前任期数，那么candiate认为该leader是有效的并且返回到follower的状态。如果RPC中的term小于candidate的当前任期数，那么candidate会拒绝该RPC并且保持candidate状态。 第三种可能的情况是一个candidate在选举中既没有赢也没有输：如果在同一时刻有很多follower成为了candidate，选票将会因为分裂而没有candidate会获得大多数选票。当这种情况发生时，每个candidate都会发生timeout并且通过增加term和发送新一轮的RequestVote RPC来开始新的选举。然而如果没有额外的措施，分裂投票（splite vote）可能会一直重复下去。 Raft使用随机的election timeout来确保split vote很少发生并且保证即使发生了也很快会被解决。为了在一开始就避免split ovte，election timeout会在一个固定区间内随机选择（如 150-300ms）。这就将server错开从而保证在大多数情况下只有一个server会timeout；它将赢得选举并且在其他的server超时之前发送heartbeat。同样的机制也被用在处理split vote上。每个candidate在选举开始的时候重新随机确定一个election timeout并在下一次election开始前静止等待timeout的到来；这就减少了在下一轮选举时发生split vote的可能。Section 8.3展示了使用这种方法快速选择一个leader的过程。 选举过程是一个能很好显示易理解性指导我们做出设计选择的例子。一开始我们计划使用一个rank system：每个candidate都会赋予一个唯一的rank，它会被用来在相互竞争的candidate之中做出选择。当一个candidate发现另一个candidate有更高的rank，那么它就会退回到follower的状态，从而让有更高rank的candidate能更容易赢得下一轮election。但我们发现这种方法会在可用性方面产生一些不易察觉的问题（如果有着更高rank的server发生了故障，一个低rank的server可能需要timeout并且重新成为candidate，但是这个过程发生地太快，则会引发新的leader选择过程）。我们对这一算法做了多次调整，但是每次调整之后都有新的极端情况（corner cases）产生。最后我们得出结论：随机重试的方法是更明显和更易于理解的方法。 5.3 Log replication一旦一个leader被选择出来以后，它开始处理client的请求。每个client请求都包含了需要由replicated state machine执行的命令。leader用命令扩展log，作为新的entry，然后并行地给其他server发生AppendEntry RPC来备份entry。当该entry被安全地备份之后（如下所述），leader会让它的state machine执行该entry，并且将执行结果返回给client。如果follower崩溃了或者运行很慢，亦或是丢包的话，leader会不停地重发AppendEntry RPC直到所有的follower最终都保存了所有的log entry。 Log以Figure 6中的形式被组织。当一个entry被leader接收的时候，每个log entry都会包含一个state machine命令和term number。log entry中的term number是用来检测log之间是否一致并且确保Figure 3中的一些特性的。同时，每个log entry都有一个整数型的index用于标示它在log中的位置。 leader决定何时让state machine执行log entry是安全的，而这样的entry被称为committed。Raft保证所有committed entry都是持久的（durable）并最终会被所有可用的state machine执行。一旦创建它的leader已经将它备份到大多数server中，log entry就会被committed（例如Figure 6中的entry 7）。同时它也会commit leader的log中所有前面的entry，包括那些由之前leader创建的entry。Section 5.4中会讨论在leader改变之后应用这条规则会产生的一些微妙的问题，同时它也会说明这样关于commitment的定义是安全的。leader会追踪它已知被committed最高的index，并且会在之后的AppendEntry RPC（包括heartbeat）包含此index，从而让其他server能读取它。一旦follower知道了一个log entry被committed，它会将这个entry应用于本地的state machine（以log的顺序）。 我们设计了Raft log mechanism来保持不同server的log间的高度一致性。这不仅简化了系统行为而让它们可预测，并且这也是确保安全性的重要组件。Raft维护了以下特性，它们合起来构成了Figure 3所示的日志匹配性（Log Matching Property）： 如果不同的log中的两个entry有着相同的index和term，那么它们存储相同的command。 如果不同的log中的两个entry有着相同的index和term，那么它们前面的entry都是相同的。第一个性质保证了leader对于给定log的index和term，它最多产生一个entry,并且log entry永远不会改变它在log中的位置。第二个特性则由AppendEntry一个简单的一致性检查来保证。在发送一个AppendEntry RPC的时候，leader会在其中包含新entry前面entry的index和term。如果follower没有在log中有同样index和term的entry，那么它就会拒绝这个新entry。一致性检查起到了归纳步骤（induction step）的作用：log的initial empty state是满足Log Matching Property的，而一致性检查则在log扩展的时候保证了Log Matching Property。因此，当AppendEntry成功返回的时候，leader就知道该follower的log和自己是否一致。 在进行正常操作的时候，leader和follower的操作始终是一致的，因此AppendEntry的一致性检查永远不会失败。但是，leader的崩溃会导致log处于不一致的状态（老的leader可能还没有将它log中的所有entry完全备份）。而这些不一致性可能随着一系列的leader与follower的崩溃而叠加。Figure 7说明了follower的log可能和新的leader不一致的情况。follower中可能会遗漏一些leader中的entry，同时它里面也可能有一些leader中没有的额外的entry，或者两者都有。log中遗失的或者额外的entry中可能跨越多个任期。 为了让follower的log和自己保持一致，leader必须找到最后使二者log一致的entry，并且删除follower中该entry之后所有的entry。所有这些操作都用于回应AppendEntry RPC的一致性检查。leader为每一个follower都维护一个nextIndex，它代表了leader将会发送给follower的下一个log entry的编号。当一个leader刚刚开始运行的时候，它会将所有的nextIndex都初始化为它自己log的最后一个entry的index + 1（Figure 7中的11）。如果follower和leader的log不一致，AppendEntry RPC的一致性检查会在下一个AppendEntry RPC的时候失败。在收到一个rejection之后，leader会减小它的nextIndex并且重发AppendEntry RPC。最终nextIndex会达到leader和follower的log匹配的状态。此时，AppendEntry会成功返回，删除follower的log中不一致的entry并且会根据leader的log进行扩展（如果有的话）。一旦AppendEntry成功，follower已经和leader的log一致了，而且将在term的接下来部分保持。该协议可以通过减少rejected AppendEntry RPC的数目来优化。 在这种机制下，leader不用在它刚刚成为leader的时候执行任何额外的操作用于恢复log的一致性。它只用正常地开始运行，并且log会随着AppendEntry一致性检查的失败而不断收敛。leader从来不会重写或者删除它自己log的entry（Figure 3中的Leader Append-Only Property）。 该log replication mechanism展示了Section 2中想要达到的一致性（consensus property）：Raft可以接收、备份并执行新的log entry，只要有大多数server正常运行；在正常情况下，一个新entry会在仅一轮RPC中被备份到集群的大多数server中；因此一个运行较慢的follower并不会影响性能。 5.4 Safety在前面的章节中描述了Raft如何选举leader以及备份log entry。但是之前描述的机制并不足以保证每个state machine以同样的顺序执行同样的command。例如，follower可能在leader commit多个log entry的时候一直处于不可用的状态，而之后它可能被选作leader并且用新的entry覆写这些entry；因此，不同的state machine可能会执行不同的command序列。 本节中，我们通过给哪些server能被选举为leader增加约束来完善Raft算法。该约束确保任何term的leader会包含之前term所有commit的entry（Figure 3中的Leader Completeness Property）。通过增加election restriction，我们更加细化了commitment的规则。最后，我们给出了Leader Completeness Property的证明概述并展示了它如何规范了replicated state machine的操作。 5.4.1 Election restriction任何基于leader的共识算法，leader最终都必须存储所有的已提交entry。在一些共识算法中，例如Viewstamped Replication[20]，即使一开始没有包含全部的已提交entry也能被选为leader。这些算法都会包含额外的机制用于识别遗失的entry并且将它们传给新的leader，要么在election期间，要么在不久之后。不幸的是，这需要额外的机制和更高的复杂度。Raft使用了一种更简单的方法，它保证在选举期间每个新的leader都包含了前面term包含的所有entry，从而不需要将这些entry传给leader。这意味着log entry的流动是单方向的，只从leader流向follower，而leader从不会重写log中已有的entry。 Raft用投票程序（voting process）来防止那些log中不含全部committed entry的candidate成为leader。candidate为了赢得选举必须和集群的大多数server进行交互，这意味着每个committed entry必须在大多数server中存在。如果一个candidate的log至少和一个大多数server子集群的log保持up-to-date（”up-to-date”将在下文精确定义），那么它就包含了所有committed entry。RequestVote RPC实现了这一约束：RPC中包含了candidate的log信息，如果voter自身的log比该candidate的log更up-to-date，那么它会拒绝投票。 Raft通过比较log中最近一个entry的index和term来确定两个log哪个更up-to-date。如果两个log的last entry有不同的term，那么拥有较大term的那个log更up-to-date。如果两个log以相同的term结束，那么log更长的那个就更up-to-date。 5.4.2 Committing entries from previous terms如Section 5.3中所述，一旦该entry已经被大多数个server存储了，leader就知道current term中的entry已经被提交了。如果一个leader在committing an entry之前就崩溃了，那么新leader就会尝试完成该entry的备份。可是一旦前面term的entry被存储于大多数个server中，leader就很难立刻确定它是否已经committed。Figure 8展示了这样一种情况，一个旧log entry已经被存储在大多数个server中，但是它仍然可以被新leader重写。 为了防止Figure 8中这样问题的发生，Raft不会通过计算备份的数目来提交之前term的log entry。只有leader当前term的log entry才通过计算备份数committed；一旦当前term的entry以这种方式被committed了，那么之前的所有entry都将因为Log Matching Property而被间接committed。其实在很多情况下，leader可以非常安全地确定一个旧entry已经被committed了（比如，如果该entry已经被存储在所有server中了），但是Raft为了简单起见使用了一种更保守的方法。 因为leader从之前的term备份entry时，log要保留之前的term number，这会让Raft在提交规则中引入额外的复杂度。在其他共识算法中，如果一个新的leader从之前的term备份entry时，它必须使用它自己的新的term number。因为log entry的term number不随时间和log的不同而改变，这就能让Raft更加容易地进行推导。另外，Raft中的新的leader与其他算法相比只需要从之前的term传输更少的log entry（其他的算法必须在传输备份的log entry被committed之前进行重新编号）。 5.4.3 Safety argument给出了完整的Raft算法之后，我们可以进一步论证leader完整性（Leader Completeness Property）成立（该论据基于safety proof；参见Section 8.2）。我们假设leader完整性是不成立的，并推出矛盾。假设term T的leader(leaderT) commit了一个该term的log entry，但是该log entry并没有被新term的leader存储。考虑满足大于T的最小的term U，它的leader(leaderU)没有存储该entry。 在leaderU选举期间，该committed entry一定不存在于它的log中（leader从不删除或者重写entry）。 leaderT将entry备份到了集群的大多数server中，并且leaderU获取了来自集群的大多数的投票，如Figure 9所示。而voter是产身矛盾的关键。 voter一定在投票给leaderU之前已经接受了来自leaderT的committed entry；否则它将拒绝来自leaderT的AppendEntry request（因为它的current term已经高于了T）。 当voter投票给leaderU的时候它依然保有该entry，因为每个intervening leader都包含该entry(根据假设)，leader从不删除entry，而follower只删除它们和leader矛盾的entry。 voter投票给leaderU，因此leaderU的log一定和voter的log一样up-to-date。这就产生了两个矛盾中的其中一个。 首先，如果voter和leaderU共享同一个last log term，那么leaderU的log至少要和voter的log一样长，因此它的log包含了voter的log中的每一个entry。这是矛盾的，因为voter包含了committed entry而假设中的leaderU是不包含的。 除非，leaderU的last log term必须比voter的大。进一步说，它必须大于T，因为voter的last log term至少是T（它包含了term T的committed entry）。之前创建leaderU的last log entry的leader必须在它的log中包含了committed entry（根据假设）。那么，根据Log Matching Property，leaderU的log必须包含committed entry，这同样是一个矛盾。 这就是矛盾所在。因此，所有term大于T的leader必须包含所有来自于T并且在term T提交的entry。 Log Matching Property确保了新leader也会包含那些间接committed的entry，例如Figure 8(d)中的index 2。 给定Leader Completeness Property，证明Figure 3中的State Machine Safety Property就比较容易，即让所有的state machine以相同的顺序执行同样的log entry。 5.5 Follower and candidate crashes在此之前我们都在重点研究leader failures。follower和candidate的崩溃比起leader的崩溃要容易处理得多，而且它们的处理方式相同。如果一个follower或者candidate崩溃了，那么后面发送给它的RequestVote和AppendEntry RPC都会失败。Raft通过不断地重试来处理这些故障；若崩溃的服务器重启了，那么后面的RPC就会生效。如果server在RPC生效后但在回复前崩溃了，那么它会在重启之后收到同样的RPC。但是Raft的RPC是幂等的(idempotent)，因此不会造成什么问题。比如一个follower接收了包含一个已经存在于log中的AppendEntry request，它会直接忽略。 5.6 Timing and availability我们对于Raft的一个要求是，其安全性不能依赖于时间：系统不会因为有些事件发生地比预期更快或更慢而产生错误的结果。然而，可用性（系统及时响应client的能力）将不可避免地依赖于时间。比如，由于server崩溃造成的信息交换的时间比通常情况下来得长，所以candidate就不能停留足够长的时间来赢得选举；而没有一个稳定的leader，Raft将不能进一步执行。 leader选举是Raft中时间作用最重要的地方。当系统满足以下的时间要求的时候，Raft就能够选举并且维护一个稳定的leader： broadcastTime &lt;&lt; electionTimeout &lt;&lt; MTBF(广播时间 &lt;&lt; 选举超时时间 &lt;&lt; 故障时间间隔) 在这个不等式中，broadcastTime是server并行地向集群中的每个server发送RPC并且收到回复的平均时间；electionTimeout就是如Section 5.2中描述的选举超时；MTBF是单个server发生故障的时间间隔。broadcastTime必须比electionTimeout小几个数量级，这样leader就能可靠地发送heartbeat message从而防止follower开始选举；通过随机化的方法确定electionTimeout，该不等式又让split vote不太可能出现。electionTimeout必须比MTBF小几个数量级，从而让系统能稳定运行。当leader崩溃时，系统会在大概一个electionTimeout里不可用；我们希望这只占整个时间的很小一部分。 broadcastTime和MTBF都是底层系统的性质，而electionTimeout是我们必须要进行选择的。Raft的RPC通常要求接收者持久化信息到stable storage，因此broadcastTime的范围在0.5ms到20ms之间，这取决于存储技术。因此，election timeout可以取10ms到500ms。通常，server的MTBF是几个月或者更多，因此很容易满足timing requirement。 6 Cluster membership changes到目前为止，我们都假设集群配置(参与共识算法的server集合)是固定的。但实际上，偶尔改变配置是必要的，比如在server发生故障时将其移除或者改变复制程度。虽然这可以通过停止整个集群来更新配置文件，再重启集群实现，但是这会让集群在转换期间变为不可用。此外，如果其中存在手动操作的话，还会产生操作失误的风险。为了防止上述情况的发生，我们决定将配置变更自动化，并且将其和Raft共识算法结合起来。 为了保证配置更改机制的安全性，在转换期间的任意时刻，不能在一个term期间有两个leader存在。不幸的是，任何从旧配置转换到新配置的方法都是不安全的。不可能一次性对所有server进行自动转换，所以在转换期间集群会被潜在地分为两个独立的majority（见Figure 10）。 为了保证安全性，配置更改必须使用二阶段（two-phase）的方法。有很多种方法可以实现实现two-phase，比如有些系统使用first phase来禁用旧配置，从而不能处理client的请求；然后在second phase中使用新配置。在Raft中，集群首先转换到一个过度的配置，我们称作joint consensus；一旦joint consensus被提交之后，系统就过渡到新配置。joint consensus同时结合了旧配置和新配置。 log entry会被备份到两个配置的所有server中 来自任意配置的server都可能会成为leader Agreement（election和entry的commitment）需要由旧配置和新配置的majority达成 joint consensus允许个别server在不破坏安全性的情况下，在不同的时间进行配置的过渡。另外，joint consensus允许集群在配置转换期间依旧能够处理来自client的请求。 集群的配置被存储在replicated log的special entry中，并且通过它来进行通信；Figure 11说明了配置改变的过程。当leader收到了一个将配置从Cold转换到Cnew请求，它会将joint consensus的配置（figure中的Cold,new）作为一个log entry存储并且使用上文描述的机制进行备份。一旦一个给定的server将一个新配置的entry加入它的log中，它就会在以后所有的decision中使用该配置（server总是使用它log中的最新配置，不管该entry是否被committed）。这意味着leader会使用Cold,new的规则来决定何时Cold,new的log entry被committed。如果该leader崩溃了，一个新的leader可能使用Cold或者Cold,new，这取决于赢得选举的candidate是否收到了Cold,new。任何情况下，Cnew都不能在这个阶段做单方面的决定。 一旦Cold,new被committed，Cold或者Cnew就不能在没有对方同意的情况下单独做决定了，而Leader完整性则确保了Cold,new的log entry的server才能被选作leader。现在leader创建一个描述Cnew的log entry并且将它备份到整个集群是安全的。同样，这个配置只要server看到它就会生效。当新的配置在Cnew的规则被committed时，old 配置就不再有效了，而那些不在新配置中的server就会被关闭。如Figure 11所示，没有一个时刻，Cold或者Cnew会单方面做决定，这就保证了安全性。 对于重新配置（reconfiguration）还有三个问题需要处理。第一个问题是新加入的server可能初始的时候没有存储任何log entry。如果它们以这种状态直接添加进集群，可能会花费相当多的时间让它们赶上来，而在这期间就不能提交新的log entry了。为了避免可用性差距（availability gaps），Raft在配置变更之前引入了一个附加项，在这期间新的server作为non-voting member（leader将log entry向它们备份，但是在计算majority时，并不考虑它们）加入集群。一旦新加入的server赶上了集群中的其他server之后，reconfiguration就会按照上面描述的步骤进行。 第二个问题是集群的leader可能并不包含在新配置中。在这种情况下，leader一旦提交了Cnew log entry之后leader就会step down(返回follower的状态)。这意味着会有这样一段时间（当在commit Cnew）时，leader可能会管理一个并不包含它自己的集群；它备份log entry，但是并不把它自己考虑在majority的计算中。leader的转换会在Cnew被committed之后发生，因为这是新配置可以独立运行的第一步（总是可以在Cnew中选出一个leader）。在这之前，只有Cold中的server才会被选为leader。 第三个问题是被移除的server（那些不在Cnew中的server）可能会破坏集群。这些server不会收到heartbeats，所以它们会timeout并且开始new election。于是它们会用新的term number发送RequestVote RPC，这会导致current leader恢复到follower的状态。一个新的leader最终会被选举出来，但是removed server还会再次timeout，而这个过程会不断重复，最终导致可用性非常差。 为了防止这样的情况发生，server会无视RequestVote RPC，如果它们认为current leader依旧存在的话。特别是一个server在election timeout内收到了一个RequestVote RPC，那么它不会更新它的term或者进行投票。这不会影响正常的选举，在开始election之前每个server都至少等待一个最小的election timeout。而这避免了removed server带来的破坏；如果一个leader能够从它的集群中得到heartbeat，那么它就不会受到更大的term number的影响。 7 Clients and log compaction由于篇幅的原因本章就略过了，但是相关的资料在本论文的扩展版中可以获得。其中描述了client如何和Raft进行交互，包括client怎么找到cluster leader以及Raft如何支持线性语义（linearizable semantics）。扩展版本中还描述了如何利用快照（snapshotting）的方法回收replicated log的空间。这些问题在所有一致性系统（consensus-based system）中都会出现，Raft的解决方案和它们是类似的。 8 Implementation and evalution我们已经将Raft作为存储RAMCloud配置信息的replicated state machine实现并且协助RAMCloud coordinator的故障转移。Raft的实现大概包含2000行C++代码，不包括测试，注释以及空白行。源代码可以自由获取。同时还有25个基于本论文的关于Raft的独立第三方开源实现。同时，还有各种公司在部署Raft-based systems。本节的剩余部分将从可理解性，正确性以及性能三个标准来评估Raft。","link":"/2022/01/21/%E3%80%8AIn-Search-of-an-Understandable-Consensus-Algorithm%E3%80%8B%E7%BF%BB%E8%AF%91/"},{"title":"前端学习路线","text":"html, css和js 提升开发环境 学习框架 提升知识深度与广度 软实力 享受生活 零. 路线来源作者：objtube的卢克儿路线图：https://objtube.github.io/front-end-roadmap/#/视频：https://www.bilibili.com/video/BV1ZZ4y1H7rU ## 一. html, css和js 首先菜鸟教程上掌握html的常用标签和css的基本属性。要重点掌握如何使用css灵活布局节点。要注意初学者不要过早使用框架，这会导致基础不扎实。然后开始学习js，掌握js的基本语法、数据类型、操作符、变量、函数声明、DOM编程、Ajax等。作者推荐了两本书 《JavaScript高级程序设计》《JavaScript DOM编程艺术》 试着开发一个静态博客网站，并上传至github。借此来初步了解版本控制工具git的使用方法。总之这一阶段就是打好基础，不要着急学抽象封装好的库和框架。 不要跳步！多看多写！ 二. 提升开发环境首先安装nodejs，安装成功后，包管理工具npm也安装好了。这时候就要去了解npm常用命令以及package.json里面的常见属性。不要着急，先将node当作辅助学习前端的工具使用，了解如何起服务，如何使用nodejs提供的fs包读取本地文件就差不多。 这个阶段更推荐了解的是Webpack。打开Webpack的官网的指南页面，按照官方教程去学习，配合阮一峰老师的es6教程一起使用。官方教程看到“开发”这一章节就可以了，后面比较复杂不太常用到。 根据学到的Webpack知识，可以试着提升一下开发环境，最终使写的网页可以在localhost: 8080被访问，js、css加载正常，并且修改代码后网页会动态刷新。 最后可以在Webpack中引入Sass或Less预处理器，以提升写CSS的效率。 三. 学习框架基础夯实了之后，可以选则一个框架来深入学习。如react、vue、angular，新手更推荐使用vue，更容易入手，并且官方文档详细，翻译的质量更高。以上三者都是提供工具包来帮助你创建项目工程，无需自己去配置Webpack，省去了很短麻烦。在这一简短，可以短时间的学会很短东西。因为严格来说React、Vue并不是一个框架，而是操作视图UI的lib库，需要配合路由状态管理工具库等一起使用才称得上一个框架。例如，vue有vue-router、vuex，除此之外可能还会引入一些其他的库，比如组件库。像Ant Design、ElementUI等等。 所以在一个项目的开发中，可能需要格外去学习很多的库，这个阶段的建议是：一定要多读官方文档。在开发中遇到的大部分问题，通过阅读文档都能解决。掌握一个框架要多读、多想、多练。 回顾回顾所学过的知识，查漏补缺。比如网络相关知识，互联网是如何运作的，http、https、DNS的工作原理，浏览器是如何渲染页面的，什么是重绘和重排，http怎么做SEO搜索优化，JS如何做ES6语法，promise的使用，set map的使用。 这个阶段要总结出自己的知识库。被动接受的知识并不能代表真正掌握了知识，需要主动输出，写博客或与大家分享。 四. 提升知识深度与广度回顾自己的技术栈，在学习的过程中。很多的技术都有替代品，那么他们之间有什么差异？不同的情况下又将如何选择呢？比如Webpack和Rollup.js都是打包工具，但webpack打包时会生成很多冗余的代码，而rollup则不会，所以rollup更适合打包一些lib包。 五. 软实力抽象思维、视野与影响力。 抽象思维包括对代码的抽象和对业务的抽象。对代码的抽象是将常写的代码封装成工具库，将复杂的代码逻辑抽象简单化，然后提供给团队成员使用。业务的抽象指的是寻找业务场景中的一些共性或一些机器可替代的工作。然后，要拓宽技术和业务的视野。影响力又分为在公司和业内的影响力。 六. 享受生活多锻炼身体、好好休息、不要熬夜、拥有一个好的向上的心态。垫高显示器，把显示器的中心和视线齐平，保护好颈椎，身体是革命的本钱。最后，还要保护好自己的头发。","link":"/2021/12/30/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/"},{"title":"安装 CentOS-7","text":"安装 VMware Workstation 安装 CentOS-7 目录 1 安装 VMware Workstation 1.1 什么是 VMware？ 1.2 下载 VMware 1.3 安装 VMware 2 安装 CentOS-7 2.1 什么是 CentOS-7？ 2.2 下载 CentOS-7 2.3 创建虚拟机 2.4 配置虚拟机 2.5 安装虚拟机 1 安装 VMware Workstation1.1 什么是 VMware？VMware Workstation是VMware公司销售的商业软件产品之一。该工作站软件包含一个用于英特尔x86兼容计算机的虚拟机套装，其允许用户同时创建和运行多个x86虚拟机。每个虚拟机可以运行其安装的操作系统，如（但不限于）Windows、Linux、BSD变生版本。用简单术语来描述就是，VMware Workstation允许一台真实的计算机在一个操作系统中同时打开并运行数个操作系统，其它VMware产品帮助在多个宿主计算机之间管理或移植VMware虚拟机。免费版本为VMware Workstation Player。 1.2 下载 VMware进入下载地址，点击下载windows版本。 1.3 安装 VMware1.3.1 打开安装向导程序 1.3.2 接收许可协议中的条款 1.3.3 选择安装位置 1.3.4 用户体验设置 1.3.5 快捷方式设置 1.3.6 开始安装 1.3.7 输入许可证密钥选择下列中的一个密钥输入： ZF3R0-FHED2-M80TY-8QYGC-NPKYFYF390-0HF8P-M81RQ-2DXQE-M2UT6ZF71R-DMX85-08DQY-8YMNC-PPHV8 1.3.7 完成安装 1.4 打开 VMware打开创建在桌面的快捷方式，VMware的界面如下： 2 安装 CentOS-72.1 什么是 CentOS-7？CentOS 7是CentOS项目发布的开源类服务器操作系统，于2014年7月7日正式发布，它是一个企业级的Linux发行版本，它源于RedHat免费公开的源代码进行再发行。 CentOS 7提供的各种安装镜像可用于在对应安装环境里的安装，优先选择DVD镜像。 “DVD”版本：允许选择要安装的组件，并包含可以从GUI安装程序中选择的所有软件包。 “Everything”版本：大小是普通DVD版本镜像的两倍以上，并且在大多数常见安装中都不是必需的。它仅供希望运行自己的本地镜像的系统管理员使用。使用“Everything”镜像不会在安装程序中提供更多选择软件包的选项。 “Gnome”和“KDE”版本：可以在桌面环境中使用实时媒体图像。 “NetInstall”版本：可用于通过网络进行安装。使用“NetInstall”版本镜像引导计算机后，安装程序将询问应从何处获取要安装的软件包。 “Minimal”版本：精简版，自带的软件最少。 2.2 下载 CentOS-7进入阿里云镜像站点，进行下载。 各个版本的ISO镜像文件说明： CentOS-7-x86_64-DVD-2009.iso 标准安装版（推荐） CentOS-7-x86_64-Everything-2009.iso 完整版，集成所有软件 CentOS-7-x86_64-LiveGNOME-2009.iso GNOME桌面版 CentOS-7-x86_64-LiveKDE-2009.iso KDE桌面版 CentOS-7-x86_64-Minimal-2009.iso 精简版 CentOS-7-x86_64-NetInstall-2009.iso 网络安装版 2.3 创建虚拟机打开前面安装好的 VMware Workstation，创建新的虚拟机。 2.3.1 配置类型–自定义 2.3.2 硬盘兼容性–默认 2.3.3 安装来源–稍后安装操作系统 2.3.4 操作系统版本–CentOS 7 64位windows系统应安装64位版本。 2.3.5 命名虚拟机并选择位置 2.3.6 处理器配置虚拟机总核心数不能超过主机核心数，否则会有警告提醒。 2.3.7 处理器配置虚拟机总核心数不能超过主机核心数，否则会有警告提醒。 2.3.8 内存设置一般虚拟机内存设置为2G。 2.3.9 网络类型–桥接网络可以使虚拟机与主机使用同一网络。 2.3.10 I/O控制器类型–默认 2.3.11 磁盘类型–默认 2.3.12 选择磁盘–创建新的虚拟磁盘 2.3.13 指定磁盘容量–100G不占主机内存。 2.3.14 指定磁盘文件文件 2.3.15 完成点击自定义硬件，建议删除USB控制器、声卡、打印机，让虚拟机启动快一些。 2.3.16 添加镜像文件点击自定义硬件或虚拟机设置，选择设备中的CD/DVD（IDE），选择使用iso镜像文件并填入下载好的iso镜像路径。 2.4 配置虚拟机点击进入虚拟机，选择Install CentOS 7。 2.4.1 选择安装语言–中文 2.4.2 本地化点击键盘，添加 English（US）。 2.4.3 软件点击软件选择，我这里选择了 GNOME 桌面。 字符界面安装：最小安装或者基本网页服务器。 图形界面安装：带GUI的服务器或者GNOME桌面。 字符界面与图形界面安装过程相同，只在这一步有区分。 2.4.3 系统点击安装位置，先选中创建虚拟机时候的100G虚拟硬盘，再选择自定义分区，点击完成。 点击加号创建分区/boot区、/分区、swap交换分区。 点击完成，再点击接受修改。 回到安装信息摘要界面，点击网络连接和主机名，设置主机名。 以上完成了所有的配置，点击开始安装并等待安装完成。 2.5 安装虚拟机2.5.1 设置 ROOT 密码务必记住密码。 2.5.2 创建用户此处可以不进行创建，安装完成后进入root也可以重新创建。 安装完成之后，点击完成配置，然后点击重启，进入登录界面。 输入密码，就可以开始使用了。 这里默认的终端主题是白底黑字，修改方式为“应用程序–&gt;附件–&gt;优化–&gt;外观–&gt;主题”设置应用程序的主题为“Adwaita-dark”。 使用ntp同步标准时间，ntp：网络时间协议（network time protol） yum install ntpntpdate pool.ntp.org","link":"/2022/02/05/%E5%AE%89%E8%A3%85%20CentOS-7/"},{"title":"安装 openGauss","text":"更换国内镜像下载源 安装 Python 3.7.0 安装 openGauss 目录 1 更换国内镜像下载源 1.1 备份原配置文件 1.2 下载新配置文件 1.3 更新元数据 2 安装 Python 3.7.0 2.1 安装依赖环境 2.2 下载与安装 Python 3.7.0 3 安装 openGauss 3.1 安装相关软件包 3.2 创建用户 3.3 下载并解压 openGauss 安装包 3.4 配置XML文件 3.5 预安装 3.6 安装 1 更换国内镜像下载源1.1 备份原配置文件进入yum源配置目录： cd /etc/yum.repos.d 安装wget： sudo yum install wget 修改yum源，即修改CentOS-Base.repo的内容，先做备份： sudo mv CentOS-Base.repo CentOS-Base.repo.backup 1.2 下载新配置文件用wget下载国内的yum源（即CentOS-Base.repo文件），目前国内主要有三个yum源： 阿里云（推荐）： sudo wget -O CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 中科大： sudo wget -O CentOS-Base.repo https://lug.ustc.edu.cn/wiki/_export/code/mirrors/help/centos?codeblock=3 网易： sudo wget -O CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo 1.3 更新元数据清除原来的元数据缓存： sudo yum clean all 更新元数据缓存： sudo yum makecache 2 安装 Python 3.7.0先安装Python的依赖环境，不然在安装过程中容易报错 2.1 安装依赖环境 yum install gcc-c++yum -y install -y lsbyum -y install -y libXScrnSaveryum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel libffi-devel 2.2 下载与安装 Python 3.7.0打开官网Python.org，在 Downloads目录下的Source code中查看Python版本和下载链接，这里选择3.7.0版本。 wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgz 解压安装包： tar -xvzf Python-3.7.0.tgzcd Python-3.7.0/ 添加相关配置信息： ./configure –prefix=/usr/python3 –enable-optimizations –with-ssl 编译与安装： make &amp;&amp; make install 这样就是安装成功了： 创建软连接： ln -s /usr/python3/bin/python3 /usr/bin/python3ln -s /usr/python3/bin/pip3 /usr/bin/pip3 升级pip工具： pip3 install –upgrade pip 以上就完成了python的安装，查看python版本： python3 –version 3 安装 openGauss3.1 安装相关软件包 yum install -y libaio-develyum install -y flexyum install -y bisonyum install -y ncurses-develyum install -y glibc-develyum install -y patchyum install -y lsb release 3.2 创建用户linux中已有用户root，但是Gauss数据库默认以dbgrp为用户组，omm为用户，所以需要进行用户创建。 cd /groupadd dbgrpuseradd -g dbgrp ommecho 123456 | passwd –stdin omm 123456 处填入用户密码。 3.3 下载并解压 openGauss 安装包首先为 openGauss 创建一个目录，用来存放下载的压缩包和解压后的文件，这里在 /opt/software 下创建名为 openGauss 的文件夹，并用 chmod 命令赋予 openGauss 文件夹的读写权限： cd /optmkdir softwarecd softwaremkdir openGausschmod -R 755 /opt/software/openGauss 进入openGauss官网下载安装包，这里选择的是2.1.0企业版。 下载完成后将安装包放入 /opt/software/openGauss 文件夹。如果不能直接复制或拖拽可以使用共享文件夹，在设置中开启共享文件夹，然后将安装包放入共享文件夹，并输入以下命令： vmhgfs-fuse .host:/ /mnt/hgfscd /mnt/hgfscd Sharels 这里如果想永久挂载，要编辑文件 /etc/fstab，添加信息： .host:/Share /mnt/hgfs fuse.vmhgfs-fuse allow_other,defaults 0 0 执行命令 mount -a 使之立即生效。 然后使用 mv 命令将文件移动至 /opt/software/openGauss 文件夹中： mvopenGauss-2.1.0-CentOS-64bit-all.tar.gz /opt/software/openGauss/openGauss-2.1.0-CentOS-64bit-all.tar。gz 然后进入 openGauss 文件夹进行解压： tar -zxvf openGauss-2.1.0-CentOS-64bit-all.tar.gztar -zxvf openGauss-2.1.0-CentOS-64bit-om.tar.gzls -l 显示如下信息即解压成功： 3.4 配置XML文件进入刚刚解压产生的script文件夹，查看是否有预安装脚本： cd /opt/software/openGauss/script 在openGauss目录下执行 vim 命令。然后将下面内容右键粘贴到新建的xml文件中，然后按esc退出插入模式，输入:wq！保存并退出。 cd /opt/software/openGaussvim clusterconfig.xml 填入内容如下，节点名称和IP要改成自己的，可以 hostname 命令查看本机名称： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;ROOT&gt; &lt;!-- openGauss整体信息 --&gt; &lt;CLUSTER&gt; &lt;!-- 数据库名称 --&gt; &lt;PARAM name=&quot;clusterName&quot; value=&quot;dbCluster&quot; /&gt; &lt;!-- 数据库节点名称(hostname) --&gt; &lt;PARAM name=&quot;nodeNames&quot; value=&quot;node1,node2&quot; /&gt; &lt;!-- 节点IP，与nodeNames一一对应 --&gt; &lt;PARAM name=&quot;backIp1s&quot; value=&quot;192.168.0.11,192.168.0.12&quot;/&gt; &lt;!-- 数据库安装目录--&gt; &lt;PARAM name=&quot;gaussdbAppPath&quot; value=&quot;/opt/huawei/install/app&quot; /&gt; &lt;!-- 日志目录--&gt; &lt;PARAM name=&quot;gaussdbLogPath&quot; value=&quot;/var/log/omm&quot; /&gt; &lt;!-- 临时文件目录--&gt; &lt;PARAM name=&quot;tmpMppdbPath&quot; value=&quot;/opt/huawei/tmp&quot;/&gt; &lt;!--数据库工具目录--&gt; &lt;PARAM name=&quot;gaussdbToolPath&quot; value=&quot;/opt/huawei/install/om&quot; /&gt; &lt;!--数据库core文件目录--&gt; &lt;PARAM name=&quot;corePath&quot; value=&quot;/opt/huawei/corefile&quot;/&gt; &lt;!-- openGauss类型，此处示例为单机类型，“single-inst”表示单机一主多备部署形态--&gt; &lt;PARAM name=&quot;clusterType&quot; value=&quot;single-inst&quot;/&gt; &lt;/CLUSTER&gt; &lt;!-- 每台服务器上的节点部署信息 --&gt; &lt;DEVICELIST&gt; &lt;!-- node1上的节点部署信息 --&gt; &lt;DEVICE sn=&quot;1000001&quot;&gt; &lt;!-- node1的hostname --&gt; &lt;PARAM name=&quot;name&quot; value=&quot;node1&quot;/&gt; &lt;!-- node1所在的AZ及AZ优先级 --&gt; &lt;PARAM name=&quot;azName&quot; value=&quot;AZ1&quot;/&gt; &lt;PARAM name=&quot;azPriority&quot; value=&quot;1&quot;/&gt; &lt;!-- 如果服务器只有一个网卡可用，将backIP1和sshIP1配置成同一个IP --&gt; &lt;PARAM name=&quot;backIp1&quot; value=&quot;192.168.0.11&quot;/&gt; &lt;PARAM name=&quot;sshIp1&quot; value=&quot;192.168.0.11&quot;/&gt; &lt;!--dbnode--&gt; &lt;PARAM name=&quot;dataNum&quot; value=&quot;1&quot;/&gt; &lt;!--DBnode端口号--&gt; &lt;PARAM name=&quot;dataPortBase&quot; value=&quot;26000&quot;/&gt; &lt;!--DBnode主节点上数据目录，及备机数据目录--&gt; &lt;PARAM name=&quot;dataNode1&quot; value=&quot;/opt/huawei/install/data/db1,node2,/opt/huawei/install/data/db1&quot;/&gt; &lt;!--DBnode节点上设定同步模式的节点数--&gt; &lt;PARAM name=&quot;dataNode1_syncNum&quot; value=&quot;0&quot;/&gt; &lt;/DEVICE&gt; &lt;!-- node2上的节点部署信息，其中“name”的值配置为主机名称（hostname） --&gt; &lt;DEVICE sn=&quot;1000002&quot;&gt; &lt;PARAM name=&quot;name&quot; value=&quot;node2&quot;/&gt; &lt;PARAM name=&quot;azName&quot; value=&quot;AZ1&quot;/&gt; &lt;PARAM name=&quot;azPriority&quot; value=&quot;1&quot;/&gt; &lt;!-- 如果服务器只有一个网卡可用，将backIP1和sshIP1配置成同一个IP --&gt; &lt;PARAM name=&quot;backIp1&quot; value=&quot;192.168.0.12&quot;/&gt; &lt;PARAM name=&quot;sshIp1&quot; value=&quot;192.168.0.12&quot;/&gt; &lt;/DEVICE&gt; &lt;/DEVICELIST&gt;&lt;/ROOT&gt; 然后执行 vi /etc/profile 命令打开profile文件，添加如下命令： export LD_LIBRARY_PATH=/opt/software/openGauss/script/gspylib/clib:$LD_LIBRARY_PATHexport GPHOME=/opt/huawei/install/omexport PATH=$GPHOME/script/gspylib/pssh/bin:$GPHOME/script:$PATHexport LD_LIBRARY_PATH=$GPHOME/script/gspylib/clib:$LD_LIBRARY_PATHexport LD_LIBRARY_PATH=$GPHOME/lib:$LD_LIBRARY_PATHexport PYTHONPATH=$GPHOME/lib 然后接 source 命令： source /etc/profile 3.5 预安装执行命令： cd /opt/software/openGauss/script./gs_preinstall -U omm -G dbgrp -X /opt/software/openGauss/clusterconfig.xml 出现提示，说明CentOS-7版本过高，应降至7.6版本： The current OS is not supported. The current system is: centos7.9 这里尝试降低 CentOS 版本，下载 Centos 7.6 的rpm包： wget https://www.repo.cloudlinux.com/cloudlinux/migrate/release-files/centos/7/x86_64/centos-release-7-6.1810.2.el7.centos.x86_64.rpm 安装下载的7.6 rpm 包： rpm -ivh centos-release-7-6.1810.2.el7.centos.x86_64.rpm –force 运行 rpm -qa | grep -i centos-release 可以查看到两个发行版本： rpm -qa | grep -i centos-release 卸载7.9版本： rpm -ev centos-release-7-7.1908.0.el7.centos.x86_64 再查看内核版本和发行版版本： uname -acat /etc/redhat-release 重新执行预安装命令，这样就预安装成功了： cd /opt/software/openGauss/script./gs_preinstall -U omm -G dbgrp -X /opt/software/openGauss/clusterconfig.xml 预安装可能会出现的问题： XML文件不完整[GAUSS-51234] : The configuration file [/opt/software/openGauss/clusterconfig.xml] contains parsing errors. Error: 节点名称修改有误：[GAUSS-51236] : Failed to parsing xml. Error: 通过openGauss提供的gs_checkos工具来检查系统状态。注意需要切换到/opt目录下执行命令： cd /optgs_checkos -i A 3.6 安装切换到omm用户，进行安装： su - ommenv | grep GAUSSgs_install -X /opt/software/openGauss/clusterconfig.xml 其中需要设置密码，八位以上并且至少有三种字符。出现以下输出即为安装成功： 在omm用户下，执行gs_om -t start命令和gs_om -t stop命令启动或关闭数据库： gs_om -t startgs_om -t stop 以上就完成了 openGauss 的全部安装过程。","link":"/2022/02/07/%E5%AE%89%E8%A3%85-openGauss/"},{"title":"更换 icarus 主题","text":"下载 icarus 主题 配置 icarus 主题 查看 icarus 效果 修改上方导航栏 修改下方导航栏 修改个人信息 一. 下载 icarus 主题方法 1在博客根目录右键点击 Git Bash Here，输入： npm install hexo-theme-icarus 检查themes文件夹，看是否出现了 icarus 文件夹 方法 2在博客根目录右键点击 Git Bash Here，输入： git clone https://github.com/ppoffice/hexo-theme-icarus themes/icarus 检查themes文件夹，看是否出现了 icarus 文件夹 方法 3若前面的方法无效的话，进入icarus项目，点击 code 下载文件。将下载好的安装包解压至themes文件夹，并重命名：icarus。 二. 配置 icarus 主题在博客根目录右键点击 Git Bash Here，依次输入： hexo config theme icarushexo cleanhexo ghexo s 如果中间出现错误信息，则按提示下载缺少的依赖。 三. 查看 icarus 效果在浏览器中打开：localhost:4000。成功的效果如下： 如出现白屏，并有如下显示： const { Component } = require(‘inferno’); const classname = require(‘hexo-component-inferno/lib/util/classname’); const Head = require(‘./common/head’); const Navbar = require(‘./common/navbar’); const Widgets = require(‘./common/widgets’); const Footer = require(‘./common/footer’); const Scripts = require(‘./common/scripts’); const Search = require(‘./common/search’); module.exports = class extends Component { render() { const { site, config, page, helper, body } = this.props; const language = page.lang || page.language || config.language; const columnCount = Widgets.getColumnCount(config.widgets); return ; } }; 则需要在 Git Bash Here 中依次执行： npm install –save bulma-stylus@0.8.0 hexo-renderer-inferno@^0.1.3hexo cleanhexo ghexo s 这样，我们就完成了 icarus 主题的更换。如果还遇到了其他问题，请查看：icarus用户指南。 四. 修改logo与图标打开 themes\\icarus\\source\\img，其中：网站logo为 /img/logo.svg网站图标为 /img/favicon.svg你的头像为 /img/avatar.png 替换相应的图标即可。 若想改变图像名称，如将 favicon.svg 改为 touxiang.svg，还需要在根目录下的 _config.icarus.yml 中同时更改字段： logo: /img/logo.svgfavicon: /img/favicon.svg 推荐两个可能用到的网站：svg图片转换网站、2. 圆角图片制作网站 五. 修改上方导航栏打开根目录下的 _config.icarus.yml 文件，找到 navbar 字段。menu 字段下是导航栏的各个选项，可对其名称和路径进行增加、删除和修改。 1. 增加新导航栏选项在 Git Bash Here 中输入如下指令，其中双引号中添加选项名称。 hexo new page “ “ 在 source 文件夹下便可以找到选项所对应的文件夹。打开文件加，修改对应的 .md 文件，便可以实现对相应页面的渲染。 2. 删除与修改新导航栏选项删除与修改相应的字段即可。icarus 默认带有的选项无对应文件夹，但是存在代码实现对应的页面。 3. 修改 github 链接找到 links 字段下的 url 字段，将其替换为自己的 github 主页链接。 可以对导航栏的链接进行替换，如换成 b站 或 微博 的链接。方法是直接修改 icon 和 url 字段。其中，icon 字段的值由图标库所定义，具体可以查看：FontAwesome图标库 如要向导航栏右侧添加链接，请向links设置项中添加 链接名: 链接URL。 五. 修改下方导航栏打开根目录下的 _config.icarus.yml 文件，找到 footer 字段。这里有三个位置可供修改，修改方法同上。可以删掉多余的字段，即保留少于三个链接。 六. 修改个人信息打开根目录下的 _config.icarus.yml 文件，找到 widgets 字段。这个字段下配置着基本信息和设置。 author: 昵称 author_title: 作者身份描述 location: 作者当前居住地 avatar: 头像url follow_link: 个人链接，可设为GitHub主页 social_links: 社交平台链接，可进行删除和修改。 更多设置可参考：Hexo+icarus主题配置","link":"/2022/01/04/%E6%9B%B4%E6%8D%A2-icarus-%E4%B8%BB%E9%A2%98/"},{"title":"搭建自己的博客","text":"关于教程 初版效果 关于教程我看的是程序羊的搭建博客的教程，网址是：https://www.bilibili.com/video/BV1Yb411a7ty 初版效果","link":"/2021/12/30/%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/"},{"title":"服务器上启动OG的DCF模块","text":"前期配置工作 DCF的启动 测试 修改代码 目录 1 前期配置工作 2 DCF的启动 2.1 配置DCF白名单 2.2 配置DCF参数 2.3 启动集群 3 测试 3.1 数据同步测试 3.2 节点异常测试 4 修改代码 1 前期配置工作按照师兄《OpenGauss 编译环境配置、编译与安装》中的OpenGauss编译流程，分别在slave02-slave04上进行OpenGauss的编译。编译过程中值得注意的是，第三方软件需要修改环境变量，对/data/toolchain/binarylibs进行引用，而不要移动或拷贝这一文件夹。注意，以下操作需要在正确进行编译工作后进行。 本次参与集群构建的三台服务器地址与角色如下： slave02（172.19.0.202）: leaderslave03（172.19.0.203）: followerslave04（172.19.0.204）: follower 如果新建终端，需要配置环境变量: cd /home/lenyb/openGauss-serversource env.sh 分别在三台服务器上进行初始化，需要添加 -c 参数，以生成 dcf 相关文件，注意设置 nodename。 gs_initdb --nodename=gaussdb1 -w lamber@123456 -D /home/lenyb/opengauss/data/ -c 2 DCF模块的启动2.1 配置DCF白名单分别在slave02-slave04上打开 pg_hba.conf 配置文件: vim /home/lenyb/opengauss/data/pg_hba.conf 在 postgresql.conf 最后面添加白名单： host all all 172.19.0.202/32 trusthost all all 172.19.0.203/32 trusthost all all 172.19.0.204/32 trust 2.2 配置DCF参数分别在slave02-slave04上打开 postgresql.conf 配置文件，因为在初始化时加了 -c，其中的 enable_dcf 参数会自动打开。 vim /home/lenyb/opengauss/data/postgresql.conf 在 172.19.0.202 下 postgresql.conf 的最后添加下列信息（全部使用英文符号）： port=21000dcf_node_id = 1dcf_ssl=offdcf_data_path = ‘/home/lenyb/opengauss/data/dcf_data’dcf_log_path= ‘/home/lenyb/opengauss/data/dcf_log’dcf_config=’[{“stream_id”:1,”node_id”:1,”ip”:”172.19.0.202”,”port”:21000,”role”:”LEADER”},{“stream_id”:1,”node_id”:2,”ip”:”172.19.0.203”,”port”:21000,”role”:”FOLLOWER”},{“stream_id”:1,”node_id”:3,”ip”:”172.19.0.204”,”port”:21000,”role”:”FOLLOWER”}]’replconninfo1 = ‘localhost=172.19.0.202 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=172.19.0.203 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’replconninfo2 = ‘localhost=172.19.0.202 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=172.19.0.204 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’ 在 172.19.0.203 下 postgresql.conf 的最后添加下列信息（全部使用英文符号）： port=21000dcf_node_id = 2dcf_ssl=offdcf_data_path = ‘/home/lenyb/opengauss/data/dcf_data’dcf_log_path= ‘/home/lenyb/opengauss/data/dcf_log’dcf_config=’[{“stream_id”:1,”node_id”:1,”ip”:”172.19.0.202”,”port”:21000,”role”:”LEADER”},{“stream_id”:1,”node_id”:2,”ip”:”172.19.0.203”,”port”:21000,”role”:”FOLLOWER”},{“stream_id”:1,”node_id”:3,”ip”:”172.19.0.204”,”port”:21000,”role”:”FOLLOWER”}]’replconninfo1 = ‘localhost=172.19.0.203 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=172.19.0.202 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’replconninfo2 = ‘localhost=172.19.0.203 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=172.19.0.204 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’ 在 172.19.0.204 下 postgresql.conf 的最后添加下列信息（全部使用英文符号）： port=21000dcf_node_id = 3dcf_ssl=offdcf_data_path = ‘/home/lenyb/opengauss/data/dcf_data’dcf_log_path= ‘/home/lenyb/opengauss/data/dcf_log’dcf_config=’[{“stream_id”:1,”node_id”:1,”ip”:”172.19.0.202”,”port”:21000,”role”:”LEADER”},{“stream_id”:1,”node_id”:2,”ip”:”172.19.0.203”,”port”:21000,”role”:”FOLLOWER”},{“stream_id”:1,”node_id”:3,”ip”:”172.19.0.204”,”port”:21000,”role”:”FOLLOWER”}]’replconninfo1 = ‘localhost=172.19.0.204 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=172.19.0.202 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’replconninfo2 = ‘localhost=172.19.0.204 localport=21001 localheartbeatport=21005 localservice=21004 remotehost=172.19.0.203 remoteport=21001 remoteheartbeatport=21005 remoteservice=21004’ 2.3 启动集群如果有正在运行的OG进程，需要先关闭： gs_ctl stop -D /home/lenyb/opengauss/data 成功关闭OG进程后，将集群全部节点以standby的模式启动： gs_ctl start -D /home/lenyb/opengauss/data -M standby 在主节点（leader）设置存活节点为少数派模式运行： gs_ctl setrunmode -D /home/lenyb/opengauss/data -v 1 -x minority 然后，集群其他节点（folloer）主动重建拉起： gs_ctl build -b full -D /home/lenyb/opengauss/data 最后，在主节点（leader）执行，使存活节点重回多数派（需要关闭防火墙）： gs_ctl setrunmode -D /home/lenyb/opengauss/data -x normal 至此，集群启动完成，可以查看当前节点状态： gs_ctl query -D /home/lenyb/opengauss/data 3 测试当完成了集群的搭建后，下面做一些简单的测试。 3.1 数据同步测试首先在主节点上连接数据库： gsql -p 21000 postgres -r 创建 ysl 表，插入一条数据并查看： create table ysl (id int);insert into ysl values(1);select * from ysl; 然后在从节点上分别连接数据库，并直接查询该表： gsql -p 21000 postgres -rselect * from ysl; 结果与上图相同，数据同步成功。 3.2 节点异常测试如上文所述，当前slave02（172.19.0.202）为leader节点，slave03（172.19.0.203）与slave04（172.19.0.204）为follower节点。此时，我们让主节点失效再重启，看集群如何处理异常。 首先，在slave02上停掉数据库进程： gs_ctl stop -D /home/lenyb/opengauss/data 然后查看slave03状态： gs_ctl query -D /home/lenyb/opengauss/data 可见此时slave03的状态已经由standby变为primary，角色由follower变为leader。然后查看slave04状态： gs_ctl query -D /home/lenyb/opengauss/data 此时slave04的状态依然为standby，作为follower。是因为当slave03与slave04一段时间没有收到过集群leader的心跳消息后，发起了新一轮的leader竞选，slave03当选新一周期的leader节点。此时，将slave02重启，并查看节点状态： gs_ctl start -D /home/lenyb/opengauss/data -M standbygs_ctl query -D /home/lenyb/opengauss/data 可见slave02重启后重新加入集群，并作为follower节点继续运行。如果进行switchover切换操作，那么slave02又会重新成为leader节点： gs_ctl switchover -D /home/lenyb/opengauss/data 但此时，上一任主节点slave03会down掉，需要手动加入集群。 gs_ctl start -D /home/lenyb/opengauss/data -M standby 4 修改代码如果想在集群成功搭建起来后对代码进行修改，需要重新编译运行，先删除opengauss文件： rm -rf /home/lenyb/opengauss 然后配置编译版本、编译与安装： ./configure --gcc-version=7.3.0 CC=g++ CFLAGS=’-O0’ --prefix=$GAUSSHOME --3rd=$BINARYLIBS --enable-debug --enable-cassert --enable-thread-safety --with-readline --without-zlibmake -j`grep -c ^processor /proc/cpuinfo`make install -j`grep -c ^processor /proc/cpuinfo` 然后在按上文所述的全部过程执行一遍。","link":"/2022/10/10/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%90%AF%E5%8A%A8OG%E7%9A%84DCF%E6%A8%A1%E5%9D%97/"},{"title":"百度谷歌收录hexo博客","text":"百度收录博客 谷歌收录博客 1. 百度收录博客以下方法流程适用于 hexo + icarus 博客，其他主题下的设置也大同小异。 1.1 添加网站地址登录百度资源资源平台，在站点管理页面中进行身份验证，然后点击”添加网站”，添加博客网址。然后根据提示输入网站地址和选择网站属性。 1.2 验证网站所有权验证网站所有权的方法有三种：文件、HTML标签和CNAME验证三种。建议使用HTML方法验证。根据指示，将如下格式的代码加入 themes\\icarus\\layout\\common\\head.jsx 文件中的 标签间，注意，要将xxxxxx改为自己网站的序列。 123456789&lt;html&gt; &lt;head&gt; &lt;meta name=&quot;baidu-site-verification&quot; content=&quot;xxxxxx&quot; /&gt; &lt;title&gt;My title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; page contents &lt;/body&gt;&lt;/html&gt; 添加后在 Git Bash Here 中输入指令： hexo ghexo d 等待博客更新后，再点击”验证”，显示验证成功后根据提示开始提交。 1.3 网站资源提交普通收录有三种方式：API提交、sitemap和手动提交，建议使用sitemap提交。 使用sitemap提交方法，要先安装生成器插件。在 Git Bash Here 中输入指令： npm install hexo-generator-sitemap –savenpm install hexo-generator-baidu-sitemap –save 注意：建议安装cnpm后使用cnpm命令。 修改配置文件 _config.icarus.yml，在最后添加： 1234sitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml Git Bash Here 再次重新部署并上传后，检查public文件夹是否出现了 sitemap.xml 和 baidusitemap.xml 两个文件，然后再平台上以如下格式提交： https://lamber1123.github.io/baidusitemap.xml","link":"/2022/01/06/%E7%99%BE%E5%BA%A6%E8%B0%B7%E6%AD%8C%E6%94%B6%E5%BD%95hexo%E5%8D%9A%E5%AE%A2/"},{"title":"编译 openGauss","text":"下载源码包与第三方软件 修改配置文件 编译、安装与测试 目录 1 编译前的准备 2 下载源码包与第三方软件 3 修改配置文件 4 编译与安装 5 测试 1 编译前的准备编译 openGauss 的流程参照了 openGauss编译文档 和 openGauss编译指导书。 编译的流程虽然简单，但网上的博客各有不详细之处。我在首次编译的时候就遇到了无法解决的问题，而本文是将其中我验证过的正确流程加以总结。请先按本文的流程进行编译，如果仍有问题，再阅读官方文档。 编译 openGauss 需要下载 openGauss-server 和 binarylibs 两个组件，后文会给出下载方式。 openGauss-server：openGauss 的主要代码。可以从开源社区获取。 binarylibs：openGauss 依赖的第三方开源软件，官方已经做出了一份已经编译过的版本。 然后请在编译前确保下列软件达到要求版本： 软件 推荐版本 libaio-devel 0.3.109-13 flex 2.5.31及以上版本 bison 2.7-4 ncurses-devel 5.9-13.20130511 glibc-devel 2.17-111 patch 2.7.1-10 lsb_release 4.1 readline-devel 7.0-13 yum install unzip gcc-c++ readline readline-develyum install libaio-devel flex bison ncurses-devel glibc-devel patch lsb_release 2 下载源码包与第三方软件 开源第三方软件：opengauss-openGauss-server-v2.0.0.tar.gz openGauss源码：openGauss-third_party_binarylibs.tar.gz 将下载好的文件通过共享文件夹放入目录 /home/omm 下，然后创建用户 omm（如果未创建）： sugroupadd dbgrp -g 2000useradd omm -g 2000 -u 2000passwd omm 创建安装目录并把目录的读写权赋给用户omm： mkdir -p {/opt/og,/opt/ogdata}chown -R omm: {/opt/og,/opt/ogdata}chmod -R 755 /opt/ogchmod -R 700 /opt/ogdata 把文件的读写权赋给用户omm，注意正确填写压缩包名称： chown omm: openGauss-third_party_binarylibs.tar.gzchmod 755 openGauss-third_party_binarylibs.tar.gzchown omm: openGauss-server-2.1.0.tar.gzchmod 755 openGauss-server-2.1.0.tar.gz 此时一定要通过用户 omm 对两个文件进行解压： su - ommtar -zxvf openGauss-server-2.1.0.tar.gztar -zxvf openGauss-third_party_binarylibs.tar.gz 将压缩包重命名： mv openGauss-third_party_binarylibs binarylibsmv openGauss-server-2.1.0 openGauss-server 3 修改配置文件配置环境变量，如果路径与我不同请进行相应的替换： export CODE_BASE=/home/omm/openGauss-serverexport BINARYLIBS=/home/omm/binarylibsexport GAUSSHOME=/opt/ogexport GCC_PATH=$BINARYLIBS/buildtools/centos7.6_x86_64/gcc7.3/export CC=$GCC_PATH/gcc/bin/gccexport CXX=$GCC_PATH/gcc/bin/g++export LD_LIBRARY_PATH=$GAUSSHOME/lib:$GCC_PATH/gcc/lib64:$GCC_PATH/isl/lib:$GCC_PATH/mpc/lib/:$GCC_PATH/mpfr/lib/:$GCC_PATH/gmp/lib/:$LD_LIBRARY_PATHexport PATH=$GAUSSHOME/bin:$GCC_PATH/gcc/bin:$PATH 这里建议在 /.bash_profile 和 /.bashrc 中同样添加： vim ~/.bash_profile 在文件的末尾添加相同的命令： export CODE_BASE=/home/omm/openGauss-serverexport BINARYLIBS=/home/omm/binarylibsexport GAUSSHOME=/opt/ogexport GCC_PATH=$BINARYLIBS/buildtools/centos7.6_x86_64/gcc7.3/export CC=$GCC_PATH/gcc/bin/gccexport CXX=$GCC_PATH/gcc/bin/g++export LD_LIBRARY_PATH=$GAUSSHOME/lib:$GCC_PATH/gcc/lib64:$GCC_PATH/isl/lib:$GCC_PATH/mpc/lib/:$GCC_PATH/mpfr/lib/:$GCC_PATH/gmp/lib/:$LD_LIBRARY_PATHexport PATH=$GAUSSHOME/bin:$GCC_PATH/gcc/bin:$PATH 使其立即生效： source ~/.bash_profile 对 ~/.bashrc 的操作同上。 4 编译与安装进入目标文件： cd /home/omm/openGauss-servermake clean 忽略这里的报错，开始编译： ./configure –prefix=/opt/og –3rd=/home/omm/binarylibs –gcc-version=7.3.0 –without-readline –without-zlib –enable-thread-safety CC=g++ CFLAGS=”-O2 -g3” 正常情况得到如下反馈： 接下来 make 的时候需要耐心等待，看到如下提示则表明编译成功： make 恭喜，接下来开始安装，同样需要十分耐心的等待： make install 出现 openGauss installation complete 反馈代表安装成功： 5 测试先查看一下安装版本： /opt/og/bin/gsql –version 接着初始化数据库： gs_initdb –nodename=master_5432 –pgdata=/opt/ogdata –encoding=UTF-8 –locale=en_US.UTF-8 –dbcompatibility=’A’ –username=omm –pwpasswd=Mypwd123 在 /opt/ogdata/postgresql.conf 中可以修改监听端口，IP地址为‘0.0.0.0’代表监听所有IP： 启动服务： gs_ctl start -D /opt/ogdata 使用omm用户登陆postgres数据库： gsql -p 5432 -Uomm postgres 以上完成了 openGauss 编译与安装的全部流程。","link":"/2022/02/08/%E7%BC%96%E8%AF%91-openGauss/"},{"title":"给hexo添加网页图标","text":"hexo + yilia 主题设置图标方法 hexo 其他设置图标方法 hexo + yilia 主题设置图标方法 1. 制作ico小图标推荐一个ico制作网站：https://www.bitbug.net/选择一张图片上传，生成.ico文件，这里建议32*32大小，保存名为favicon.ico文件，这里建议32*32大小，保存名为favicon 2. 放置图标将 favicon.ico 图标文件放到 themes/yilia/source/img 文件夹下，找到 hexo\\themes\\yilia\\layout_partial\\head.ejs，修改下面一段代码为： &lt;% if (theme.favicon){ %&gt; &lt;link rel=”icon” href=”/img/favicon.ico”&gt; &lt;% } %&gt; 3. 部署 hexo ghexo shexo d hexo 其他设置图标方法Hexo next主题默认的网页图标长这个样子: 1. 下载或制作ico小图标如上一种方法。 2. 放置图标下载的图标重命名为favicon.ico，位置放在/themes/xxx/source/images中。 3. 放置图标修改主题配置文件，在/themes/xxx/_config.yml中修改成自己的图标。 favicon: small: /images/favicon.ico #medium: /images/favicon-32x32-next.png medium: /images/favicon.ico apple_touch_icon: /images/apple-touch-icon-next.png safari_pinned_tab: /images/logo.svg #android_manifest: /manifest.json","link":"/2021/12/31/%E7%BB%99hexo%E6%B7%BB%E5%8A%A0%E7%BD%91%E9%A1%B5%E5%9B%BE%E6%A0%87/"}],"tags":[{"name":"css","slug":"css","link":"/tags/css/"},{"name":"html","slug":"html","link":"/tags/html/"},{"name":"openGauss","slug":"openGauss","link":"/tags/openGauss/"},{"name":"DCFTest","slug":"DCFTest","link":"/tags/DCFTest/"},{"name":"DCF","slug":"DCF","link":"/tags/DCF/"},{"name":"js","slug":"js","link":"/tags/js/"},{"name":"TiDB","slug":"TiDB","link":"/tags/TiDB/"},{"name":"TiKV","slug":"TiKV","link":"/tags/TiKV/"},{"name":"Raft","slug":"Raft","link":"/tags/Raft/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"RPC","slug":"RPC","link":"/tags/RPC/"},{"name":"Region","slug":"Region","link":"/tags/Region/"},{"name":"Key-Value","slug":"Key-Value","link":"/tags/Key-Value/"},{"name":"RocksDB","slug":"RocksDB","link":"/tags/RocksDB/"},{"name":"MVCC","slug":"MVCC","link":"/tags/MVCC/"},{"name":"PD","slug":"PD","link":"/tags/PD/"},{"name":"TiFlash","slug":"TiFlash","link":"/tags/TiFlash/"},{"name":"映射关系","slug":"映射关系","link":"/tags/%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB/"},{"name":"元信息","slug":"元信息","link":"/tags/%E5%85%83%E4%BF%A1%E6%81%AF/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/tags/Zookeeper/"},{"name":"Zab","slug":"Zab","link":"/tags/Zab/"},{"name":"etcd","slug":"etcd","link":"/tags/etcd/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"},{"name":"Paxos","slug":"Paxos","link":"/tags/Paxos/"},{"name":"VMware","slug":"VMware","link":"/tags/VMware/"},{"name":"CentOS","slug":"CentOS","link":"/tags/CentOS/"},{"name":"ico","slug":"ico","link":"/tags/ico/"}],"categories":[{"name":"css笔记","slug":"css笔记","link":"/categories/css%E7%AC%94%E8%AE%B0/"},{"name":"html笔记","slug":"html笔记","link":"/categories/html%E7%AC%94%E8%AE%B0/"},{"name":"openGauss","slug":"openGauss","link":"/categories/openGauss/"},{"name":"js笔记","slug":"js笔记","link":"/categories/js%E7%AC%94%E8%AE%B0/"},{"name":"TiKV笔记","slug":"TiKV笔记","link":"/categories/TiKV%E7%AC%94%E8%AE%B0/"},{"name":"Raft笔记","slug":"Raft笔记","link":"/categories/Raft%E7%AC%94%E8%AE%B0/"},{"name":"icarus","slug":"icarus","link":"/categories/icarus/"},{"name":"CentOS","slug":"CentOS","link":"/categories/CentOS/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"}]}